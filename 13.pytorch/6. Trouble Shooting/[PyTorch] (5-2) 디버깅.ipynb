{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d327ee5bf5b740f9a0168996230b6cfb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d0ef836c3a44a3e9ff8b0a227e3abdc","IPY_MODEL_7ac73b08943d4ecda4e28b806cf1d0fc","IPY_MODEL_0905c2e6e5d046beb756a381c9900589"],"layout":"IPY_MODEL_f790999fc7cb477ca5613698615d4e6f"}},"5d0ef836c3a44a3e9ff8b0a227e3abdc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ac08a2135d742098b9df667cf527383","placeholder":"​","style":"IPY_MODEL_23054ca7b6a646d2a4b97562765cadbe","value":"  0%"}},"7ac73b08943d4ecda4e28b806cf1d0fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_c76ba883d3b548dd8928ba06dce2f7d4","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9247eb218d214447bfc0473579337e72","value":0}},"0905c2e6e5d046beb756a381c9900589":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14b8f642a1eb4be799508f65105d1fd2","placeholder":"​","style":"IPY_MODEL_60f5c65fef72482484821c9cee47d9a1","value":" 0/10 [00:00&lt;?, ?it/s]"}},"f790999fc7cb477ca5613698615d4e6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ac08a2135d742098b9df667cf527383":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23054ca7b6a646d2a4b97562765cadbe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c76ba883d3b548dd8928ba06dce2f7d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9247eb218d214447bfc0473579337e72":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"14b8f642a1eb4be799508f65105d1fd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60f5c65fef72482484821c9cee47d9a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"305565c21ca34ba788d7eb87fe5817f6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8375ebff861e44bea59cfac1d214b194","IPY_MODEL_aa68868934154c4e970b670212d25dcb","IPY_MODEL_664407e80b2d4d358db674382803dc43"],"layout":"IPY_MODEL_c66d2837eb814554b3d6eefde80adc62"}},"8375ebff861e44bea59cfac1d214b194":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34cfb887dd8f4d7ea32cf975dfcbfd39","placeholder":"​","style":"IPY_MODEL_096715831d3b42409b48362da7f1bd30","value":"Epoch [1/1], Train Loss: 6.0820: 100%"}},"aa68868934154c4e970b670212d25dcb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2898fd1ae8b4cf7b42316d0bd621cc0","max":153,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5c10324688034d47a55e90ac39989682","value":153}},"664407e80b2d4d358db674382803dc43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6368ec6b27f649f892831d17077053bd","placeholder":"​","style":"IPY_MODEL_f87166b68cbf4226a4cee26991c766c1","value":" 153/153 [10:59&lt;00:00,  3.65s/it]"}},"c66d2837eb814554b3d6eefde80adc62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34cfb887dd8f4d7ea32cf975dfcbfd39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"096715831d3b42409b48362da7f1bd30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2898fd1ae8b4cf7b42316d0bd621cc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c10324688034d47a55e90ac39989682":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6368ec6b27f649f892831d17077053bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f87166b68cbf4226a4cee26991c766c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4335c20e43c4494e9844ced338fe93e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4bd352a341a940068dc6e449f37ecbb7","IPY_MODEL_0f43c75d13224254a497689e312ff0f8","IPY_MODEL_bf0129c7c3c4446ea80d0c0e94d8425e"],"layout":"IPY_MODEL_7525c4940a864cc980a4e3bc5d8aad53"}},"4bd352a341a940068dc6e449f37ecbb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d46bd413217e4aecafcb60f108736776","placeholder":"​","style":"IPY_MODEL_79d1f1343f3c41f7b54e115727c199c7","value":"Epoch [1/1], Valid Loss: 6.2296: 100%"}},"0f43c75d13224254a497689e312ff0f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57e20eb5afa84eddbb4636bb67335756","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a111b7deca7f44cdae5687410b87177e","value":20}},"bf0129c7c3c4446ea80d0c0e94d8425e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fc990c8e3f941248367a34ba9fbcf43","placeholder":"​","style":"IPY_MODEL_233a81482b054b0f8caa069f05bdcdee","value":" 20/20 [00:23&lt;00:00,  1.01s/it]"}},"7525c4940a864cc980a4e3bc5d8aad53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d46bd413217e4aecafcb60f108736776":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79d1f1343f3c41f7b54e115727c199c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57e20eb5afa84eddbb4636bb67335756":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a111b7deca7f44cdae5687410b87177e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fc990c8e3f941248367a34ba9fbcf43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"233a81482b054b0f8caa069f05bdcdee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# 디버깅"],"metadata":{"id":"LqtnQrHQ2CdP"}},{"cell_type":"markdown","source":["## 실습 개요\n","\n","1) **실습 목적**\n","\n","이 실습은 여러분이 PyTorch를 사용하여 딥러닝 모델을 개발하고 훈련하는 과정에서 발생할 수 있는 다양한 에러 상황을 이해하고, 이를 어떻게 해결할 수 있는지에 대해 배우는 것을 목표로 합니다. 특히, Custom Dataset과 Custom Model 구현, 그리고 학습 및 평가 시에 자주 발생하는 에러 상황을 중점적으로 다룹니다.\n","\n","\n","\n","2) **수강 목표**\n","\n","- Custom Dataset과 Custom Model을 구현하는 과정에서 발생하는 주요 에러를 이해하고 이를 해결할 수 있다.\n","- CUDA 메모리 문제를 이해하고, 이를 해결하는 방법을 배울 수 있다.\n","- 모델 학습 및 평가 시에 발생하는 다양한 에러 상황과 이를 해결하는 방법을 배울 수 있다."],"metadata":{"id":"h8l2Fx195bzp"}},{"cell_type":"markdown","source":["### 실습 목차\n","- 1. Custom Dataset 구현 시 에러\n","- 2. Custom Model 구현 시 에러\n","- 3. 학습 및 평가 시 에러\n","- 4. 흔한 실수 사례"],"metadata":{"id":"VEoniSz85ioV"}},{"cell_type":"markdown","source":["### ❗ 들어가기 전\n","\n","앞으로 PyTorch로 딥러닝 모델을 구현하면서 많은 에러들을 만나게 될 것 입니다. 에러들은 예상치 못한 상황, 코드의 오타, 런타임 오류, 그리고 버전 문제 등 다양한 문제에 의해 발생할 수 있습니다. 이런 경우에도 문제를 해결할 수 있는 능력을 키워야 합니다.\n","\n","실습에서 다루지 않은 에러가 발생한다면?\n","\n","1. 에러 메세지를 자세히 읽어보는 것은 매우 중요합니다. 에러 메세지를 읽어보는 것은 첫 걸음이며, Python과 PyTorch는 보통 **어디에서** **왜** 에러가 발생했는지를 나타내는 메세지를 제공합니다. 메세지를 이해하는 것은 때로 어려울 수 있지만, 이해하려고 노력하는 것이 중요합니다. 😎\n","\n","2. 구글에 키워드 기반으로 검색합니다. 거의 대부분의 에러는 다른 개발자들도 이미 접했고, 이런 문제를 해결하는 많은 정보를 인터넷을 통해 공유했습니다. 구글을 통해 답을 알게 된 후, 현재 자신의 코드와 비교해보며 어떤 실수로 인해 에러가 발생했는지 이해하려 한다면 큰 도움이 될 것입니다! 💪🏻"],"metadata":{"id":"f7H1RahW5kMj"}},{"cell_type":"markdown","source":["### 환경 설정\n","\n","- 패키지 설치 및 임포트"],"metadata":{"id":"gX0pcekYAyln"}},{"cell_type":"code","source":["!pip install torch==2.0.1 -q\n","!pip install torchtext==0.15.2 -q"],"metadata":{"id":"qGKwt2iS8Ovl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np # 기본적인 연산을 위한 라이브러리\n","from tqdm.notebook import tqdm # 상태 바를 나타내기 위한 라이브러리\n","\n","import torch # PyTorch 라이브러리\n","import torch.nn as nn # 모델 구성을 위한 라이브러리\n","import torch.optim as optim # optimizer 설정을 위한 라이브러리\n","from torch.utils.data import Dataset, DataLoader # 데이터셋 설정을 위한 라이브러리\n","\n","from torchtext.data import get_tokenizer # torch에서 tokenizer를 얻기 위한 라이브러리\n","import torchtext # torch에서 text를 더 잘 처리하기 위한 라이브러리\n","\n","from sklearn.metrics import accuracy_score # 성능지표 측정\n","from sklearn.model_selection import train_test_split # train-validation-test set 나누는 라이브러리\n","\n","import re # text 전처리를 위한 라이브러리\n","import pandas as pd # 테이블 데이터를 편리하게 처리하기 위한 라이브러리"],"metadata":{"id":"wUwDqn6qA1Gh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# seed 고정\n","import random\n","import torch.backends.cudnn as cudnn\n","\n","def random_seed(seed_num):\n","    torch.manual_seed(seed_num)\n","    torch.cuda.manual_seed(seed_num)\n","    torch.cuda.manual_seed_all(seed_num)\n","    np.random.seed(seed_num)\n","    cudnn.benchmark = False\n","    cudnn.deterministic = True\n","    random.seed(seed_num)\n","\n","random_seed(42)"],"metadata":{"id":"vqbaN6TSA4bt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###  데이터 셋 개요 </b>\n","\n","* 데이터셋: <a href='https://www.kaggle.com/datasets/dorianlazar/medium-articles-dataset'>Medium Dataset</a>\n","* 데이터셋 개요: \"Towards Data Science\", \"UX Collective\", \"The Startup\", \"The Writing Cooperative\", \"Data Driven Investor\", \"Better Humans\", \"Better Marketing\" 의 7개의 주제를 가지는 publication 에 대해서 크롤링을 한 데이터입니다. 원본 데이터는 총 6,508개의 블로그 이미지와 메타 데이터(.csv)로 구성됩니다. 실습에서는 메타데이터를 사용하여 CustomDataset을 구현합니다.\n","  * [How to collect ths dataset?](https://dorianlazar.medium.com/scraping-medium-with-python-beautiful-soup-3314f898bbf5)\n","- 메타 데이터 스키마: 메타 데이터는 총 **10**개의 column으로 구성됩니다.\n","  - id: 아이디\n","  - url: 포스팅 링크\n","  - title: 제목\n","  - subtitle: 부제목\n","  - image: 포스팅 이미지의 파일 이름\n","  - claps: 추천 수\n","  - reponses: 댓글 수\n","  - reading_time: 읽는데 걸리는 시간\n","  - publication: 주제 카테고리(e.g. Towards Data Science..)\n","  - date: 작성 날짜\n","- 데이터 셋 저작권: CC0: Public Domain\n","\n","\n"],"metadata":{"id":"A2le5RDL7n7w"}},{"cell_type":"markdown","source":["## 1. Custom Dataset 구현 시 에러\n","\n","```\n","💡 목차 개요: Custom Dataset을 구현하며 쉽게 접하는 에러를 알아봅니다.\n","```\n"],"metadata":{"id":"ZVop-Shw_QBw"}},{"cell_type":"code","source":["# google drive mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"F9i53UVnA54h","executionInfo":{"status":"ok","timestamp":1691293195925,"user_tz":-540,"elapsed":2188,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c40f3d7c-e8df-47b7-c38e-c314b9463abd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7nACn3OokeR","executionInfo":{"status":"ok","timestamp":1691293195926,"user_tz":-540,"elapsed":7,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"9042d135-7a53-495c-fdfa-0309b23a998e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["data_csv = pd.read_csv('medium_data.csv')\n","\n","# train set과 validation set, test set을 각각 나눕니다. 8 : 1 : 1 의 비율로 나눕니다.\n","train_csv, test_csv = train_test_split(data_csv, test_size = .2, random_state = 42)\n","val_csv, test_csv = train_test_split(test_csv, test_size = .5, random_state = 42)\n","\n","# index 를 reset 해줍니다.\n","train_csv = train_csv.reset_index(drop=True)\n","val_csv = val_csv.reset_index(drop=True)\n","test_csv = test_csv.reset_index(drop=True)\n","\n","print(\"Train 개수: \", len(train_csv))\n","print(\"Validation 개수: \", len(val_csv))\n","print(\"Test 개수: \", len(test_csv))\n","\n","# 각각의 title만 추출합니다.\n","# 우리는 title의 첫 단어가 주어졌을 떄, 다음 단어를 예측하는 것을 수행할 것입니다.\n","data = data_csv['title'].values\n","train = train_csv['title'].values\n","val = val_csv['title'].values\n","test = test_csv['title'].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUFKk_DvA8Tv","executionInfo":{"status":"ok","timestamp":1691288267841,"user_tz":-540,"elapsed":312,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"026c5112-bd69-453a-b6ab-721fc48775e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train 개수:  5206\n","Validation 개수:  651\n","Test 개수:  651\n"]}]},{"cell_type":"markdown","source":["#### 📝 설명: `__len__` 메서드에서의 에러\n","Custom Dataset을 구현하며 `__len__` 메서드에서는 필수적으로 데이터의 총 개수를 반환해야 합니다. 하드 코딩을 한다면 코드의 재사용성이 낮아지게 됩니다.\n","\n","아래 코드에서는 `__len__` 메서드에서 반환하는 값을 총 개수가 아닌 숫자 값으로 작성했습니다.\n","\n","- `__len__` 반환 값이 데이터 수보다 적은 경우: 데이터 로더에서 반환하는 값만큼의 데이터를 사용하게 돼 모든 데이터를 사용하지 못합니다.\n","- `__len__` 반환 값이 데이터 수보다 많은 경우: 현재 가진 데이터의 최대 index보다 큰 값을 데이터 로더가 불러올 경우, 해당 index의 데이터를 찾지 못해 IndexError가 발생합니다.\n","\n","\n","📚 구글 검색 키워드: `pytorch custom dataset 인덱스 에러`\n"],"metadata":{"id":"cdrzlWFMDIsl"}},{"cell_type":"code","source":["def cleaning_text(text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text)\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ')\n","    cleaned_text = cleaned_text.replace('\\u200a',' ')\n","    return cleaned_text\n","\n","def make_word_dic(data, tokenizer):\n","    cleaned_data = map(cleaning_text, data)\n","    vocab = torchtext.vocab.build_vocab_from_iterator(map(tokenizer, cleaned_data))\n","    vocab.insert_token('<pad>',0)\n","    word_to_id = dict(sorted(vocab.get_stoi().items(), key=lambda item: item[1]))\n","    return word_to_id"],"metadata":{"id":"ETPsvPtUrDME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Medium 데이터를 사용하여 Custom Dataset을 구축합니다.\n","# 아래의 코드는 __len__ 메서드 반환 값이 잘못된 경우입니다.\n","class CustomDataset(Dataset):\n","  def __init__(self, data, word_to_id, tokenizer, max_len):\n","    self.data = list(map(self.cleaning_text, data))\n","    self.word_to_id = word_to_id # 단어 사전 불러오기\n","    self.max_len = max_len\n","    self.tokenizer = tokenizer\n","    seq = self.make_sequence(self.data, self.word_to_id, self.tokenizer) # next word prediction을 하기 위한 형태로 변환\n","    self.seq = self.pre_zeropadding(seq, self.max_len) # zero padding으로 채워줌\n","    self.X = torch.tensor(self.seq[:,:-1])\n","    self.label = torch.tensor(self.seq[:,-1])\n","\n","  def cleaning_text(self, text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text) # 특수문자 를 모두 지우는 작업을 수행합니다.\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # non-breaking space를 unicode 빈칸으로 변환\n","    cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode 빈칸을 빈칸으로 변환\n","    return cleaned_text\n","\n","  def make_sequence(self, data, word_to_id, tokenizer):\n","    seq = []\n","    for i in data:\n","      token_id = list(map(lambda x: word_to_id[x], tokenizer(i)))\n","      for j in range(1, len(token_id)):\n","        sequence = token_id[:j+1]\n","        seq.append(sequence)\n","    return seq\n","\n","  def pre_zeropadding(self, seq, max_len): # max_len 길이에 맞춰서 0 으로 padding 처리 (앞부분에 padding 처리)\n","    return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","  def __len__(self): # dataset의 전체 길이 반환\n","    return 50000  # len(self.X)\n","\n","  def __getitem__(self, idx): # dataset 접근\n","    X = self.X[idx]\n","    label = self.label[idx]\n","\n","    return X, label\n","\n","batch_size = 32\n","tokenizer = get_tokenizer(\"basic_english\")\n","word_to_id = make_word_dic(data, tokenizer)\n","max_len = 37\n","train_dataset = CustomDataset(train, word_to_id, tokenizer, max_len)\n","train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = False, drop_last = False)\n","\n","for text, labels in train_dataloader:\n","  pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"lsPFPonTo0bJ","executionInfo":{"status":"error","timestamp":1691289189400,"user_tz":-540,"elapsed":778,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"8e40a0bc-b293-4256-9af0-d206c27e102c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-0bb5656dd646>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-0bb5656dd646>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# dataset 접근\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 39021 is out of bounds for dimension 0 with size 39021"]}]},{"cell_type":"code","source":["# Medium 데이터를 사용하여 Custom Dataset을 구축합니다.\n","# 아래의 코드는 __len__ 메서드 반환 값이 잘못된 경우입니다.\n","class CustomDataset(Dataset):\n","  def __init__(self, data, word_to_id, tokenizer, max_len):\n","    self.data = list(map(self.cleaning_text, data))\n","    self.word_to_id = word_to_id # 단어 사전 불러오기\n","    self.max_len = max_len\n","    self.tokenizer = tokenizer\n","    seq = self.make_sequence(self.data, self.word_to_id, self.tokenizer) # next word prediction을 하기 위한 형태로 변환\n","    self.seq = self.pre_zeropadding(seq, self.max_len) # zero padding으로 채워줌\n","    self.X = torch.tensor(self.seq[:,:-1])\n","    self.label = torch.tensor(self.seq[:,-1])\n","\n","  def cleaning_text(self, text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text) # 특수문자 를 모두 지우는 작업을 수행합니다.\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # non-breaking space를 unicode 빈칸으로 변환\n","    cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode 빈칸을 빈칸으로 변환\n","    return cleaned_text\n","\n","  def make_sequence(self, data, word_to_id, tokenizer):\n","    seq = []\n","    for i in data:\n","      token_id = list(map(lambda x: word_to_id[x], tokenizer(i)))\n","      for j in range(1, len(token_id)):\n","        sequence = token_id[:j+1]\n","        seq.append(sequence)\n","    return seq\n","\n","  def pre_zeropadding(self, seq, max_len): # max_len 길이에 맞춰서 0 으로 padding 처리 (앞부분에 padding 처리)\n","    return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","  def __len__(self): # dataset의 전체 길이 반환\n","    return len(self.X)\n","\n","  def __getitem__(self, idx): # dataset 접근\n","    X = self.X[idx]\n","    label = self.label[idx]\n","\n","    return X, label\n","\n","batch_size = 32\n","tokenizer = get_tokenizer(\"basic_english\")\n","word_to_id = make_word_dic(data, tokenizer)\n","max_len = 37\n","train_dataset = CustomDataset(train, word_to_id, tokenizer, max_len)\n","train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = False, drop_last = False)\n","\n","for text, labels in train_dataloader:\n","  pass"],"metadata":{"id":"7n0_xr2pIGJn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 📝 설명: `__getitem__` 메서드에서의 에러\n","위의 에러 상황과 같은 맥락으로 Custom Dataset 구현 시 IndexError는 자주 발생하는 에러 중 하나입니다. `__getitem__` 메서드 작성 시에도 주어진 데이터 수보다 초과하는 인덱스에 접근한다면, IndexError가 발생합니다.\n"],"metadata":{"id":"s-3_U3reIo-_"}},{"cell_type":"code","source":["# 아래의 코드는 __getitem__ 메서드에서 index를 잘못 접근한 경우입니다.\n","class CustomDataset(Dataset):\n","  def __init__(self, data, word_to_id, tokenizer, max_len):\n","    self.data = list(map(self.cleaning_text, data))\n","    self.word_to_id = word_to_id # 단어 사전 불러오기\n","    self.max_len = max_len\n","    self.tokenizer = tokenizer\n","    seq = self.make_sequence(self.data, self.word_to_id, self.tokenizer) # next word prediction을 하기 위한 형태로 변환\n","    self.seq = self.pre_zeropadding(seq, self.max_len) # zero padding으로 채워줌\n","    self.X = torch.tensor(self.seq[:,:-1])\n","    self.label = torch.tensor(self.seq[:,-1])\n","\n","  def cleaning_text(self, text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text) # 특수문자 를 모두 지우는 작업을 수행합니다.\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # non-breaking space를 unicode 빈칸으로 변환\n","    cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode 빈칸을 빈칸으로 변환\n","    return cleaned_text\n","\n","  def make_sequence(self, data, word_to_id, tokenizer):\n","    seq = []\n","    for i in data:\n","      token_id = list(map(lambda x: word_to_id[x], tokenizer(i)))\n","      for j in range(1, len(token_id)):\n","        sequence = token_id[:j+1]\n","        seq.append(sequence)\n","    return seq\n","\n","  def pre_zeropadding(self, seq, max_len): # max_len 길이에 맞춰서 0 으로 padding 처리 (앞부분에 padding 처리)\n","    return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","  def __len__(self): # dataset의 전체 길이 반환\n","    return len(self.X)\n","\n","  def __getitem__(self, idx): # dataset 접근\n","    # 전처리된 데이터(self.X)가 아닌 원시 데이터(self.data)에 접근하는 상황을 가정합니다.\n","\n","    X = self.data[idx] # DataLoader에서 인자로 주는 idx보다 self.data의 크기가 작기 때문에 에러 발생\n","    label = self.label[idx]\n","\n","    return X, label\n","\n","batch_size = 32\n","tokenizer = get_tokenizer(\"basic_english\")\n","word_to_id = make_word_dic(data, tokenizer)\n","max_len = 37\n","train_dataset = CustomDataset(train, word_to_id, tokenizer, max_len)\n","train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = False, drop_last = False)\n","\n","for text, labels in train_dataloader:\n","  pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"VnEJscoSJdS9","executionInfo":{"status":"error","timestamp":1691289373764,"user_tz":-540,"elapsed":616,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"63877f98-63fe-4b3b-d892-4df731b3365b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-4a2babef310d>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-4a2babef310d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# dataset 접근\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# 전처리된 데이터(self.X)가 아닌 원시 데이터(self.data)에 접근하는 상황을 가정합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","source":["# 올바르게 수정된 코드\n","class CustomDataset(Dataset):\n","  def __init__(self, data, word_to_id, tokenizer, max_len):\n","    self.data = list(map(self.cleaning_text, data))\n","    self.word_to_id = word_to_id # 단어 사전 불러오기\n","    self.max_len = max_len\n","    self.tokenizer = tokenizer\n","    seq = self.make_sequence(self.data, self.word_to_id, self.tokenizer) # next word prediction을 하기 위한 형태로 변환\n","    self.seq = self.pre_zeropadding(seq, self.max_len) # zero padding으로 채워줌\n","    self.X = torch.tensor(self.seq[:,:-1])\n","    self.label = torch.tensor(self.seq[:,-1])\n","\n","\n","  def cleaning_text(self, text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text) # 특수문자 를 모두 지우는 작업을 수행합니다.\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # non-breaking space를 unicode 빈칸으로 변환\n","    cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode 빈칸을 빈칸으로 변환\n","    return cleaned_text\n","\n","  def make_sequence(self, data, word_to_id, tokenizer):\n","    seq = []\n","    for i in data:\n","      token_id = list(map(lambda x: word_to_id[x], tokenizer(i)))\n","      for j in range(1, len(token_id)):\n","        sequence = token_id[:j+1]\n","        seq.append(sequence)\n","    return seq\n","\n","  def pre_zeropadding(self, seq, max_len): # max_len 길이에 맞춰서 0 으로 padding 처리 (앞부분에 padding 처리)\n","    return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","\n","  def __len__(self): # dataset의 전체 길이 반환\n","    return len(self.X)\n","\n","  def __getitem__(self, idx): # dataset 접근\n","    X = self.X[idx]\n","    label = self.label[idx]\n","\n","    return X, label\n","\n","batch_size = 32\n","tokenizer = get_tokenizer(\"basic_english\")\n","word_to_id = make_word_dic(data, tokenizer)\n","max_len = 37\n","train_dataset = CustomDataset(train, word_to_id, tokenizer, max_len)\n","train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = False, drop_last = False)\n","\n","for text, labels in train_dataloader:\n","  pass"],"metadata":{"id":"ttDT2O0sKh0y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 📝 설명: `__getitem__`에서 데이터 타입을 제대로 변환하지 않은 경우\n","\n","TypeError는 PyTorch의 특정 레이어나 함수에서 요구하는 데이터 타입과 입력 데이터의 타입이 일치 하지 않을 때 주로 발생합니다.\n","예를 들어 `nn.Embedding` 레이어는 입력으로 long 타입의 tensor를 요구하는데, float 타입의 tensor를 입력하면 type 문제로 인한 `RuntimeError`가 발생합니다.\n","\n","\n","📚 구글 검색 키워드: nn.Embedding Runtime Error\n"],"metadata":{"id":"74y6G5uAMjvB"}},{"cell_type":"code","source":["# float 타입의 데이터를 반환하는 Dataset\n","class CustomDataset(Dataset):\n","  def __init__(self, data, word_to_id, tokenizer, max_len):\n","    self.data = list(map(self.cleaning_text, data))\n","    self.word_to_id = word_to_id # 단어 사전 불러오기\n","    self.max_len = max_len\n","    self.tokenizer = tokenizer\n","    seq = self.make_sequence(self.data, self.word_to_id, self.tokenizer) # next word prediction을 하기 위한 형태로 변환\n","    self.seq = self.pre_zeropadding(seq, self.max_len) # zero padding으로 채워줌\n","\n","    \"\"\"\n","    데이터를 처리하는 과정에서 데이터 타입이 맞지 않는 경우(e.g. Embedding Layer를 통과하는 데 사용되는 데이터가 torch.float인 경우)\n","    \"\"\"\n","    self.X = self.seq[:,:-1].astype(float) # float 타입의 numpy array\n","    self.label = self.seq[:,-1].astype(float)\n","\n","  def cleaning_text(self, text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text) # 특수문자 를 모두 지우는 작업을 수행합니다.\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # non-breaking space를 unicode 빈칸으로 변환\n","    cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode 빈칸을 빈칸으로 변환\n","    return cleaned_text\n","\n","  def make_sequence(self, data, word_to_id, tokenizer):\n","    seq = []\n","    for i in data:\n","      token_id = list(map(lambda x: word_to_id[x], tokenizer(i)))\n","      for j in range(1, len(token_id)):\n","        sequence = token_id[:j+1]\n","        seq.append(sequence)\n","    return seq\n","\n","  def pre_zeropadding(self, seq, max_len): # max_len 길이에 맞춰서 0 으로 padding 처리 (앞부분에 padding 처리)\n","    return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","  def __len__(self): # dataset의 전체 길이 반환\n","    return len(self.X)\n","\n","  def __getitem__(self, idx): # dataset 접근\n","    # numpy array 타입의 데이터를 tensor로 변환\n","    X = torch.tensor(self.X[idx])\n","    label = torch.tensor(self.label[idx])\n","\n","    return X, label\n","\n","batch_size = 32\n","tokenizer = get_tokenizer(\"basic_english\")\n","word_to_id = make_word_dic(data, tokenizer)\n","max_len = 37\n","train_dataset = CustomDataset(train, word_to_id, tokenizer, max_len)\n","train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = False, drop_last = False)\n","\n","for text, labels in train_dataloader:\n","  pass\n","\n","layer = nn.Embedding(len(word_to_id), 128)\n","out = layer(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"4FpTiBE9MPcr","executionInfo":{"status":"error","timestamp":1691291223861,"user_tz":-540,"elapsed":2254,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"bf4a8fe5-fd03-4e03-e73c-a33b043b2962"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-bd3e049dbeae>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2208\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.DoubleTensor instead (while checking arguments for embedding)"]}]},{"cell_type":"code","source":["# 올바르게 수정된 코드\n","class CustomDataset(Dataset):\n","  def __init__(self, data, word_to_id, tokenizer, max_len):\n","    self.data = list(map(self.cleaning_text, data))\n","    self.word_to_id = word_to_id # 단어 사전 불러오기\n","    self.max_len = max_len\n","    self.tokenizer = tokenizer\n","    seq = self.make_sequence(self.data, self.word_to_id, self.tokenizer) # next word prediction을 하기 위한 형태로 변환\n","    self.seq = self.pre_zeropadding(seq, self.max_len) # zero padding으로 채워줌\n","\n","    \"\"\"\n","    데이터를 처리하는 과정에서 데이터 타입이 맞지 않는 경우(e.g. Embedding Layer를 통과하는 데 사용되는 데이터가 torch.float인 경우)\n","    아래의 실습 예시에서는 __getitem__에서 torch.long 데이터 타입으로 변경\n","    \"\"\"\n","    self.X = self.seq[:,:-1].astype(float)\n","    self.label = self.seq[:,-1].astype(float)\n","\n","\n","  def cleaning_text(self, text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text) # 특수문자 를 모두 지우는 작업을 수행합니다.\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # non-breaking space를 unicode 빈칸으로 변환\n","    cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode 빈칸을 빈칸으로 변환\n","    return cleaned_text\n","\n","  def make_sequence(self, data, word_to_id, tokenizer):\n","    seq = []\n","    for i in data:\n","      token_id = list(map(lambda x: word_to_id[x], tokenizer(i)))\n","      for j in range(1, len(token_id)):\n","        sequence = token_id[:j+1]\n","        seq.append(sequence)\n","    return seq\n","\n","  def pre_zeropadding(self, seq, max_len): # max_len 길이에 맞춰서 0 으로 padding 처리 (앞부분에 padding 처리)\n","    return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","\n","  def __len__(self): # dataset의 전체 길이 반환\n","    return len(self.X)\n","\n","  def __getitem__(self, idx): # dataset 접근\n","    X = torch.tensor(self.X[idx], dtype = torch.long)\n","    label = torch.tensor(self.label[idx], dtype = torch.long)\n","\n","    return X, label\n","\n","batch_size = 32\n","tokenizer = get_tokenizer(\"basic_english\")\n","word_to_id = make_word_dic(data, tokenizer)\n","max_len = 37\n","train_dataset = CustomDataset(train, word_to_id, tokenizer, max_len)\n","train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = False, drop_last = False)\n","\n","for text, labels in train_dataloader:\n","  pass\n","\n","layer = nn.Embedding(len(word_to_id), 128)\n","out = layer(text)"],"metadata":{"id":"QgMrTpySOonx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 📝 설명: Dimension Error\n","\n","일반적으로 PyTorch에서 CNN 레이어는 입력 데이터의 차원을 B $\\times$ C $\\times$ H $\\times$ W(B: 미니 배치 크기, C: 채널 수, H: 높이, W: 너비)로 입력 받습니다.(배치가 아닌 경우, C $\\times$ H $\\times$ W도 가능합니다.) 만약 이 차원과 일치하지 않는 데이터를 입력한다면, `Dimension Error`가 발생합니다.\n","\n","\n","📚 구글 검색 키워드: 에러 메세지\n"],"metadata":{"id":"pXOd9x4AP3ZK"}},{"cell_type":"code","source":["# 입력 tensor의 차원이 맞지 않는 경우\n","conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\n","inputs = torch.randn(28, 28)  # 차원이 HxW\n","out = conv(inputs)  # 에러 발생: expected 4D input (got 3D input)\n","out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"HYclcB0PPkJB","executionInfo":{"status":"error","timestamp":1690141112942,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"f30e7dbc-0958-449c-862f-8745a00a205f"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-e79558492e96>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 차원이 HxW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 에러 발생: expected 4D input (got 3D input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [28, 28]"]}]},{"cell_type":"code","source":["# 올바르게 구현된 코드\n","conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\n","inputs_3d = torch.randn(1, 28, 28)  # 차원이 HxW\n","out = conv(inputs_3d)  # 에러 발생: expected 4D input (got 3D input)\n","\n","inputs_4d = torch.randn(1, 1, 28, 28)  # 차원이 HxW\n","out = conv(inputs_4d)"],"metadata":{"id":"4zqnNqcGQ6sf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Custom Model 구현 시 에러\n","\n","```\n","💡 목차 개요: 딥러닝 모델의 구조를 직접 설계하는 경우 발생할 수 있는 에러에 대해 알아봅니다.\n","```\n"],"metadata":{"id":"F14iDOXSTcPL"}},{"cell_type":"markdown","source":["#### 📝 설명: Dimension mistmatch error\n","\n","mismatch error는 네트워크의 한 layer에서 다음 layer로 데이터를 전달할 때 입력 데이터의 차원과 계층이 기대하는 차원이 일치하지 않을 때 발생합니다. 주로 잘못된 계층 구성 또는 데이터 전처리로 인해 발생합니다.\n","\n","\n","📚 구글 검색 키워드: 에러 메세지\n"],"metadata":{"id":"8heq3_rXTjQS"}},{"cell_type":"code","source":["# mistmath error가 발생하는 코드\n","class CNN(nn.Module):\n","    def __init__(self, num_classes, dropout_ratio):\n","        super(CNN,self).__init__()\n","        self.num_classes = num_classes\n","\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5),  # [1,28,28] -> [16,24,24]\n","            nn.ReLU(),  # ReLU 활성화 함수 적용\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5), # [16,24,24] -> [32,20,20]\n","            nn.ReLU(),  # ReLU 활성화 함수 적용\n","            nn.MaxPool2d(kernel_size=2), # [32,20,20] -> [32,10,10]\n","            nn.Dropout(dropout_ratio),\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5), # [32,10,10] -> [64,6,6]\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2), # 크기를 1/2로 줄입니다. [64,6,6] -> [64,3,3]\n","            nn.Dropout(dropout_ratio),\n","        )\n","\n","        self.fc_layer = nn.Linear(64*5*5, self.num_classes) # [64*3*3] 차원을 입력으로 받아야 하나, 잘못된 입력 구성\n","        self.softmax = nn.LogSoftmax(dim = 1)\n","\n","\n","    def forward(self,x):\n","        \"\"\"\n","        Input and Output Summary\n","\n","        Input:\n","          x: [batch_size, 1, 28, 28]\n","        Output:\n","          output: [batch_size, num_classes]\n","\n","        \"\"\"\n","        out = self.layer(x) # [batch_size, 64, 3, 3]\n","        out = out.view(x.shape[0], -1) # [batch_size, 64, 576]\n","        pred = self.fc_layer(out) # mis-match\n","        pred = self.softmax(pred)\n","\n","        return pred\n","\n","model = CNN(num_classes = 10, dropout_ratio = 0.2)\n","input = torch.randn(1, 1, 28, 28)\n","output = model(input)  # this will cause RuntimeError"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"id":"vcpD-hwzTfxV","executionInfo":{"status":"error","timestamp":1690277038570,"user_tz":-540,"elapsed":1692,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"c360d3f5-8f98-4675-fd72-da1bb565e985"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-acd7ff29ad46>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# this will cause RuntimeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-acd7ff29ad46>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x576 and 1600x10)"]}]},{"cell_type":"code","source":["# fully connected layer에서 mismatch error가 발생할 경우, 아래의 반복문을 통해 어떤 레이어에서 에러 메세지가 발생했는지 비교하여 확인할 수 있습니다.\n","for name, layer in model.named_modules():\n","    if isinstance(layer, torch.nn.Linear):\n","        print(f\"Layer {name}: {layer.in_features} -> {layer.out_features}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_1AlAnNWlmv","executionInfo":{"status":"ok","timestamp":1690277043890,"user_tz":-540,"elapsed":568,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"b1cb9e1b-b351-4172-c028-da0a8a0c8553"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Layer fc_layer: 1600 -> 10\n"]}]},{"cell_type":"code","source":["# 올바르게 구현된 코드\n","class CNN(nn.Module):\n","    def __init__(self, num_classes, dropout_ratio):\n","        super(CNN,self).__init__()\n","        self.num_classes = num_classes\n","\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5),  # [1,28,28] -> [16,24,24]\n","            nn.ReLU(),  # ReLU 활성화 함수 적용\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5), # [16,24,24] -> [32,20,20]\n","            nn.ReLU(),  # ReLU 활성화 함수 적용\n","            nn.MaxPool2d(kernel_size=2), # [32,20,20] -> [32,10,10]\n","            nn.Dropout(dropout_ratio),\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5), # [32,10,10] -> [64,6,6]\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2), # 크기를 1/2로 줄입니다. [64,6,6] -> [64,3,3]\n","            nn.Dropout(dropout_ratio),\n","        )\n","\n","        self.fc_layer = nn.Linear(64*3*3, self.num_classes) # [64*3*3]\n","        self.softmax = nn.LogSoftmax(dim = 1)\n","\n","\n","    def forward(self,x):\n","        \"\"\"\n","        Input and Output Summary\n","\n","        Input:\n","          x: [batch_size, 1, 28, 28]\n","        Output:\n","          output: [batch_size, num_classes]\n","\n","        \"\"\"\n","        out = self.layer(x) # [batch_size, 64, 3, 3]\n","        out = out.view(x.shape[0], -1) # [batch_size, 576]\n","        pred = self.fc_layer(out) # [batch_size, 10]\n","        pred = self.softmax(pred) # [batch_size, 10]\n","\n","        return pred\n","\n","model = CNN(num_classes = 10, dropout_ratio = 0.2)\n","input = torch.randn(1, 1, 28, 28)\n","output = model(input)"],"metadata":{"id":"0PoClmOoUXLs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 📝 설명: Tensor manipulation\n","\n","Dimension mismath error와 같은 맥락으로 특정 레이어 통과 후 데이터의 차원을 고려하여 적절하게 조작해줘야 하는 경우가 많습니다. 예시로 Global Average Pooling을 사용하면 B $\\times$ C $\\times$ H $\\times$ W의 입력 tensor는 B $\\times$ C $\\times$ 1 $\\times$ 1로 변환 됩니다.\n","\n","이 경우, 다음 layer인 fully connected layer와 연산하기 위해서는 적절하게 tensor의 차원을 조작해줘야 합니다. 그렇지 않을 경우 dimension mismatch error가 발생합니다.\n"],"metadata":{"id":"bB6akOVSWiRu"}},{"cell_type":"code","source":["class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Conv2d(1, 10, kernel_size=5)\n","        self.gap = nn.AdaptiveAvgPool2d(1) # 1x1 Global Average Pooling\n","        self.fc = nn.Linear(10, 10)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Input and Output Summary\n","\n","        Input:\n","          x: [batch_size, 1, 28, 28]\n","        Output:\n","          output: [batch_size, 10]\n","\n","        \"\"\"\n","        x = self.conv(x) # [batch_size, 10, 24, 24]\n","        x = self.gap(x) # [batch_size, 10, 1, 1]\n","        # x = x.view(x.size(0), -1) view를 사용하지 않아 4 dimension이 계속 유지되는 경우\n","        # mis-match\n","        x = self.fc(x)\n","        return x\n","\n","net = Model()\n","input = torch.randn(1, 1, 28, 28)\n","output = net(input)  # This will cause RuntimeError due to mismatch in dimension\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"id":"viHnrMwHUx0t","executionInfo":{"status":"error","timestamp":1690142845591,"user_tz":-540,"elapsed":297,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"d0bdb2b3-9dcc-4318-d842-cb74bec3ac45"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-68-89491a1c99fa>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This will cause RuntimeError due to mismatch in dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-68-89491a1c99fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, C, 1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# x = x.view(x.size(0), -1) view를 사용하지 않아 4 dimension이 계속 유지되는 경우\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x1 and 10x10)"]}]},{"cell_type":"code","source":["class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Conv2d(1, 10, kernel_size=5)\n","        self.gap = nn.AdaptiveAvgPool2d(1) # 1x1 Global Average Pooling\n","        self.fc = nn.Linear(10, 10)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Input and Output Summary\n","\n","        Input:\n","          x: [batch_size, 1, 28, 28]\n","        Output:\n","          output: [batch_size, 10]\n","\n","        \"\"\"\n","        x = self.conv(x) # [batch_size, 10, 24, 24]\n","        x = self.gap(x) # [batch_size, 10, 1, 1]\n","\n","        x = x.view(x.size(0), -1) # [batch_size, 10]\n","        x = self.fc(x) # [batch_size, 10]\n","        return x\n","\n","net = Model()\n","input = torch.randn(1, 1, 28, 28)\n","output = net(input)\n"],"metadata":{"id":"FhFkV0yKWmmG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. 학습 및 평가 시 에러\n","\n","```\n","💡 목차 개요: 학습 및 평가 단계에서 발생하는 에러에 대해 알아봅니다.\n","```\n"],"metadata":{"id":"mzpLBLKiZexB"}},{"cell_type":"markdown","source":["#### 📝 설명: CUDA RAM out of memory\n","\n","GPU의 메모리는 한정적이기에 모델을 학습할 때, GPU 메모리 사용량에 주의하며 학습 코드를 작성해야 합니다. 딥러닝 모델을 학습할 때, GPU RAM을 사용하는 경우는 다음과 같습니다.\n","\n","- 미니 배치 데이터\n","- 모델의 파라미터\n","- 역전파 수행을 위한 각 레이어의 출력 결과물\n","\n","CUDA RAM out of memory 에러가 발생했을 경우, 대표적인 해결 방법은 다음과 같습니다.\n","1. **batch_size 감소**: 미니 배치의 크기를 줄이면, 미니 배치 데이터 및 각 레이어의 출력 결과물의 메모리 사용량 또한 줄어들게 됩니다.\n","2. **torch.cuda.empty_cache 메서드 호출**: PyTorch에서 CUDA RAM 캐시를 비우는 메서드입니다. PyTorch는 CUDA를 사용하여 GPU 연산을 수행하는데, 이 과정에서 메모리 관리를 효율적으로 하기 위해 일부 CUDA RAM을 캐싱합니다. `torch.cuda.empty_cache` 메서드를 호출하면 캐싱된 데이터를 비우게 되며 이를 통해 CUDA RAM을 확보할 수 있습니다.\n","\n","\n","📚 구글 검색 키워드: cuda out of memory 해결\n"],"metadata":{"id":"6so7XvxKbaJv"}},{"cell_type":"code","source":["data_csv = pd.read_csv('medium_data.csv')\n","\n","# train set과 validation set, test set을 각각 나눕니다. 8 : 1 : 1 의 비율로 나눕니다.\n","train_csv, test_csv = train_test_split(data_csv, test_size = .2, random_state = 42)\n","val_csv, test_csv = train_test_split(test_csv, test_size = .5, random_state = 42)\n","\n","# index 를 reset 해줍니다.\n","train_csv = train_csv.reset_index(drop=True)\n","val_csv = val_csv.reset_index(drop=True)\n","test_csv = test_csv.reset_index(drop=True)\n","\n","print(\"Train 개수: \", len(train_csv))\n","print(\"Validation 개수: \", len(val_csv))\n","print(\"Test 개수: \", len(test_csv))\n","\n","# 각각의 title만 추출합니다.\n","# 우리는 title의 첫 단어가 주어졌을 떄, 다음 단어를 예측하는 것을 수행할 것입니다.\n","data = data_csv['title'].values\n","train = train_csv['title'].values\n","val = val_csv['title'].values\n","test = test_csv['title'].values"],"metadata":{"id":"pm6-psfvftz8","executionInfo":{"status":"ok","timestamp":1691293196471,"user_tz":-540,"elapsed":5,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dc5c6313-5d5a-43ab-aace-f974a04f51bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train 개수:  5206\n","Validation 개수:  651\n","Test 개수:  651\n"]}]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, data, word_to_id, tokenizer, max_len):\n","        self.data = list(map(cleaning_text, data))\n","        self.word_to_id = word_to_id # 단어 사전 불러오기\n","        self.max_len = max_len\n","        self.tokenizer = tokenizer\n","        seq = self.make_sequence(self.data, self.word_to_id, self.tokenizer) # next word prediction을 하기 위한 형태로 변환\n","        self.seq = self.pre_zeropadding(seq, self.max_len) # zero padding으로 채워줌\n","        self.X = torch.tensor(self.seq[:,:-1])\n","        self.label = torch.tensor(self.seq[:,-1])\n","\n","    def cleaning_text(self, text):\n","        cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text) # 특수문자 를 모두 지우는 작업을 수행합니다.\n","        cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # non-breaking space를 unicode 빈칸으로 변환\n","        cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode 빈칸을 빈칸으로 변환\n","        return cleaned_text\n","\n","    def make_sequence(self, data, word_to_id, tokenizer):\n","        seq = []\n","        for i in data:\n","            token_id = list(map(lambda x: word_to_id[x], tokenizer(i)))\n","            for j in range(1, len(token_id)):\n","                sequence = token_id[:j+1]\n","                seq.append(sequence)\n","        return seq\n","\n","    def pre_zeropadding(self, seq, max_len): # max_len 길이에 맞춰서 0 으로 padding 처리 (앞부분에 padding 처리)\n","        return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","    def __len__(self): # dataset의 전체 길이 반환\n","        return len(self.X)\n","\n","    def __getitem__(self, idx): # dataset 접근\n","        X = self.X[idx]\n","        label = self.label[idx]\n","\n","        return X, label"],"metadata":{"id":"x_U2b_5EfwwO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cleaning_text(text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text)\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ')\n","    cleaned_text = cleaned_text.replace('\\u200a',' ')\n","    return cleaned_text\n","\n","def make_word_dic(data, tokenizer):\n","    cleaned_data = map(cleaning_text, data)\n","    vocab = torchtext.vocab.build_vocab_from_iterator(map(tokenizer, cleaned_data))\n","    vocab.insert_token('<pad>',0)\n","    word_to_id = dict(sorted(vocab.get_stoi().items(), key=lambda item: item[1]))\n","    return word_to_id"],"metadata":{"id":"Gb9nRtILbZZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = get_tokenizer(\"basic_english\")\n","word_to_id = make_word_dic(data, tokenizer)\n","max_len = 30\n","batch_size = 4096\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') # gpu 설정\n","\n","train_dataset = CustomDataset(train, word_to_id, tokenizer, max_len)\n","valid_dataset = CustomDataset(val, word_to_id, tokenizer, max_len)\n","test_dataset = CustomDataset(test, word_to_id, tokenizer, max_len)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n","valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = False)\n","test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"],"metadata":{"id":"1c-b4la217T3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LSTM(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size):\n","        super(LSTM, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True, num_layers = 2)\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Input and Output Summary\n","\n","        Input:\n","          x: [batch_size, max_len]\n","        Output:\n","          output: [batch_size, vocab_size]\n","\n","        \"\"\"\n","        x = self.embedding(x) # [batch_size, max_len, embedding_dim]\n","        output, _ = self.lstm(x) # [batch_size, max_len, hidden_size]\n","        output = output[:, -1, :] # [batch_size, hidden_size]\n","        output = self.fc(output) # [batch_size, vocab_size]\n","        return output"],"metadata":{"id":"qNHb_0Pn2w_J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training 코드, evaluation 코드, training_loop 코드\n","def training(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs):\n","    model.train()  # 모델을 학습 모드로 설정\n","    train_loss = 0.0\n","    train_accuracy = 0\n","\n","    tbar = tqdm(dataloader)\n","    for texts, labels in tbar:\n","        texts = texts.to(device)\n","        labels = labels.to(device)\n","        # 순전파\n","        outputs = model(texts)\n","\n","        loss = criterion(outputs, labels)\n","\n","        # 역전파 및 가중치 업데이트\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # 손실과 정확도 계산\n","        train_loss += loss.item()\n","        # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n","        _, predicted = torch.max(outputs, dim=1)\n","\n","\n","        train_accuracy += (predicted == labels).sum().item()\n","\n","        # tqdm의 진행바에 표시될 설명 텍스트를 설정\n","        tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}\")\n","\n","    # 에폭별 학습 결과 출력\n","    train_loss = train_loss / len(dataloader)\n","    train_accuracy = train_accuracy / len(train_dataset)\n","\n","    return model, train_loss, train_accuracy\n","\n","def evaluation(model, dataloader, valid_dataset, criterion, device, epoch, num_epochs):\n","    model.eval()  # 모델을 평가 모드로 설정\n","    valid_loss = 0.0\n","    valid_accuracy = 0\n","\n","    with torch.no_grad(): # model의 업데이트 막기\n","        tbar = tqdm(dataloader)\n","        for texts, labels in tbar:\n","            texts = texts.to(device)\n","            labels = labels.to(device)\n","\n","            # 순전파\n","            outputs = model(texts)\n","            loss = criterion(outputs, labels)\n","\n","            # 손실과 정확도 계산\n","            valid_loss += loss.item()\n","            # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n","            _, predicted = torch.max(outputs, 1)\n","            # _, true_labels = torch.max(labels, dim=1)\n","            valid_accuracy += (predicted == labels).sum().item()\n","\n","\n","            # tqdm의 진행바에 표시될 설명 텍스트를 설정\n","            tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Valid Loss: {loss.item():.4f}\")\n","\n","    valid_loss = valid_loss / len(dataloader)\n","    valid_accuracy = valid_accuracy / len(valid_dataset)\n","\n","    return model, valid_loss, valid_accuracy\n","\n","\n","def training_loop(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name):\n","    best_valid_loss = float('inf')  # 가장 좋은 validation loss를 저장\n","    early_stop_counter = 0  # 카운터\n","    valid_max_accuracy = -1\n","\n","    for epoch in range(num_epochs):\n","        model, train_loss, train_accuracy = training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\n","        model, valid_loss, valid_accuracy = evaluation(model, valid_dataloader, val_dataset, criterion, device, epoch, num_epochs)\n","\n","        if valid_accuracy > valid_max_accuracy:\n","            valid_max_accuracy = valid_accuracy\n","\n","        # validation loss가 감소하면 모델 저장 및 카운터 리셋\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            torch.save(model.state_dict(), f\"./model_{model_name}.pt\")\n","            early_stop_counter = 0\n","\n","        # validation loss가 증가하거나 같으면 카운터 증가\n","        else:\n","            early_stop_counter += 1\n","\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f} Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\")\n","\n","        # 조기 종료 카운터가 설정한 patience를 초과하면 학습 종료\n","        if early_stop_counter >= patience:\n","            print(\"Early stopping\")\n","            break\n","\n","    return model, valid_max_accuracy"],"metadata":{"id":"mQkq3kBge2zT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 진행 중 메모리 사용량을 확인합니다.\n","lr = 0.001\n","num_epochs = 1\n","patience = 3\n","model_name = 'LSTM'\n","\n","vocab_size = len(word_to_id)\n","embedding_dim = 4096\n","hidden_size = 4096\n","model = LSTM(vocab_size, embedding_dim, hidden_size).to(device)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index = 0)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","model, valid_max_accuracy = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":440,"referenced_widgets":["d327ee5bf5b740f9a0168996230b6cfb","5d0ef836c3a44a3e9ff8b0a227e3abdc","7ac73b08943d4ecda4e28b806cf1d0fc","0905c2e6e5d046beb756a381c9900589","f790999fc7cb477ca5613698615d4e6f","5ac08a2135d742098b9df667cf527383","23054ca7b6a646d2a4b97562765cadbe","c76ba883d3b548dd8928ba06dce2f7d4","9247eb218d214447bfc0473579337e72","14b8f642a1eb4be799508f65105d1fd2","60f5c65fef72482484821c9cee47d9a1"]},"id":"2ISTb3zMfBqg","executionInfo":{"status":"error","timestamp":1691292705449,"user_tz":-540,"elapsed":11547,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"fd15e59b-da1c-4f66-8017-9380cf4a00f6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d327ee5bf5b740f9a0168996230b6cfb"}},"metadata":{}},{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-1feda174053c>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_max_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-a3f14b50e52b>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-a3f14b50e52b>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# 순전파\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-f286809539eb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    813\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    814\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 10.77 GiB (GPU 0; 14.75 GiB total capacity; 8.49 GiB already allocated; 5.31 GiB free; 8.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["# batch_size 감소\n","batch_size = 256\n","\n","train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n","valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = False)\n","test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"],"metadata":{"id":"_PqouXBLgtvF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr = 0.001\n","num_epochs = 1\n","patience = 3\n","model_name = 'LSTM'\n","\n","vocab_size = len(word_to_id)\n","embedding_dim = 4096\n","hidden_size = 4096\n","model = LSTM(vocab_size, embedding_dim, hidden_size).to(device)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index = 0)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","model, valid_max_accuracy = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":98,"referenced_widgets":["305565c21ca34ba788d7eb87fe5817f6","8375ebff861e44bea59cfac1d214b194","aa68868934154c4e970b670212d25dcb","664407e80b2d4d358db674382803dc43","c66d2837eb814554b3d6eefde80adc62","34cfb887dd8f4d7ea32cf975dfcbfd39","096715831d3b42409b48362da7f1bd30","f2898fd1ae8b4cf7b42316d0bd621cc0","5c10324688034d47a55e90ac39989682","6368ec6b27f649f892831d17077053bd","f87166b68cbf4226a4cee26991c766c1","4335c20e43c4494e9844ced338fe93e5","4bd352a341a940068dc6e449f37ecbb7","0f43c75d13224254a497689e312ff0f8","bf0129c7c3c4446ea80d0c0e94d8425e","7525c4940a864cc980a4e3bc5d8aad53","d46bd413217e4aecafcb60f108736776","79d1f1343f3c41f7b54e115727c199c7","57e20eb5afa84eddbb4636bb67335756","a111b7deca7f44cdae5687410b87177e","6fc990c8e3f941248367a34ba9fbcf43","233a81482b054b0f8caa069f05bdcdee"]},"id":"eDJjWAxIiAWK","executionInfo":{"status":"ok","timestamp":1691293917355,"user_tz":-540,"elapsed":710385,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"4405b4dd-281b-4364-fa8b-ca57bb13f88c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/153 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"305565c21ca34ba788d7eb87fe5817f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4335c20e43c4494e9844ced338fe93e5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch [1/1], Train Loss: 6.6701, Train Accuracy: 0.1253 Valid Loss: 6.2977, Valid Accuracy: 0.1483\n"]}]},{"cell_type":"code","source":["# 큰 사이즈의 텐서를 CUDA RAM에 할당합니다.\n","test_tensor = torch.randn((10000, 10000, 3)).to(device)"],"metadata":{"id":"aXL8nLGBjBt9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# torch.cuda.empty_cache() 실행 전\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xS0QSj5-iE2j","executionInfo":{"status":"ok","timestamp":1690364662185,"user_tz":-540,"elapsed":23,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"e19c9b24-2235-4b40-da58-b470e7de0ddd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Jul 26 09:44:21 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P0    32W /  70W |   1745MiB / 15360MiB |     32%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# test_tensor를 del 명령을 통해 'test_tensor' 객체를 삭제합니다.\n","del test_tensor\n","\n","# GPU 메모리 캐시를 비웁니다.\n","torch.cuda.empty_cache()"],"metadata":{"id":"18GFBrFEi9CL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# torch.cuda.empty_cache() 실행 후\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WLPkyV8YjciH","executionInfo":{"status":"ok","timestamp":1690364662186,"user_tz":-540,"elapsed":21,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"ae1a75f2-cf4f-462c-bef1-759a4589d314"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Jul 26 09:44:21 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P0    32W /  70W |    599MiB / 15360MiB |      4%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["#### 📝 설명: `detach`, `cpu`\n","PyTorch의 tensor는 기본적으로 gradient를 계산하고 역전파를 위한 정보를 가지고 있습니다. 이는 GPU 메모리에 추가적인 부담을 주며, 이 tensor를 NumPy 배열로 변환하려고 하면 에러가 발생합니다.\n","\n","이를 해결하기 위해 'detach()'를 호출하여 gradient를 기록하지 않아야 합니다. 또한, tensor가 GPU에 있을 경우, CPU로 옮긴 후에 NumPy 배열로 변환해야 합니다.\n","\n","\n","📚 구글 검색 키워드: 에러 메세지\n","\n"],"metadata":{"id":"Wxad25P8mFCg"}},{"cell_type":"code","source":["pred = torch.tensor([1., 0., 1.], requires_grad = True)\n","label = torch.tensor([1., 0., 0.], requires_grad = True)\n","\n","pred = pred.numpy()\n","label = label.numpy()\n","\n","accuracy_score(label, pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"VQvK9GNrblp4","executionInfo":{"status":"error","timestamp":1690278718936,"user_tz":-540,"elapsed":444,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"5f226920-fdf6-4195-9338-76963b25f92b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-60d623d22480>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."]}]},{"cell_type":"code","source":["# 일반적으로 scikit learn metric 등 numpy ndarray를 입력으로 받는 함수들을 사용하기 위해 모델에서 연산된 결과물을 변환해야 합니다.\n","# requires_grad와 cuda tensor로 변경합니다.\n","pred = torch.tensor([1., 0., 1.]).to(device)\n","label = torch.tensor([1., 0., 0.]).to(device)\n","\n","pred = pred.numpy()\n","label = label.numpy()\n","\n","accuracy_score(label, pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"FDTwiLlhl9vY","executionInfo":{"status":"error","timestamp":1690278744619,"user_tz":-540,"elapsed":377,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"96c4a0c2-e574-49a4-981e-f1071d525ff6"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-45143f68146f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."]}]},{"cell_type":"code","source":["# 올바르게 구현된 코드\n","pred = torch.tensor([1., 0., 1.], requires_grad = True).to(device)\n","label = torch.tensor([1., 0., 0.], requires_grad = True).to(device)\n","\n","pred = pred.detach().cpu().numpy()\n","label = label.detach().cpu().numpy()\n","\n","accuracy_score(label, pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"isNGuIEeoIKx","executionInfo":{"status":"ok","timestamp":1690147310322,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"2a36eb2f-92a6-4f3d-ad2f-2a0ffbec73fb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6666666666666666"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## 4. 흔한 실수 사례\n","\n","```\n","💡 목차 개요: 딥러닝 모델을 구현하며 흔히 실수하는 내용을 알아봅니다.\n","   이번 섹션에서 실수하는 사례들은 코드적인 오류가 존재하지는 않기 때문에 에러 메세지가 발생하지 않습니다.\n","   하지만 실수에 따라 모델의 성능에 치명적으로 영향을 미칠 수 있습니다.\n","```\n"],"metadata":{"id":"rSFUv0VErBkd"}},{"cell_type":"markdown","source":["#### 📝 설명: 실수 사례\n","흔히 실수하는 사례로는 크게 세 가지가 존재합니다.\n","1. **random seed를 고정하지 않고 하이퍼 파라미터 튜닝**: 딥러닝 모델의 결과는 초기화와 같은 random 요소에 크게 영향을 받습니다. 모델의 학습이 매번 동일한 조건에서 시작되도록 하기 위해, 실험의 재현성을 보장하는 데 중요한 역할을 하는 random seed를 설정해야 합니다.\n","\n","2. **`optim.zero_grad()`를 하지 않는 경우**: PyTorch에서는 기본적으로 gradient가 누적되도록 설정되어 있습니다. 따라서 각 배치에서 역전파를 진행하기 전에 명시적으로 gradient를 0으로 설정하여 데이터가 누적되어 학습에 사용되지 않도록 해야 합니다.\n","\n","3. **evaluation 단계에서 `model.eval()`을 하지 않은 경우**: BatchNorm이나 Dropout 같은 일부 레이어는 훈련 모드와 평가 모드에서 다르게 동작합니다. 딥러닝 모델을 구현하다 보면, 학습 코드와 평가 코드를 나누어 두는 경우가 일반적인데, 평가 코드에서 모델을 로드하기만 한다면 BatchNorm, Dropout 등의 일부 레이어는 정상적으로 작동하지 않습니다. 그래서 평가 시에는 `model.eval()`을 꼭 호출하여 평가 모드로 전환하는 것이 중요합니다.\n","\n"],"metadata":{"id":"InZViRNZrrY0"}},{"cell_type":"code","source":["# 3번 사례에서 dropout 레이어를 모델로 가정하고 실습합니다.\n","# dropout layer에서는 tensor의 output이 '0'로 설정되기 때문에, 평가 시 사용할 때는 dropout을 비활성화 해야 합니다.\n","\n","model = nn.Dropout(0.5)\n","\n","# 랜덤하게 생성한 tensor\n","input_tensor = torch.randn(5, 10)\n","\n","# Dropout in Training Mode\n","model.train()\n","output_train = model(input_tensor)\n","print(\"Output in Training Mode: \\n\", output_train)\n","\n","print(\"\\n\")\n","# Dropout in Evaluation Mode\n","model.eval()\n","output_eval = model(input_tensor)\n","print(\"Output in Evaluation Mode: \\n\", output_eval)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4_Vs3yAMrpG3","executionInfo":{"status":"ok","timestamp":1690148819598,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍유환승[졸업생 / 바이오메디컬공학전공]","userId":"11562210152573735741"}},"outputId":"8d9bfe84-eec0-4daf-b2b1-e5612b594555"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Output in Training Mode: \n"," tensor([[-0.0000,  0.0800, -0.0000, -1.6276, -3.7987,  0.0000,  0.0224,  0.0000,\n","         -0.4158,  1.4847],\n","        [-0.0000, -0.0000, -1.5982, -0.2413, -0.0889,  2.8080, -0.0000,  0.0000,\n","         -1.9399, -0.0000],\n","        [ 0.9740,  0.0000,  0.0000,  1.6898, -0.4581,  0.0000, -0.0000, -1.2434,\n","         -2.6227,  0.0000],\n","        [ 0.0000, -1.0533,  1.1514,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000,\n","         -0.3282,  1.1166],\n","        [ 1.1275,  0.0000, -0.0000, -2.1059, -0.0000,  3.6567,  0.9929,  0.0000,\n","         -0.0000,  3.6460]])\n","\n","\n","Output in Evaluation Mode: \n"," tensor([[-0.1918,  0.0400, -1.2375, -0.8138, -1.8994,  0.0333,  0.0112,  0.3753,\n","         -0.2079,  0.7423],\n","        [-0.2489, -0.0378, -0.7991, -0.1207, -0.0444,  1.4040, -0.1574,  0.0917,\n","         -0.9700, -0.1417],\n","        [ 0.4870,  0.1062,  0.3865,  0.8449, -0.2290,  1.9565, -0.8436, -0.6217,\n","         -1.3114,  1.2831],\n","        [ 1.4974, -0.5266,  0.5757,  0.8682,  0.9398, -1.2513,  0.8596, -0.1509,\n","         -0.1641,  0.5583],\n","        [ 0.5637,  0.8667, -0.7867, -1.0529, -0.2489,  1.8284,  0.4965,  0.3708,\n","         -1.6801,  1.8230]])\n"]}]},{"cell_type":"markdown","source":["## Required Package\n","\n","> torch == 2.0.1\n","\n","> torchtext == 0.15.2"],"metadata":{"id":"B0XKnrD7uTns"}},{"cell_type":"markdown","source":["## 콘텐츠 라이선스\n","\n","저작권 : <font color='blue'> <b> ©2023 by Upstage X fastcampus Co., Ltd. All rights reserved.</font></b>\n","\n","<font color='red'><b>WARNING</font> : 본 교육 콘텐츠의 지식재산권은 업스테이지 및 패스트캠퍼스에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다. </b>"],"metadata":{"id":"hivVGQ9Gubxp"}},{"cell_type":"code","source":[],"metadata":{"id":"sreOCGkNiBsI"},"execution_count":null,"outputs":[]}]}