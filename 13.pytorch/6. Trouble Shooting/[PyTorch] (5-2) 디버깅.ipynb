{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d327ee5bf5b740f9a0168996230b6cfb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d0ef836c3a44a3e9ff8b0a227e3abdc","IPY_MODEL_7ac73b08943d4ecda4e28b806cf1d0fc","IPY_MODEL_0905c2e6e5d046beb756a381c9900589"],"layout":"IPY_MODEL_f790999fc7cb477ca5613698615d4e6f"}},"5d0ef836c3a44a3e9ff8b0a227e3abdc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ac08a2135d742098b9df667cf527383","placeholder":"â€‹","style":"IPY_MODEL_23054ca7b6a646d2a4b97562765cadbe","value":"  0%"}},"7ac73b08943d4ecda4e28b806cf1d0fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_c76ba883d3b548dd8928ba06dce2f7d4","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9247eb218d214447bfc0473579337e72","value":0}},"0905c2e6e5d046beb756a381c9900589":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14b8f642a1eb4be799508f65105d1fd2","placeholder":"â€‹","style":"IPY_MODEL_60f5c65fef72482484821c9cee47d9a1","value":" 0/10 [00:00&lt;?, ?it/s]"}},"f790999fc7cb477ca5613698615d4e6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ac08a2135d742098b9df667cf527383":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23054ca7b6a646d2a4b97562765cadbe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c76ba883d3b548dd8928ba06dce2f7d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9247eb218d214447bfc0473579337e72":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"14b8f642a1eb4be799508f65105d1fd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60f5c65fef72482484821c9cee47d9a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"305565c21ca34ba788d7eb87fe5817f6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8375ebff861e44bea59cfac1d214b194","IPY_MODEL_aa68868934154c4e970b670212d25dcb","IPY_MODEL_664407e80b2d4d358db674382803dc43"],"layout":"IPY_MODEL_c66d2837eb814554b3d6eefde80adc62"}},"8375ebff861e44bea59cfac1d214b194":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34cfb887dd8f4d7ea32cf975dfcbfd39","placeholder":"â€‹","style":"IPY_MODEL_096715831d3b42409b48362da7f1bd30","value":"Epoch [1/1], Train Loss: 6.0820: 100%"}},"aa68868934154c4e970b670212d25dcb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2898fd1ae8b4cf7b42316d0bd621cc0","max":153,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5c10324688034d47a55e90ac39989682","value":153}},"664407e80b2d4d358db674382803dc43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6368ec6b27f649f892831d17077053bd","placeholder":"â€‹","style":"IPY_MODEL_f87166b68cbf4226a4cee26991c766c1","value":" 153/153 [10:59&lt;00:00,  3.65s/it]"}},"c66d2837eb814554b3d6eefde80adc62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34cfb887dd8f4d7ea32cf975dfcbfd39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"096715831d3b42409b48362da7f1bd30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2898fd1ae8b4cf7b42316d0bd621cc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c10324688034d47a55e90ac39989682":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6368ec6b27f649f892831d17077053bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f87166b68cbf4226a4cee26991c766c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4335c20e43c4494e9844ced338fe93e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4bd352a341a940068dc6e449f37ecbb7","IPY_MODEL_0f43c75d13224254a497689e312ff0f8","IPY_MODEL_bf0129c7c3c4446ea80d0c0e94d8425e"],"layout":"IPY_MODEL_7525c4940a864cc980a4e3bc5d8aad53"}},"4bd352a341a940068dc6e449f37ecbb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d46bd413217e4aecafcb60f108736776","placeholder":"â€‹","style":"IPY_MODEL_79d1f1343f3c41f7b54e115727c199c7","value":"Epoch [1/1], Valid Loss: 6.2296: 100%"}},"0f43c75d13224254a497689e312ff0f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57e20eb5afa84eddbb4636bb67335756","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a111b7deca7f44cdae5687410b87177e","value":20}},"bf0129c7c3c4446ea80d0c0e94d8425e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fc990c8e3f941248367a34ba9fbcf43","placeholder":"â€‹","style":"IPY_MODEL_233a81482b054b0f8caa069f05bdcdee","value":" 20/20 [00:23&lt;00:00,  1.01s/it]"}},"7525c4940a864cc980a4e3bc5d8aad53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d46bd413217e4aecafcb60f108736776":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79d1f1343f3c41f7b54e115727c199c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57e20eb5afa84eddbb4636bb67335756":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a111b7deca7f44cdae5687410b87177e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fc990c8e3f941248367a34ba9fbcf43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"233a81482b054b0f8caa069f05bdcdee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# ë””ë²„ê¹…"],"metadata":{"id":"LqtnQrHQ2CdP"}},{"cell_type":"markdown","source":["## ì‹¤ìŠµ ê°œìš”\n","\n","1) **ì‹¤ìŠµ ëª©ì **\n","\n","ì´ ì‹¤ìŠµì€ ì—¬ëŸ¬ë¶„ì´ PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ê°œë°œí•˜ê³  í›ˆë ¨í•˜ëŠ” ê³¼ì •ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ì—ëŸ¬ ìƒí™©ì„ ì´í•´í•˜ê³ , ì´ë¥¼ ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•´ ë°°ìš°ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. íŠ¹íˆ, Custom Datasetê³¼ Custom Model êµ¬í˜„, ê·¸ë¦¬ê³  í•™ìŠµ ë° í‰ê°€ ì‹œì— ìì£¼ ë°œìƒí•˜ëŠ” ì—ëŸ¬ ìƒí™©ì„ ì¤‘ì ì ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤.\n","\n","\n","\n","2) **ìˆ˜ê°• ëª©í‘œ**\n","\n","- Custom Datasetê³¼ Custom Modelì„ êµ¬í˜„í•˜ëŠ” ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ì£¼ìš” ì—ëŸ¬ë¥¼ ì´í•´í•˜ê³  ì´ë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤.\n","- CUDA ë©”ëª¨ë¦¬ ë¬¸ì œë¥¼ ì´í•´í•˜ê³ , ì´ë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì„ ë°°ìš¸ ìˆ˜ ìˆë‹¤.\n","- ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ì‹œì— ë°œìƒí•˜ëŠ” ë‹¤ì–‘í•œ ì—ëŸ¬ ìƒí™©ê³¼ ì´ë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì„ ë°°ìš¸ ìˆ˜ ìˆë‹¤."],"metadata":{"id":"h8l2Fx195bzp"}},{"cell_type":"markdown","source":["### ì‹¤ìŠµ ëª©ì°¨\n","- 1. Custom Dataset êµ¬í˜„ ì‹œ ì—ëŸ¬\n","- 2. Custom Model êµ¬í˜„ ì‹œ ì—ëŸ¬\n","- 3. í•™ìŠµ ë° í‰ê°€ ì‹œ ì—ëŸ¬\n","- 4. í”í•œ ì‹¤ìˆ˜ ì‚¬ë¡€"],"metadata":{"id":"VEoniSz85ioV"}},{"cell_type":"markdown","source":["### â— ë“¤ì–´ê°€ê¸° ì „\n","\n","ì•ìœ¼ë¡œ PyTorchë¡œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬í˜„í•˜ë©´ì„œ ë§ì€ ì—ëŸ¬ë“¤ì„ ë§Œë‚˜ê²Œ ë  ê²ƒ ì…ë‹ˆë‹¤. ì—ëŸ¬ë“¤ì€ ì˜ˆìƒì¹˜ ëª»í•œ ìƒí™©, ì½”ë“œì˜ ì˜¤íƒ€, ëŸ°íƒ€ì„ ì˜¤ë¥˜, ê·¸ë¦¬ê³  ë²„ì „ ë¬¸ì œ ë“± ë‹¤ì–‘í•œ ë¬¸ì œì— ì˜í•´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ° ê²½ìš°ì—ë„ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ í‚¤ì›Œì•¼ í•©ë‹ˆë‹¤.\n","\n","ì‹¤ìŠµì—ì„œ ë‹¤ë£¨ì§€ ì•Šì€ ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤ë©´?\n","\n","1. ì—ëŸ¬ ë©”ì„¸ì§€ë¥¼ ìì„¸íˆ ì½ì–´ë³´ëŠ” ê²ƒì€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ì—ëŸ¬ ë©”ì„¸ì§€ë¥¼ ì½ì–´ë³´ëŠ” ê²ƒì€ ì²« ê±¸ìŒì´ë©°, Pythonê³¼ PyTorchëŠ” ë³´í†µ **ì–´ë””ì—ì„œ** **ì™œ** ì—ëŸ¬ê°€ ë°œìƒí–ˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë©”ì„¸ì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë©”ì„¸ì§€ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì€ ë•Œë¡œ ì–´ë ¤ìš¸ ìˆ˜ ìˆì§€ë§Œ, ì´í•´í•˜ë ¤ê³  ë…¸ë ¥í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ğŸ˜\n","\n","2. êµ¬ê¸€ì— í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤. ê±°ì˜ ëŒ€ë¶€ë¶„ì˜ ì—ëŸ¬ëŠ” ë‹¤ë¥¸ ê°œë°œìë“¤ë„ ì´ë¯¸ ì ‘í–ˆê³ , ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë§ì€ ì •ë³´ë¥¼ ì¸í„°ë„·ì„ í†µí•´ ê³µìœ í–ˆìŠµë‹ˆë‹¤. êµ¬ê¸€ì„ í†µí•´ ë‹µì„ ì•Œê²Œ ëœ í›„, í˜„ì¬ ìì‹ ì˜ ì½”ë“œì™€ ë¹„êµí•´ë³´ë©° ì–´ë–¤ ì‹¤ìˆ˜ë¡œ ì¸í•´ ì—ëŸ¬ê°€ ë°œìƒí–ˆëŠ”ì§€ ì´í•´í•˜ë ¤ í•œë‹¤ë©´ í° ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤! ğŸ’ªğŸ»"],"metadata":{"id":"f7H1RahW5kMj"}},{"cell_type":"markdown","source":["### í™˜ê²½ ì„¤ì •\n","\n","- íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„í¬íŠ¸"],"metadata":{"id":"gX0pcekYAyln"}},{"cell_type":"code","source":["!pip install torch==2.0.1 -q\n","!pip install torchtext==0.15.2 -q"],"metadata":{"id":"qGKwt2iS8Ovl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np # ê¸°ë³¸ì ì¸ ì—°ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","from tqdm.notebook import tqdm # ìƒíƒœ ë°”ë¥¼ ë‚˜íƒ€ë‚´ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","\n","import torch # PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬\n","import torch.nn as nn # ëª¨ë¸ êµ¬ì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","import torch.optim as optim # optimizer ì„¤ì •ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","from torch.utils.data import Dataset, DataLoader # ë°ì´í„°ì…‹ ì„¤ì •ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","\n","from torchtext.data import get_tokenizer # torchì—ì„œ tokenizerë¥¼ ì–»ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","import torchtext # torchì—ì„œ textë¥¼ ë” ì˜ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","\n","from sklearn.metrics import accuracy_score # ì„±ëŠ¥ì§€í‘œ ì¸¡ì •\n","from sklearn.model_selection import train_test_split # train-validation-test set ë‚˜ëˆ„ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n","\n","import re # text ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","import pandas as pd # í…Œì´ë¸” ë°ì´í„°ë¥¼ í¸ë¦¬í•˜ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬"],"metadata":{"id":"wUwDqn6qA1Gh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# seed ê³ ì •\n","import random\n","import torch.backends.cudnn as cudnn\n","\n","def random_seed(seed_num):\n","    torch.manual_seed(seed_num)\n","    torch.cuda.manual_seed(seed_num)\n","    torch.cuda.manual_seed_all(seed_num)\n","    np.random.seed(seed_num)\n","    cudnn.benchmark = False\n","    cudnn.deterministic = True\n","    random.seed(seed_num)\n","\n","random_seed(42)"],"metadata":{"id":"vqbaN6TSA4bt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###  ë°ì´í„° ì…‹ ê°œìš” </b>\n","\n","* ë°ì´í„°ì…‹: <a href='https://www.kaggle.com/datasets/dorianlazar/medium-articles-dataset'>Medium Dataset</a>\n","* ë°ì´í„°ì…‹ ê°œìš”: \"Towards Data Science\", \"UX Collective\", \"The Startup\", \"The Writing Cooperative\", \"Data Driven Investor\", \"Better Humans\", \"Better Marketing\" ì˜ 7ê°œì˜ ì£¼ì œë¥¼ ê°€ì§€ëŠ” publication ì— ëŒ€í•´ì„œ í¬ë¡¤ë§ì„ í•œ ë°ì´í„°ì…ë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°ëŠ” ì´ 6,508ê°œì˜ ë¸”ë¡œê·¸ ì´ë¯¸ì§€ì™€ ë©”íƒ€ ë°ì´í„°(.csv)ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ì‹¤ìŠµì—ì„œëŠ” ë©”íƒ€ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ CustomDatasetì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n","  * [How to collect ths dataset?](https://dorianlazar.medium.com/scraping-medium-with-python-beautiful-soup-3314f898bbf5)\n","- ë©”íƒ€ ë°ì´í„° ìŠ¤í‚¤ë§ˆ: ë©”íƒ€ ë°ì´í„°ëŠ” ì´ **10**ê°œì˜ columnìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n","  - id: ì•„ì´ë””\n","  - url: í¬ìŠ¤íŒ… ë§í¬\n","  - title: ì œëª©\n","  - subtitle: ë¶€ì œëª©\n","  - image: í¬ìŠ¤íŒ… ì´ë¯¸ì§€ì˜ íŒŒì¼ ì´ë¦„\n","  - claps: ì¶”ì²œ ìˆ˜\n","  - reponses: ëŒ“ê¸€ ìˆ˜\n","  - reading_time: ì½ëŠ”ë° ê±¸ë¦¬ëŠ” ì‹œê°„\n","  - publication: ì£¼ì œ ì¹´í…Œê³ ë¦¬(e.g. Towards Data Science..)\n","  - date: ì‘ì„± ë‚ ì§œ\n","- ë°ì´í„° ì…‹ ì €ì‘ê¶Œ: CC0: Public Domain\n","\n","\n"],"metadata":{"id":"A2le5RDL7n7w"}},{"cell_type":"markdown","source":["## 1. Custom Dataset êµ¬í˜„ ì‹œ ì—ëŸ¬\n","\n","```\n","ğŸ’¡ ëª©ì°¨ ê°œìš”: Custom Datasetì„ êµ¬í˜„í•˜ë©° ì‰½ê²Œ ì ‘í•˜ëŠ” ì—ëŸ¬ë¥¼ ì•Œì•„ë´…ë‹ˆë‹¤.\n","```\n"],"metadata":{"id":"ZVop-Shw_QBw"}},{"cell_type":"code","source":["# google drive mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"F9i53UVnA54h","executionInfo":{"status":"ok","timestamp":1691293195925,"user_tz":-540,"elapsed":2188,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c40f3d7c-e8df-47b7-c38e-c314b9463abd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7nACn3OokeR","executionInfo":{"status":"ok","timestamp":1691293195926,"user_tz":-540,"elapsed":7,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"9042d135-7a53-495c-fdfa-0309b23a998e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["data_csv = pd.read_csv('medium_data.csv')\n","\n","# train setê³¼ validation set, test setì„ ê°ê° ë‚˜ëˆ•ë‹ˆë‹¤. 8 : 1 : 1 ì˜ ë¹„ìœ¨ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\n","train_csv, test_csv = train_test_split(data_csv, test_size = .2, random_state = 42)\n","val_csv, test_csv = train_test_split(test_csv, test_size = .5, random_state = 42)\n","\n","# index ë¥¼ reset í•´ì¤ë‹ˆë‹¤.\n","train_csv = train_csv.reset_index(drop=True)\n","val_csv = val_csv.reset_index(drop=True)\n","test_csv = test_csv.reset_index(drop=True)\n","\n","print(\"Train ê°œìˆ˜: \", len(train_csv))\n","print(\"Validation ê°œìˆ˜: \", len(val_csv))\n","print(\"Test ê°œìˆ˜: \", len(test_csv))\n","\n","# ê°ê°ì˜ titleë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n","# ìš°ë¦¬ëŠ” titleì˜ ì²« ë‹¨ì–´ê°€ ì£¼ì–´ì¡Œì„ ë–„, ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì„ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤.\n","data = data_csv['title'].values\n","train = train_csv['title'].values\n","val = val_csv['title'].values\n","test = test_csv['title'].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUFKk_DvA8Tv","executionInfo":{"status":"ok","timestamp":1691288267841,"user_tz":-540,"elapsed":312,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"026c5112-bd69-453a-b6ab-721fc48775e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train ê°œìˆ˜:  5206\n","Validation ê°œìˆ˜:  651\n","Test ê°œìˆ˜:  651\n"]}]},{"cell_type":"markdown","source":["#### ğŸ“ ì„¤ëª…: `__len__` ë©”ì„œë“œì—ì„œì˜ ì—ëŸ¬\n","Custom Datasetì„ êµ¬í˜„í•˜ë©° `__len__` ë©”ì„œë“œì—ì„œëŠ” í•„ìˆ˜ì ìœ¼ë¡œ ë°ì´í„°ì˜ ì´ ê°œìˆ˜ë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤. í•˜ë“œ ì½”ë”©ì„ í•œë‹¤ë©´ ì½”ë“œì˜ ì¬ì‚¬ìš©ì„±ì´ ë‚®ì•„ì§€ê²Œ ë©ë‹ˆë‹¤.\n","\n","ì•„ë˜ ì½”ë“œì—ì„œëŠ” `__len__` ë©”ì„œë“œì—ì„œ ë°˜í™˜í•˜ëŠ” ê°’ì„ ì´ ê°œìˆ˜ê°€ ì•„ë‹Œ ìˆ«ì ê°’ìœ¼ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.\n","\n","- `__len__` ë°˜í™˜ ê°’ì´ ë°ì´í„° ìˆ˜ë³´ë‹¤ ì ì€ ê²½ìš°: ë°ì´í„° ë¡œë”ì—ì„œ ë°˜í™˜í•˜ëŠ” ê°’ë§Œí¼ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê²Œ ë¼ ëª¨ë“  ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì§€ ëª»í•©ë‹ˆë‹¤.\n","- `__len__` ë°˜í™˜ ê°’ì´ ë°ì´í„° ìˆ˜ë³´ë‹¤ ë§ì€ ê²½ìš°: í˜„ì¬ ê°€ì§„ ë°ì´í„°ì˜ ìµœëŒ€ indexë³´ë‹¤ í° ê°’ì„ ë°ì´í„° ë¡œë”ê°€ ë¶ˆëŸ¬ì˜¬ ê²½ìš°, í•´ë‹¹ indexì˜ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í•´ IndexErrorê°€ ë°œìƒí•©ë‹ˆë‹¤.\n","\n","\n","ğŸ“š êµ¬ê¸€ ê²€ìƒ‰ í‚¤ì›Œë“œ: `pytorch custom dataset ì¸ë±ìŠ¤ ì—ëŸ¬`\n"],"metadata":{"id":"cdrzlWFMDIsl"}},{"cell_type":"code","source":["def cleaning_text(text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text)\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ')\n","    cleaned_text = cleaned_text.replace('\\u200a',' ')\n","    return cleaned_text\n","\n","def make_word_dic(data, tokenizer):\n","    cleaned_data = map(cleaning_text, data)\n","    vocab = torchtext.vocab.build_vocab_from_iterator(map(tokenizer, cleaned_data))\n","    vocab.insert_token('<pad>',0)\n","    word_to_id = dict(sorted(vocab.get_stoi().items(), key=lambda item: item[1]))\n","    return word_to_id"],"metadata":{"id":"ETPsvPtUrDME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Medium ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ Custom Datasetì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n","# ì•„ë˜ì˜ ì½”ë“œëŠ” __len__ ë©”ì„œë“œ ë°˜í™˜ ê°’ì´ ì˜ëª»ëœ ê²½ìš°ì…ë‹ˆë‹¤.\n","class CustomDataset(Dataset):\n","  def __init__(self, data, word_to_id, tokenizer, max_len):\n","    self.data = list(map(self.cleaning_text, data))\n","    self.word_to_id = word_to_id # ë‹¨ì–´ ì‚¬ì „ ë¶ˆëŸ¬ì˜¤ê¸°\n","    self.max_len = max_len\n","    self.tokenizer = tokenizer\n","    seq = self.make_sequence(self.data, self.word_to_id, self.tokenizer) # next word predictionì„ í•˜ê¸° ìœ„í•œ í˜•íƒœë¡œ ë³€í™˜\n","    self.seq = self.pre_zeropadding(seq, self.max_len) # zero paddingìœ¼ë¡œ ì±„ì›Œì¤Œ\n","    self.X = torch.tensor(self.seq[:,:-1])\n","    self.label = torch.tensor(self.seq[:,-1])\n","\n","  def cleaning_text(self, text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text) # íŠ¹ìˆ˜ë¬¸ì ë¥¼ ëª¨ë‘ ì§€ìš°ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # non-breaking spaceë¥¼ unicode ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","    cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode ë¹ˆì¹¸ì„ ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","    return cleaned_text\n","\n","  def make_sequence(self, data, word_to_id, tokenizer):\n","    seq = []\n","    for i in data:\n","      token_id = list(map(lambda x: word_to_id[x], tokenizer(i)))\n","      for j in range(1, len(token_id)):\n","        sequence = token_id[:j+1]\n","        seq.append(sequence)\n","    return seq\n","\n","  def pre_zeropadding(self, seq, max_len): # max_len ê¸¸ì´ì— ë§ì¶°ì„œ 0 ìœ¼ë¡œ padding ì²˜ë¦¬ (ì•ë¶€ë¶„ì— padding ì²˜ë¦¬)\n","    return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","  def __len__(self): # datasetì˜ ì „ì²´ ê¸¸ì´ ë°˜í™˜\n","    return 50000  # len(self.X)\n","\n","  def __getitem__(self, idx): # dataset ì ‘ê·¼\n","    X = self.X[idx]\n","    label = self.label[idx]\n","\n","    return X, label\n","\n","batch_size = 32\n","tokenizer = get_tokenizer(\"basic_english\")\n","word_to_id = make_word_dic(data, tokenizer)\n","max_len = 37\n","train_dataset = CustomDataset(train, word_to_id, tokenizer, max_len)\n","train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = False, drop_last = False)\n","\n","for text, labels in train_dataloader:\n","  pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"lsPFPonTo0bJ","executionInfo":{"status":"error","timestamp":1691289189400,"user_tz":-540,"elapsed":778,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"8e40a0bc-b293-4256-9af0-d206c27e102c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-0bb5656dd646>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-0bb5656dd646>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# dataset ì ‘ê·¼\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 39021 is out of bounds for dimension 0 with size 39021"]}]},{"cell_type":"code","source":["# Medium ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ Custom Datasetì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n","# ì•„ë˜ì˜ ì½”ë“œëŠ” __len__ ë©”ì„œë“œ ë°˜í™˜ ê°’ì´ ì˜ëª»ëœ ê²½ìš°ì…ë‹ˆë‹¤.\n","class CustomDataset(Dataset):\n","  def __init__(self, data, word_to_id, tokenizer, max_len):\n","    self.data = list(map(self.cleaning_text, data))\n","    self.word_to_id = word_to_id # ë‹¨ì–´ ì‚¬ì „ ë¶ˆëŸ¬ì˜¤ê¸°\n","    self.max_len = max_len\n","    self.tokenizer = tokenizer\n","    seq = self.make_sequence(self.data, self.word_to_id, self.tokenizer) # next word predictionì„ í•˜ê¸° ìœ„í•œ í˜•íƒœë¡œ ë³€í™˜\n","    self.seq = self.pre_zeropadding(seq, self.max_len) # zero paddingìœ¼ë¡œ ì±„ì›Œì¤Œ\n","    self.X = torch.tensor(self.seq[:,:-1])\n","    self.label = torch.tensor(self.seq[:,-1])\n","\n","  def cleaning_text(self, text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text) # íŠ¹ìˆ˜ë¬¸ì ë¥¼ ëª¨ë‘ ì§€ìš°ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # non-breaking spaceë¥¼ unicode ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","    cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode ë¹ˆì¹¸ì„ ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","    return cleaned_text\n","\n","  def make_sequence(self, data, word_to_id, tokenizer):\n","    seq = []\n","    for i in data:\n","      token_id = list(map(lambda x: word_to_id[x], tokenizer(i)))\n","      for j in range(1, len(token_id)):\n","        sequence = token_id[:j+1]\n","        seq.append(sequence)\n","    return seq\n","\n","  def pre_zeropadding(self, seq, max_len): # max_len ê¸¸ì´ì— ë§ì¶°ì„œ 0 ìœ¼ë¡œ padding ì²˜ë¦¬ (ì•ë¶€ë¶„ì— padding ì²˜ë¦¬)\n","    return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","  def __len__(self): # datasetì˜ ì „ì²´ ê¸¸ì´ ë°˜í™˜\n","    return len(self.X)\n","\n","  def __getitem__(self, idx): # dataset ì ‘ê·¼\n","    X = self.X[idx]\n","    label = self.label[idx]\n","\n","    return X, label\n","\n","batch_size = 32\n","tokenizer = get_tokenizer(\"basic_english\")\n","word_to_id = make_word_dic(data, tokenizer)\n","max_len = 37\n","train_dataset = CustomDataset(train, word_to_id, tokenizer, max_len)\n","train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = False, drop_last = False)\n","\n","for text, labels in train_dataloader:\n","  pass"],"metadata":{"id":"7n0_xr2pIGJn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### ğŸ“ ì„¤ëª…: `__getitem__` ë©”ì„œë“œì—ì„œì˜ ì—ëŸ¬\n","ìœ„ì˜ ì—ëŸ¬ ìƒí™©ê³¼ ê°™ì€ ë§¥ë½ìœ¼ë¡œ Custom Dataset êµ¬í˜„ ì‹œ IndexErrorëŠ” ìì£¼ ë°œìƒí•˜ëŠ” ì—ëŸ¬ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. `__getitem__` ë©”ì„œë“œ ì‘ì„± ì‹œì—ë„ ì£¼ì–´ì§„ ë°ì´í„° ìˆ˜ë³´ë‹¤ ì´ˆê³¼í•˜ëŠ” ì¸ë±ìŠ¤ì— ì ‘ê·¼í•œë‹¤ë©´, IndexErrorê°€ ë°œìƒí•©ë‹ˆë‹¤.\n"],"metadata":{"id":"s-3_U3reIo-_"}},{"cell_type":"code","source":["# ì•„ë˜ì˜ ì½”ë“œëŠ” __getitem__ ë©”ì„œë“œì—ì„œ indexë¥¼ ì˜ëª» ì ‘ê·¼í•œ ê²½ìš°ì…ë‹ˆë‹¤.\n","class CustomDataset(Dataset):\n","  def __init__(self, data, word_to_id, tokenizer, max_len):\n","    self.data = list(map(self.cleaning_text, data))\n","    self.word_to_id = word_to_id # ë‹¨ì–´ ì‚¬ì „ ë¶ˆëŸ¬ì˜¤ê¸°\n","    self.max_len = max_len\n","    self.tokenizer = tokenizer\n","    seq = self.make_sequence(self.data, self.word_to_id, self.tokenizer) # next word predictionì„ í•˜ê¸° ìœ„í•œ í˜•íƒœë¡œ ë³€í™˜\n","    self.seq = self.pre_zeropadding(seq, self.max_len) # zero paddingìœ¼ë¡œ ì±„ì›Œì¤Œ\n","    self.X = torch.tensor(self.seq[:,:-1])\n","    self.label = torch.tensor(self.seq[:,-1])\n","\n","  def cleaning_text(self, text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text) # íŠ¹ìˆ˜ë¬¸ì ë¥¼ ëª¨ë‘ ì§€ìš°ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # non-breaking spaceë¥¼ unicode ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","    cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode ë¹ˆì¹¸ì„ ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","    return cleaned_text\n","\n","  def make_sequence(self, data, word_to_id, tokenizer):\n","    seq = []\n","    for i in data:\n","      token_id = list(map(lambda x: word_to_id[x], tokenizer(i)))\n","      for j in range(1, len(token_id)):\n","        sequence = token_id[:j+1]\n","        seq.append(sequence)\n","    return seq\n","\n","  def pre_zeropadding(self, seq, max_len): # max_len ê¸¸ì´ì— ë§ì¶°ì„œ 0 ìœ¼ë¡œ padding ì²˜ë¦¬ (ì•ë¶€ë¶„ì— padding ì²˜ë¦¬)\n","    return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","  def __len__(self): # datasetì˜ ì „ì²´ ê¸¸ì´ ë°˜í™˜\n","    return len(self.X)\n","\n","  def __getitem__(self, idx): # dataset ì ‘ê·¼\n","    # ì „ì²˜ë¦¬ëœ ë°ì´í„°(self.X)ê°€ ì•„ë‹Œ ì›ì‹œ ë°ì´í„°(self.data)ì— ì ‘ê·¼í•˜ëŠ” ìƒí™©ì„ ê°€ì •í•©ë‹ˆë‹¤.\n","\n","    X = self.data[idx] # DataLoaderì—ì„œ ì¸ìë¡œ ì£¼ëŠ” idxë³´ë‹¤ self.dataì˜ í¬ê¸°ê°€ ì‘ê¸° ë•Œë¬¸ì— ì—ëŸ¬ ë°œìƒ\n","    label = self.label[idx]\n","\n","    return X, label\n","\n","batch_size = 32\n","tokenizer = get_tokenizer(\"basic_english\")\n","word_to_id = make_word_dic(data, tokenizer)\n","max_len = 37\n","train_dataset = CustomDataset(train, word_to_id, tokenizer, max_len)\n","train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = False, drop_last = False)\n","\n","for text, labels in train_dataloader:\n","  pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"VnEJscoSJdS9","executionInfo":{"status":"error","timestamp":1691289373764,"user_tz":-540,"elapsed":616,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"63877f98-63fe-4b3b-d892-4df731b3365b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-4a2babef310d>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-4a2babef310d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# dataset ì ‘ê·¼\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# ì „ì²˜ë¦¬ëœ ë°ì´í„°(self.X)ê°€ ì•„ë‹Œ ì›ì‹œ ë°ì´í„°(self.data)ì— ì ‘ê·¼í•˜ëŠ” ìƒí™©ì„ ê°€ì •í•©ë‹ˆë‹¤.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","source":["# ì˜¬ë°”ë¥´ê²Œ ìˆ˜ì •ëœ ì½”ë“œ\n","class CustomDataset(Dataset):\n","  def __init__(self, data, word_to_id, tokenizer, max_len):\n","    self.data = list(map(self.cleaning_text, data))\n","    self.word_to_id = word_to_id # ë‹¨ì–´ ì‚¬ì „ ë¶ˆëŸ¬ì˜¤ê¸°\n","    self.max_len = max_len\n","    self.tokenizer = tokenizer\n","    seq = self.make_sequence(self.data, self.word_to_id, self.tokenizer) # next word predictionì„ í•˜ê¸° ìœ„í•œ í˜•íƒœë¡œ ë³€í™˜\n","    self.seq = self.pre_zeropadding(seq, self.max_len) # zero paddingìœ¼ë¡œ ì±„ì›Œì¤Œ\n","    self.X = torch.tensor(self.seq[:,:-1])\n","    self.label = torch.tensor(self.seq[:,-1])\n","\n","\n","  def cleaning_text(self, text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text) # íŠ¹ìˆ˜ë¬¸ì ë¥¼ ëª¨ë‘ ì§€ìš°ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # non-breaking spaceë¥¼ unicode ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","    cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode ë¹ˆì¹¸ì„ ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","    return cleaned_text\n","\n","  def make_sequence(self, data, word_to_id, tokenizer):\n","    seq = []\n","    for i in data:\n","      token_id = list(map(lambda x: word_to_id[x], tokenizer(i)))\n","      for j in range(1, len(token_id)):\n","        sequence = token_id[:j+1]\n","        seq.append(sequence)\n","    return seq\n","\n","  def pre_zeropadding(self, seq, max_len): # max_len ê¸¸ì´ì— ë§ì¶°ì„œ 0 ìœ¼ë¡œ padding ì²˜ë¦¬ (ì•ë¶€ë¶„ì— padding ì²˜ë¦¬)\n","    return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","\n","  def __len__(self): # datasetì˜ ì „ì²´ ê¸¸ì´ ë°˜í™˜\n","    return len(self.X)\n","\n","  def __getitem__(self, idx): # dataset ì ‘ê·¼\n","    X = self.X[idx]\n","    label = self.label[idx]\n","\n","    return X, label\n","\n","batch_size = 32\n","tokenizer = get_tokenizer(\"basic_english\")\n","word_to_id = make_word_dic(data, tokenizer)\n","max_len = 37\n","train_dataset = CustomDataset(train, word_to_id, tokenizer, max_len)\n","train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = False, drop_last = False)\n","\n","for text, labels in train_dataloader:\n","  pass"],"metadata":{"id":"ttDT2O0sKh0y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### ğŸ“ ì„¤ëª…: `__getitem__`ì—ì„œ ë°ì´í„° íƒ€ì…ì„ ì œëŒ€ë¡œ ë³€í™˜í•˜ì§€ ì•Šì€ ê²½ìš°\n","\n","TypeErrorëŠ” PyTorchì˜ íŠ¹ì • ë ˆì´ì–´ë‚˜ í•¨ìˆ˜ì—ì„œ ìš”êµ¬í•˜ëŠ” ë°ì´í„° íƒ€ì…ê³¼ ì…ë ¥ ë°ì´í„°ì˜ íƒ€ì…ì´ ì¼ì¹˜ í•˜ì§€ ì•Šì„ ë•Œ ì£¼ë¡œ ë°œìƒí•©ë‹ˆë‹¤.\n","ì˜ˆë¥¼ ë“¤ì–´ `nn.Embedding` ë ˆì´ì–´ëŠ” ì…ë ¥ìœ¼ë¡œ long íƒ€ì…ì˜ tensorë¥¼ ìš”êµ¬í•˜ëŠ”ë°, float íƒ€ì…ì˜ tensorë¥¼ ì…ë ¥í•˜ë©´ type ë¬¸ì œë¡œ ì¸í•œ `RuntimeError`ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n","\n","\n","ğŸ“š êµ¬ê¸€ ê²€ìƒ‰ í‚¤ì›Œë“œ: nn.Embedding Runtime Error\n"],"metadata":{"id":"74y6G5uAMjvB"}},{"cell_type":"code","source":["# float íƒ€ì…ì˜ ë°ì´í„°ë¥¼ ë°˜í™˜í•˜ëŠ” Dataset\n","class CustomDataset(Dataset):\n","  def __init__(self, data, word_to_id, tokenizer, max_len):\n","    self.data = list(map(self.cleaning_text, data))\n","    self.word_to_id = word_to_id # ë‹¨ì–´ ì‚¬ì „ ë¶ˆëŸ¬ì˜¤ê¸°\n","    self.max_len = max_len\n","    self.tokenizer = tokenizer\n","    seq = self.make_sequence(self.data, self.word_to_id, self.tokenizer) # next word predictionì„ í•˜ê¸° ìœ„í•œ í˜•íƒœë¡œ ë³€í™˜\n","    self.seq = self.pre_zeropadding(seq, self.max_len) # zero paddingìœ¼ë¡œ ì±„ì›Œì¤Œ\n","\n","    \"\"\"\n","    ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ê³¼ì •ì—ì„œ ë°ì´í„° íƒ€ì…ì´ ë§ì§€ ì•ŠëŠ” ê²½ìš°(e.g. Embedding Layerë¥¼ í†µê³¼í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ê°€ torch.floatì¸ ê²½ìš°)\n","    \"\"\"\n","    self.X = self.seq[:,:-1].astype(float) # float íƒ€ì…ì˜ numpy array\n","    self.label = self.seq[:,-1].astype(float)\n","\n","  def cleaning_text(self, text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text) # íŠ¹ìˆ˜ë¬¸ì ë¥¼ ëª¨ë‘ ì§€ìš°ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # non-breaking spaceë¥¼ unicode ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","    cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode ë¹ˆì¹¸ì„ ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","    return cleaned_text\n","\n","  def make_sequence(self, data, word_to_id, tokenizer):\n","    seq = []\n","    for i in data:\n","      token_id = list(map(lambda x: word_to_id[x], tokenizer(i)))\n","      for j in range(1, len(token_id)):\n","        sequence = token_id[:j+1]\n","        seq.append(sequence)\n","    return seq\n","\n","  def pre_zeropadding(self, seq, max_len): # max_len ê¸¸ì´ì— ë§ì¶°ì„œ 0 ìœ¼ë¡œ padding ì²˜ë¦¬ (ì•ë¶€ë¶„ì— padding ì²˜ë¦¬)\n","    return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","  def __len__(self): # datasetì˜ ì „ì²´ ê¸¸ì´ ë°˜í™˜\n","    return len(self.X)\n","\n","  def __getitem__(self, idx): # dataset ì ‘ê·¼\n","    # numpy array íƒ€ì…ì˜ ë°ì´í„°ë¥¼ tensorë¡œ ë³€í™˜\n","    X = torch.tensor(self.X[idx])\n","    label = torch.tensor(self.label[idx])\n","\n","    return X, label\n","\n","batch_size = 32\n","tokenizer = get_tokenizer(\"basic_english\")\n","word_to_id = make_word_dic(data, tokenizer)\n","max_len = 37\n","train_dataset = CustomDataset(train, word_to_id, tokenizer, max_len)\n","train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = False, drop_last = False)\n","\n","for text, labels in train_dataloader:\n","  pass\n","\n","layer = nn.Embedding(len(word_to_id), 128)\n","out = layer(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"4FpTiBE9MPcr","executionInfo":{"status":"error","timestamp":1691291223861,"user_tz":-540,"elapsed":2254,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"bf4a8fe5-fd03-4e03-e73c-a33b043b2962"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-bd3e049dbeae>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2208\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.DoubleTensor instead (while checking arguments for embedding)"]}]},{"cell_type":"code","source":["# ì˜¬ë°”ë¥´ê²Œ ìˆ˜ì •ëœ ì½”ë“œ\n","class CustomDataset(Dataset):\n","  def __init__(self, data, word_to_id, tokenizer, max_len):\n","    self.data = list(map(self.cleaning_text, data))\n","    self.word_to_id = word_to_id # ë‹¨ì–´ ì‚¬ì „ ë¶ˆëŸ¬ì˜¤ê¸°\n","    self.max_len = max_len\n","    self.tokenizer = tokenizer\n","    seq = self.make_sequence(self.data, self.word_to_id, self.tokenizer) # next word predictionì„ í•˜ê¸° ìœ„í•œ í˜•íƒœë¡œ ë³€í™˜\n","    self.seq = self.pre_zeropadding(seq, self.max_len) # zero paddingìœ¼ë¡œ ì±„ì›Œì¤Œ\n","\n","    \"\"\"\n","    ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ê³¼ì •ì—ì„œ ë°ì´í„° íƒ€ì…ì´ ë§ì§€ ì•ŠëŠ” ê²½ìš°(e.g. Embedding Layerë¥¼ í†µê³¼í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ê°€ torch.floatì¸ ê²½ìš°)\n","    ì•„ë˜ì˜ ì‹¤ìŠµ ì˜ˆì‹œì—ì„œëŠ” __getitem__ì—ì„œ torch.long ë°ì´í„° íƒ€ì…ìœ¼ë¡œ ë³€ê²½\n","    \"\"\"\n","    self.X = self.seq[:,:-1].astype(float)\n","    self.label = self.seq[:,-1].astype(float)\n","\n","\n","  def cleaning_text(self, text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text) # íŠ¹ìˆ˜ë¬¸ì ë¥¼ ëª¨ë‘ ì§€ìš°ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # non-breaking spaceë¥¼ unicode ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","    cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode ë¹ˆì¹¸ì„ ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","    return cleaned_text\n","\n","  def make_sequence(self, data, word_to_id, tokenizer):\n","    seq = []\n","    for i in data:\n","      token_id = list(map(lambda x: word_to_id[x], tokenizer(i)))\n","      for j in range(1, len(token_id)):\n","        sequence = token_id[:j+1]\n","        seq.append(sequence)\n","    return seq\n","\n","  def pre_zeropadding(self, seq, max_len): # max_len ê¸¸ì´ì— ë§ì¶°ì„œ 0 ìœ¼ë¡œ padding ì²˜ë¦¬ (ì•ë¶€ë¶„ì— padding ì²˜ë¦¬)\n","    return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","\n","  def __len__(self): # datasetì˜ ì „ì²´ ê¸¸ì´ ë°˜í™˜\n","    return len(self.X)\n","\n","  def __getitem__(self, idx): # dataset ì ‘ê·¼\n","    X = torch.tensor(self.X[idx], dtype = torch.long)\n","    label = torch.tensor(self.label[idx], dtype = torch.long)\n","\n","    return X, label\n","\n","batch_size = 32\n","tokenizer = get_tokenizer(\"basic_english\")\n","word_to_id = make_word_dic(data, tokenizer)\n","max_len = 37\n","train_dataset = CustomDataset(train, word_to_id, tokenizer, max_len)\n","train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = False, drop_last = False)\n","\n","for text, labels in train_dataloader:\n","  pass\n","\n","layer = nn.Embedding(len(word_to_id), 128)\n","out = layer(text)"],"metadata":{"id":"QgMrTpySOonx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### ğŸ“ ì„¤ëª…: Dimension Error\n","\n","ì¼ë°˜ì ìœ¼ë¡œ PyTorchì—ì„œ CNN ë ˆì´ì–´ëŠ” ì…ë ¥ ë°ì´í„°ì˜ ì°¨ì›ì„ B $\\times$ C $\\times$ H $\\times$ W(B: ë¯¸ë‹ˆ ë°°ì¹˜ í¬ê¸°, C: ì±„ë„ ìˆ˜, H: ë†’ì´, W: ë„ˆë¹„)ë¡œ ì…ë ¥ ë°›ìŠµë‹ˆë‹¤.(ë°°ì¹˜ê°€ ì•„ë‹Œ ê²½ìš°, C $\\times$ H $\\times$ Wë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.) ë§Œì•½ ì´ ì°¨ì›ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë¥¼ ì…ë ¥í•œë‹¤ë©´, `Dimension Error`ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n","\n","\n","ğŸ“š êµ¬ê¸€ ê²€ìƒ‰ í‚¤ì›Œë“œ: ì—ëŸ¬ ë©”ì„¸ì§€\n"],"metadata":{"id":"pXOd9x4AP3ZK"}},{"cell_type":"code","source":["# ì…ë ¥ tensorì˜ ì°¨ì›ì´ ë§ì§€ ì•ŠëŠ” ê²½ìš°\n","conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\n","inputs = torch.randn(28, 28)  # ì°¨ì›ì´ HxW\n","out = conv(inputs)  # ì—ëŸ¬ ë°œìƒ: expected 4D input (got 3D input)\n","out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"HYclcB0PPkJB","executionInfo":{"status":"error","timestamp":1690141112942,"user_tz":-540,"elapsed":4,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"f30e7dbc-0958-449c-862f-8745a00a205f"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-e79558492e96>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ì°¨ì›ì´ HxW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ì—ëŸ¬ ë°œìƒ: expected 4D input (got 3D input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [28, 28]"]}]},{"cell_type":"code","source":["# ì˜¬ë°”ë¥´ê²Œ êµ¬í˜„ëœ ì½”ë“œ\n","conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\n","inputs_3d = torch.randn(1, 28, 28)  # ì°¨ì›ì´ HxW\n","out = conv(inputs_3d)  # ì—ëŸ¬ ë°œìƒ: expected 4D input (got 3D input)\n","\n","inputs_4d = torch.randn(1, 1, 28, 28)  # ì°¨ì›ì´ HxW\n","out = conv(inputs_4d)"],"metadata":{"id":"4zqnNqcGQ6sf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Custom Model êµ¬í˜„ ì‹œ ì—ëŸ¬\n","\n","```\n","ğŸ’¡ ëª©ì°¨ ê°œìš”: ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ì§ì ‘ ì„¤ê³„í•˜ëŠ” ê²½ìš° ë°œìƒí•  ìˆ˜ ìˆëŠ” ì—ëŸ¬ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤.\n","```\n"],"metadata":{"id":"F14iDOXSTcPL"}},{"cell_type":"markdown","source":["#### ğŸ“ ì„¤ëª…: Dimension mistmatch error\n","\n","mismatch errorëŠ” ë„¤íŠ¸ì›Œí¬ì˜ í•œ layerì—ì„œ ë‹¤ìŒ layerë¡œ ë°ì´í„°ë¥¼ ì „ë‹¬í•  ë•Œ ì…ë ¥ ë°ì´í„°ì˜ ì°¨ì›ê³¼ ê³„ì¸µì´ ê¸°ëŒ€í•˜ëŠ” ì°¨ì›ì´ ì¼ì¹˜í•˜ì§€ ì•Šì„ ë•Œ ë°œìƒí•©ë‹ˆë‹¤. ì£¼ë¡œ ì˜ëª»ëœ ê³„ì¸µ êµ¬ì„± ë˜ëŠ” ë°ì´í„° ì „ì²˜ë¦¬ë¡œ ì¸í•´ ë°œìƒí•©ë‹ˆë‹¤.\n","\n","\n","ğŸ“š êµ¬ê¸€ ê²€ìƒ‰ í‚¤ì›Œë“œ: ì—ëŸ¬ ë©”ì„¸ì§€\n"],"metadata":{"id":"8heq3_rXTjQS"}},{"cell_type":"code","source":["# mistmath errorê°€ ë°œìƒí•˜ëŠ” ì½”ë“œ\n","class CNN(nn.Module):\n","    def __init__(self, num_classes, dropout_ratio):\n","        super(CNN,self).__init__()\n","        self.num_classes = num_classes\n","\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5),  # [1,28,28] -> [16,24,24]\n","            nn.ReLU(),  # ReLU í™œì„±í™” í•¨ìˆ˜ ì ìš©\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5), # [16,24,24] -> [32,20,20]\n","            nn.ReLU(),  # ReLU í™œì„±í™” í•¨ìˆ˜ ì ìš©\n","            nn.MaxPool2d(kernel_size=2), # [32,20,20] -> [32,10,10]\n","            nn.Dropout(dropout_ratio),\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5), # [32,10,10] -> [64,6,6]\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2), # í¬ê¸°ë¥¼ 1/2ë¡œ ì¤„ì…ë‹ˆë‹¤. [64,6,6] -> [64,3,3]\n","            nn.Dropout(dropout_ratio),\n","        )\n","\n","        self.fc_layer = nn.Linear(64*5*5, self.num_classes) # [64*3*3] ì°¨ì›ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ì•¼ í•˜ë‚˜, ì˜ëª»ëœ ì…ë ¥ êµ¬ì„±\n","        self.softmax = nn.LogSoftmax(dim = 1)\n","\n","\n","    def forward(self,x):\n","        \"\"\"\n","        Input and Output Summary\n","\n","        Input:\n","          x: [batch_size, 1, 28, 28]\n","        Output:\n","          output: [batch_size, num_classes]\n","\n","        \"\"\"\n","        out = self.layer(x) # [batch_size, 64, 3, 3]\n","        out = out.view(x.shape[0], -1) # [batch_size, 64, 576]\n","        pred = self.fc_layer(out) # mis-match\n","        pred = self.softmax(pred)\n","\n","        return pred\n","\n","model = CNN(num_classes = 10, dropout_ratio = 0.2)\n","input = torch.randn(1, 1, 28, 28)\n","output = model(input)  # this will cause RuntimeError"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"id":"vcpD-hwzTfxV","executionInfo":{"status":"error","timestamp":1690277038570,"user_tz":-540,"elapsed":1692,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"c360d3f5-8f98-4675-fd72-da1bb565e985"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-acd7ff29ad46>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# this will cause RuntimeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-acd7ff29ad46>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x576 and 1600x10)"]}]},{"cell_type":"code","source":["# fully connected layerì—ì„œ mismatch errorê°€ ë°œìƒí•  ê²½ìš°, ì•„ë˜ì˜ ë°˜ë³µë¬¸ì„ í†µí•´ ì–´ë–¤ ë ˆì´ì–´ì—ì„œ ì—ëŸ¬ ë©”ì„¸ì§€ê°€ ë°œìƒí–ˆëŠ”ì§€ ë¹„êµí•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","for name, layer in model.named_modules():\n","    if isinstance(layer, torch.nn.Linear):\n","        print(f\"Layer {name}: {layer.in_features} -> {layer.out_features}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_1AlAnNWlmv","executionInfo":{"status":"ok","timestamp":1690277043890,"user_tz":-540,"elapsed":568,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"b1cb9e1b-b351-4172-c028-da0a8a0c8553"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Layer fc_layer: 1600 -> 10\n"]}]},{"cell_type":"code","source":["# ì˜¬ë°”ë¥´ê²Œ êµ¬í˜„ëœ ì½”ë“œ\n","class CNN(nn.Module):\n","    def __init__(self, num_classes, dropout_ratio):\n","        super(CNN,self).__init__()\n","        self.num_classes = num_classes\n","\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5),  # [1,28,28] -> [16,24,24]\n","            nn.ReLU(),  # ReLU í™œì„±í™” í•¨ìˆ˜ ì ìš©\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5), # [16,24,24] -> [32,20,20]\n","            nn.ReLU(),  # ReLU í™œì„±í™” í•¨ìˆ˜ ì ìš©\n","            nn.MaxPool2d(kernel_size=2), # [32,20,20] -> [32,10,10]\n","            nn.Dropout(dropout_ratio),\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5), # [32,10,10] -> [64,6,6]\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2), # í¬ê¸°ë¥¼ 1/2ë¡œ ì¤„ì…ë‹ˆë‹¤. [64,6,6] -> [64,3,3]\n","            nn.Dropout(dropout_ratio),\n","        )\n","\n","        self.fc_layer = nn.Linear(64*3*3, self.num_classes) # [64*3*3]\n","        self.softmax = nn.LogSoftmax(dim = 1)\n","\n","\n","    def forward(self,x):\n","        \"\"\"\n","        Input and Output Summary\n","\n","        Input:\n","          x: [batch_size, 1, 28, 28]\n","        Output:\n","          output: [batch_size, num_classes]\n","\n","        \"\"\"\n","        out = self.layer(x) # [batch_size, 64, 3, 3]\n","        out = out.view(x.shape[0], -1) # [batch_size, 576]\n","        pred = self.fc_layer(out) # [batch_size, 10]\n","        pred = self.softmax(pred) # [batch_size, 10]\n","\n","        return pred\n","\n","model = CNN(num_classes = 10, dropout_ratio = 0.2)\n","input = torch.randn(1, 1, 28, 28)\n","output = model(input)"],"metadata":{"id":"0PoClmOoUXLs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### ğŸ“ ì„¤ëª…: Tensor manipulation\n","\n","Dimension mismath errorì™€ ê°™ì€ ë§¥ë½ìœ¼ë¡œ íŠ¹ì • ë ˆì´ì–´ í†µê³¼ í›„ ë°ì´í„°ì˜ ì°¨ì›ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•˜ê²Œ ì¡°ì‘í•´ì¤˜ì•¼ í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì˜ˆì‹œë¡œ Global Average Poolingì„ ì‚¬ìš©í•˜ë©´ B $\\times$ C $\\times$ H $\\times$ Wì˜ ì…ë ¥ tensorëŠ” B $\\times$ C $\\times$ 1 $\\times$ 1ë¡œ ë³€í™˜ ë©ë‹ˆë‹¤.\n","\n","ì´ ê²½ìš°, ë‹¤ìŒ layerì¸ fully connected layerì™€ ì—°ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” ì ì ˆí•˜ê²Œ tensorì˜ ì°¨ì›ì„ ì¡°ì‘í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šì„ ê²½ìš° dimension mismatch errorê°€ ë°œìƒí•©ë‹ˆë‹¤.\n"],"metadata":{"id":"bB6akOVSWiRu"}},{"cell_type":"code","source":["class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Conv2d(1, 10, kernel_size=5)\n","        self.gap = nn.AdaptiveAvgPool2d(1) # 1x1 Global Average Pooling\n","        self.fc = nn.Linear(10, 10)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Input and Output Summary\n","\n","        Input:\n","          x: [batch_size, 1, 28, 28]\n","        Output:\n","          output: [batch_size, 10]\n","\n","        \"\"\"\n","        x = self.conv(x) # [batch_size, 10, 24, 24]\n","        x = self.gap(x) # [batch_size, 10, 1, 1]\n","        # x = x.view(x.size(0), -1) viewë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•„ 4 dimensionì´ ê³„ì† ìœ ì§€ë˜ëŠ” ê²½ìš°\n","        # mis-match\n","        x = self.fc(x)\n","        return x\n","\n","net = Model()\n","input = torch.randn(1, 1, 28, 28)\n","output = net(input)  # This will cause RuntimeError due to mismatch in dimension\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"id":"viHnrMwHUx0t","executionInfo":{"status":"error","timestamp":1690142845591,"user_tz":-540,"elapsed":297,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"d0bdb2b3-9dcc-4318-d842-cb74bec3ac45"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-68-89491a1c99fa>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This will cause RuntimeError due to mismatch in dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-68-89491a1c99fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, C, 1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# x = x.view(x.size(0), -1) viewë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•„ 4 dimensionì´ ê³„ì† ìœ ì§€ë˜ëŠ” ê²½ìš°\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x1 and 10x10)"]}]},{"cell_type":"code","source":["class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv = nn.Conv2d(1, 10, kernel_size=5)\n","        self.gap = nn.AdaptiveAvgPool2d(1) # 1x1 Global Average Pooling\n","        self.fc = nn.Linear(10, 10)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Input and Output Summary\n","\n","        Input:\n","          x: [batch_size, 1, 28, 28]\n","        Output:\n","          output: [batch_size, 10]\n","\n","        \"\"\"\n","        x = self.conv(x) # [batch_size, 10, 24, 24]\n","        x = self.gap(x) # [batch_size, 10, 1, 1]\n","\n","        x = x.view(x.size(0), -1) # [batch_size, 10]\n","        x = self.fc(x) # [batch_size, 10]\n","        return x\n","\n","net = Model()\n","input = torch.randn(1, 1, 28, 28)\n","output = net(input)\n"],"metadata":{"id":"FhFkV0yKWmmG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. í•™ìŠµ ë° í‰ê°€ ì‹œ ì—ëŸ¬\n","\n","```\n","ğŸ’¡ ëª©ì°¨ ê°œìš”: í•™ìŠµ ë° í‰ê°€ ë‹¨ê³„ì—ì„œ ë°œìƒí•˜ëŠ” ì—ëŸ¬ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤.\n","```\n"],"metadata":{"id":"mzpLBLKiZexB"}},{"cell_type":"markdown","source":["#### ğŸ“ ì„¤ëª…: CUDA RAM out of memory\n","\n","GPUì˜ ë©”ëª¨ë¦¬ëŠ” í•œì •ì ì´ê¸°ì— ëª¨ë¸ì„ í•™ìŠµí•  ë•Œ, GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì— ì£¼ì˜í•˜ë©° í•™ìŠµ ì½”ë“œë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµí•  ë•Œ, GPU RAMì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n","\n","- ë¯¸ë‹ˆ ë°°ì¹˜ ë°ì´í„°\n","- ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°\n","- ì—­ì „íŒŒ ìˆ˜í–‰ì„ ìœ„í•œ ê° ë ˆì´ì–´ì˜ ì¶œë ¥ ê²°ê³¼ë¬¼\n","\n","CUDA RAM out of memory ì—ëŸ¬ê°€ ë°œìƒí–ˆì„ ê²½ìš°, ëŒ€í‘œì ì¸ í•´ê²° ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n","1. **batch_size ê°ì†Œ**: ë¯¸ë‹ˆ ë°°ì¹˜ì˜ í¬ê¸°ë¥¼ ì¤„ì´ë©´, ë¯¸ë‹ˆ ë°°ì¹˜ ë°ì´í„° ë° ê° ë ˆì´ì–´ì˜ ì¶œë ¥ ê²°ê³¼ë¬¼ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë˜í•œ ì¤„ì–´ë“¤ê²Œ ë©ë‹ˆë‹¤.\n","2. **torch.cuda.empty_cache ë©”ì„œë“œ í˜¸ì¶œ**: PyTorchì—ì„œ CUDA RAM ìºì‹œë¥¼ ë¹„ìš°ëŠ” ë©”ì„œë“œì…ë‹ˆë‹¤. PyTorchëŠ” CUDAë¥¼ ì‚¬ìš©í•˜ì—¬ GPU ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ”ë°, ì´ ê³¼ì •ì—ì„œ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í•˜ê¸° ìœ„í•´ ì¼ë¶€ CUDA RAMì„ ìºì‹±í•©ë‹ˆë‹¤. `torch.cuda.empty_cache` ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ë©´ ìºì‹±ëœ ë°ì´í„°ë¥¼ ë¹„ìš°ê²Œ ë˜ë©° ì´ë¥¼ í†µí•´ CUDA RAMì„ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","\n","ğŸ“š êµ¬ê¸€ ê²€ìƒ‰ í‚¤ì›Œë“œ: cuda out of memory í•´ê²°\n"],"metadata":{"id":"6so7XvxKbaJv"}},{"cell_type":"code","source":["data_csv = pd.read_csv('medium_data.csv')\n","\n","# train setê³¼ validation set, test setì„ ê°ê° ë‚˜ëˆ•ë‹ˆë‹¤. 8 : 1 : 1 ì˜ ë¹„ìœ¨ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\n","train_csv, test_csv = train_test_split(data_csv, test_size = .2, random_state = 42)\n","val_csv, test_csv = train_test_split(test_csv, test_size = .5, random_state = 42)\n","\n","# index ë¥¼ reset í•´ì¤ë‹ˆë‹¤.\n","train_csv = train_csv.reset_index(drop=True)\n","val_csv = val_csv.reset_index(drop=True)\n","test_csv = test_csv.reset_index(drop=True)\n","\n","print(\"Train ê°œìˆ˜: \", len(train_csv))\n","print(\"Validation ê°œìˆ˜: \", len(val_csv))\n","print(\"Test ê°œìˆ˜: \", len(test_csv))\n","\n","# ê°ê°ì˜ titleë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n","# ìš°ë¦¬ëŠ” titleì˜ ì²« ë‹¨ì–´ê°€ ì£¼ì–´ì¡Œì„ ë–„, ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì„ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤.\n","data = data_csv['title'].values\n","train = train_csv['title'].values\n","val = val_csv['title'].values\n","test = test_csv['title'].values"],"metadata":{"id":"pm6-psfvftz8","executionInfo":{"status":"ok","timestamp":1691293196471,"user_tz":-540,"elapsed":5,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dc5c6313-5d5a-43ab-aace-f974a04f51bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train ê°œìˆ˜:  5206\n","Validation ê°œìˆ˜:  651\n","Test ê°œìˆ˜:  651\n"]}]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, data, word_to_id, tokenizer, max_len):\n","        self.data = list(map(cleaning_text, data))\n","        self.word_to_id = word_to_id # ë‹¨ì–´ ì‚¬ì „ ë¶ˆëŸ¬ì˜¤ê¸°\n","        self.max_len = max_len\n","        self.tokenizer = tokenizer\n","        seq = self.make_sequence(self.data, self.word_to_id, self.tokenizer) # next word predictionì„ í•˜ê¸° ìœ„í•œ í˜•íƒœë¡œ ë³€í™˜\n","        self.seq = self.pre_zeropadding(seq, self.max_len) # zero paddingìœ¼ë¡œ ì±„ì›Œì¤Œ\n","        self.X = torch.tensor(self.seq[:,:-1])\n","        self.label = torch.tensor(self.seq[:,-1])\n","\n","    def cleaning_text(self, text):\n","        cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text) # íŠ¹ìˆ˜ë¬¸ì ë¥¼ ëª¨ë‘ ì§€ìš°ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n","        cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # non-breaking spaceë¥¼ unicode ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","        cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode ë¹ˆì¹¸ì„ ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","        return cleaned_text\n","\n","    def make_sequence(self, data, word_to_id, tokenizer):\n","        seq = []\n","        for i in data:\n","            token_id = list(map(lambda x: word_to_id[x], tokenizer(i)))\n","            for j in range(1, len(token_id)):\n","                sequence = token_id[:j+1]\n","                seq.append(sequence)\n","        return seq\n","\n","    def pre_zeropadding(self, seq, max_len): # max_len ê¸¸ì´ì— ë§ì¶°ì„œ 0 ìœ¼ë¡œ padding ì²˜ë¦¬ (ì•ë¶€ë¶„ì— padding ì²˜ë¦¬)\n","        return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","    def __len__(self): # datasetì˜ ì „ì²´ ê¸¸ì´ ë°˜í™˜\n","        return len(self.X)\n","\n","    def __getitem__(self, idx): # dataset ì ‘ê·¼\n","        X = self.X[idx]\n","        label = self.label[idx]\n","\n","        return X, label"],"metadata":{"id":"x_U2b_5EfwwO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cleaning_text(text):\n","    cleaned_text = re.sub(r\"[^\\w\\s]\", \" \", text)\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ')\n","    cleaned_text = cleaned_text.replace('\\u200a',' ')\n","    return cleaned_text\n","\n","def make_word_dic(data, tokenizer):\n","    cleaned_data = map(cleaning_text, data)\n","    vocab = torchtext.vocab.build_vocab_from_iterator(map(tokenizer, cleaned_data))\n","    vocab.insert_token('<pad>',0)\n","    word_to_id = dict(sorted(vocab.get_stoi().items(), key=lambda item: item[1]))\n","    return word_to_id"],"metadata":{"id":"Gb9nRtILbZZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = get_tokenizer(\"basic_english\")\n","word_to_id = make_word_dic(data, tokenizer)\n","max_len = 30\n","batch_size = 4096\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') # gpu ì„¤ì •\n","\n","train_dataset = CustomDataset(train, word_to_id, tokenizer, max_len)\n","valid_dataset = CustomDataset(val, word_to_id, tokenizer, max_len)\n","test_dataset = CustomDataset(test, word_to_id, tokenizer, max_len)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n","valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = False)\n","test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"],"metadata":{"id":"1c-b4la217T3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LSTM(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size):\n","        super(LSTM, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True, num_layers = 2)\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Input and Output Summary\n","\n","        Input:\n","          x: [batch_size, max_len]\n","        Output:\n","          output: [batch_size, vocab_size]\n","\n","        \"\"\"\n","        x = self.embedding(x) # [batch_size, max_len, embedding_dim]\n","        output, _ = self.lstm(x) # [batch_size, max_len, hidden_size]\n","        output = output[:, -1, :] # [batch_size, hidden_size]\n","        output = self.fc(output) # [batch_size, vocab_size]\n","        return output"],"metadata":{"id":"qNHb_0Pn2w_J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training ì½”ë“œ, evaluation ì½”ë“œ, training_loop ì½”ë“œ\n","def training(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs):\n","    model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •\n","    train_loss = 0.0\n","    train_accuracy = 0\n","\n","    tbar = tqdm(dataloader)\n","    for texts, labels in tbar:\n","        texts = texts.to(device)\n","        labels = labels.to(device)\n","        # ìˆœì „íŒŒ\n","        outputs = model(texts)\n","\n","        loss = criterion(outputs, labels)\n","\n","        # ì—­ì „íŒŒ ë° ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # ì†ì‹¤ê³¼ ì •í™•ë„ ê³„ì‚°\n","        train_loss += loss.item()\n","        # torch.maxì—ì„œ dim ì¸ìì— ê°’ì„ ì¶”ê°€í•  ê²½ìš°, í•´ë‹¹ dimensionì—ì„œ ìµœëŒ“ê°’ê³¼ ìµœëŒ“ê°’ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n","        _, predicted = torch.max(outputs, dim=1)\n","\n","\n","        train_accuracy += (predicted == labels).sum().item()\n","\n","        # tqdmì˜ ì§„í–‰ë°”ì— í‘œì‹œë  ì„¤ëª… í…ìŠ¤íŠ¸ë¥¼ ì„¤ì •\n","        tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}\")\n","\n","    # ì—í­ë³„ í•™ìŠµ ê²°ê³¼ ì¶œë ¥\n","    train_loss = train_loss / len(dataloader)\n","    train_accuracy = train_accuracy / len(train_dataset)\n","\n","    return model, train_loss, train_accuracy\n","\n","def evaluation(model, dataloader, valid_dataset, criterion, device, epoch, num_epochs):\n","    model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n","    valid_loss = 0.0\n","    valid_accuracy = 0\n","\n","    with torch.no_grad(): # modelì˜ ì—…ë°ì´íŠ¸ ë§‰ê¸°\n","        tbar = tqdm(dataloader)\n","        for texts, labels in tbar:\n","            texts = texts.to(device)\n","            labels = labels.to(device)\n","\n","            # ìˆœì „íŒŒ\n","            outputs = model(texts)\n","            loss = criterion(outputs, labels)\n","\n","            # ì†ì‹¤ê³¼ ì •í™•ë„ ê³„ì‚°\n","            valid_loss += loss.item()\n","            # torch.maxì—ì„œ dim ì¸ìì— ê°’ì„ ì¶”ê°€í•  ê²½ìš°, í•´ë‹¹ dimensionì—ì„œ ìµœëŒ“ê°’ê³¼ ìµœëŒ“ê°’ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n","            _, predicted = torch.max(outputs, 1)\n","            # _, true_labels = torch.max(labels, dim=1)\n","            valid_accuracy += (predicted == labels).sum().item()\n","\n","\n","            # tqdmì˜ ì§„í–‰ë°”ì— í‘œì‹œë  ì„¤ëª… í…ìŠ¤íŠ¸ë¥¼ ì„¤ì •\n","            tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Valid Loss: {loss.item():.4f}\")\n","\n","    valid_loss = valid_loss / len(dataloader)\n","    valid_accuracy = valid_accuracy / len(valid_dataset)\n","\n","    return model, valid_loss, valid_accuracy\n","\n","\n","def training_loop(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name):\n","    best_valid_loss = float('inf')  # ê°€ì¥ ì¢‹ì€ validation lossë¥¼ ì €ì¥\n","    early_stop_counter = 0  # ì¹´ìš´í„°\n","    valid_max_accuracy = -1\n","\n","    for epoch in range(num_epochs):\n","        model, train_loss, train_accuracy = training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\n","        model, valid_loss, valid_accuracy = evaluation(model, valid_dataloader, val_dataset, criterion, device, epoch, num_epochs)\n","\n","        if valid_accuracy > valid_max_accuracy:\n","            valid_max_accuracy = valid_accuracy\n","\n","        # validation lossê°€ ê°ì†Œí•˜ë©´ ëª¨ë¸ ì €ì¥ ë° ì¹´ìš´í„° ë¦¬ì…‹\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            torch.save(model.state_dict(), f\"./model_{model_name}.pt\")\n","            early_stop_counter = 0\n","\n","        # validation lossê°€ ì¦ê°€í•˜ê±°ë‚˜ ê°™ìœ¼ë©´ ì¹´ìš´í„° ì¦ê°€\n","        else:\n","            early_stop_counter += 1\n","\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f} Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\")\n","\n","        # ì¡°ê¸° ì¢…ë£Œ ì¹´ìš´í„°ê°€ ì„¤ì •í•œ patienceë¥¼ ì´ˆê³¼í•˜ë©´ í•™ìŠµ ì¢…ë£Œ\n","        if early_stop_counter >= patience:\n","            print(\"Early stopping\")\n","            break\n","\n","    return model, valid_max_accuracy"],"metadata":{"id":"mQkq3kBge2zT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# í•™ìŠµ ì§„í–‰ ì¤‘ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•©ë‹ˆë‹¤.\n","lr = 0.001\n","num_epochs = 1\n","patience = 3\n","model_name = 'LSTM'\n","\n","vocab_size = len(word_to_id)\n","embedding_dim = 4096\n","hidden_size = 4096\n","model = LSTM(vocab_size, embedding_dim, hidden_size).to(device)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index = 0)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","model, valid_max_accuracy = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":440,"referenced_widgets":["d327ee5bf5b740f9a0168996230b6cfb","5d0ef836c3a44a3e9ff8b0a227e3abdc","7ac73b08943d4ecda4e28b806cf1d0fc","0905c2e6e5d046beb756a381c9900589","f790999fc7cb477ca5613698615d4e6f","5ac08a2135d742098b9df667cf527383","23054ca7b6a646d2a4b97562765cadbe","c76ba883d3b548dd8928ba06dce2f7d4","9247eb218d214447bfc0473579337e72","14b8f642a1eb4be799508f65105d1fd2","60f5c65fef72482484821c9cee47d9a1"]},"id":"2ISTb3zMfBqg","executionInfo":{"status":"error","timestamp":1691292705449,"user_tz":-540,"elapsed":11547,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"fd15e59b-da1c-4f66-8017-9380cf4a00f6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d327ee5bf5b740f9a0168996230b6cfb"}},"metadata":{}},{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-1feda174053c>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_max_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-a3f14b50e52b>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-a3f14b50e52b>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# ìˆœì „íŒŒ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-f286809539eb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    813\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    814\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 10.77 GiB (GPU 0; 14.75 GiB total capacity; 8.49 GiB already allocated; 5.31 GiB free; 8.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["# batch_size ê°ì†Œ\n","batch_size = 256\n","\n","train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n","valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = False)\n","test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"],"metadata":{"id":"_PqouXBLgtvF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr = 0.001\n","num_epochs = 1\n","patience = 3\n","model_name = 'LSTM'\n","\n","vocab_size = len(word_to_id)\n","embedding_dim = 4096\n","hidden_size = 4096\n","model = LSTM(vocab_size, embedding_dim, hidden_size).to(device)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index = 0)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","model, valid_max_accuracy = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":98,"referenced_widgets":["305565c21ca34ba788d7eb87fe5817f6","8375ebff861e44bea59cfac1d214b194","aa68868934154c4e970b670212d25dcb","664407e80b2d4d358db674382803dc43","c66d2837eb814554b3d6eefde80adc62","34cfb887dd8f4d7ea32cf975dfcbfd39","096715831d3b42409b48362da7f1bd30","f2898fd1ae8b4cf7b42316d0bd621cc0","5c10324688034d47a55e90ac39989682","6368ec6b27f649f892831d17077053bd","f87166b68cbf4226a4cee26991c766c1","4335c20e43c4494e9844ced338fe93e5","4bd352a341a940068dc6e449f37ecbb7","0f43c75d13224254a497689e312ff0f8","bf0129c7c3c4446ea80d0c0e94d8425e","7525c4940a864cc980a4e3bc5d8aad53","d46bd413217e4aecafcb60f108736776","79d1f1343f3c41f7b54e115727c199c7","57e20eb5afa84eddbb4636bb67335756","a111b7deca7f44cdae5687410b87177e","6fc990c8e3f941248367a34ba9fbcf43","233a81482b054b0f8caa069f05bdcdee"]},"id":"eDJjWAxIiAWK","executionInfo":{"status":"ok","timestamp":1691293917355,"user_tz":-540,"elapsed":710385,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"4405b4dd-281b-4364-fa8b-ca57bb13f88c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/153 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"305565c21ca34ba788d7eb87fe5817f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4335c20e43c4494e9844ced338fe93e5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch [1/1], Train Loss: 6.6701, Train Accuracy: 0.1253 Valid Loss: 6.2977, Valid Accuracy: 0.1483\n"]}]},{"cell_type":"code","source":["# í° ì‚¬ì´ì¦ˆì˜ í…ì„œë¥¼ CUDA RAMì— í• ë‹¹í•©ë‹ˆë‹¤.\n","test_tensor = torch.randn((10000, 10000, 3)).to(device)"],"metadata":{"id":"aXL8nLGBjBt9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# torch.cuda.empty_cache() ì‹¤í–‰ ì „\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xS0QSj5-iE2j","executionInfo":{"status":"ok","timestamp":1690364662185,"user_tz":-540,"elapsed":23,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"e19c9b24-2235-4b40-da58-b470e7de0ddd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Jul 26 09:44:21 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P0    32W /  70W |   1745MiB / 15360MiB |     32%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# test_tensorë¥¼ del ëª…ë ¹ì„ í†µí•´ 'test_tensor' ê°ì²´ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.\n","del test_tensor\n","\n","# GPU ë©”ëª¨ë¦¬ ìºì‹œë¥¼ ë¹„ì›ë‹ˆë‹¤.\n","torch.cuda.empty_cache()"],"metadata":{"id":"18GFBrFEi9CL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# torch.cuda.empty_cache() ì‹¤í–‰ í›„\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WLPkyV8YjciH","executionInfo":{"status":"ok","timestamp":1690364662186,"user_tz":-540,"elapsed":21,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"ae1a75f2-cf4f-462c-bef1-759a4589d314"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Jul 26 09:44:21 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P0    32W /  70W |    599MiB / 15360MiB |      4%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["#### ğŸ“ ì„¤ëª…: `detach`, `cpu`\n","PyTorchì˜ tensorëŠ” ê¸°ë³¸ì ìœ¼ë¡œ gradientë¥¼ ê³„ì‚°í•˜ê³  ì—­ì „íŒŒë¥¼ ìœ„í•œ ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” GPU ë©”ëª¨ë¦¬ì— ì¶”ê°€ì ì¸ ë¶€ë‹´ì„ ì£¼ë©°, ì´ tensorë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜í•˜ë ¤ê³  í•˜ë©´ ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n","\n","ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ 'detach()'ë¥¼ í˜¸ì¶œí•˜ì—¬ gradientë¥¼ ê¸°ë¡í•˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ, tensorê°€ GPUì— ìˆì„ ê²½ìš°, CPUë¡œ ì˜®ê¸´ í›„ì— NumPy ë°°ì—´ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n","\n","\n","ğŸ“š êµ¬ê¸€ ê²€ìƒ‰ í‚¤ì›Œë“œ: ì—ëŸ¬ ë©”ì„¸ì§€\n","\n"],"metadata":{"id":"Wxad25P8mFCg"}},{"cell_type":"code","source":["pred = torch.tensor([1., 0., 1.], requires_grad = True)\n","label = torch.tensor([1., 0., 0.], requires_grad = True)\n","\n","pred = pred.numpy()\n","label = label.numpy()\n","\n","accuracy_score(label, pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"VQvK9GNrblp4","executionInfo":{"status":"error","timestamp":1690278718936,"user_tz":-540,"elapsed":444,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"5f226920-fdf6-4195-9338-76963b25f92b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-60d623d22480>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."]}]},{"cell_type":"code","source":["# ì¼ë°˜ì ìœ¼ë¡œ scikit learn metric ë“± numpy ndarrayë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ëª¨ë¸ì—ì„œ ì—°ì‚°ëœ ê²°ê³¼ë¬¼ì„ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n","# requires_gradì™€ cuda tensorë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\n","pred = torch.tensor([1., 0., 1.]).to(device)\n","label = torch.tensor([1., 0., 0.]).to(device)\n","\n","pred = pred.numpy()\n","label = label.numpy()\n","\n","accuracy_score(label, pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"FDTwiLlhl9vY","executionInfo":{"status":"error","timestamp":1690278744619,"user_tz":-540,"elapsed":377,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"96c4a0c2-e574-49a4-981e-f1071d525ff6"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-45143f68146f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."]}]},{"cell_type":"code","source":["# ì˜¬ë°”ë¥´ê²Œ êµ¬í˜„ëœ ì½”ë“œ\n","pred = torch.tensor([1., 0., 1.], requires_grad = True).to(device)\n","label = torch.tensor([1., 0., 0.], requires_grad = True).to(device)\n","\n","pred = pred.detach().cpu().numpy()\n","label = label.detach().cpu().numpy()\n","\n","accuracy_score(label, pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"isNGuIEeoIKx","executionInfo":{"status":"ok","timestamp":1690147310322,"user_tz":-540,"elapsed":3,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"2a36eb2f-92a6-4f3d-ad2f-2a0ffbec73fb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6666666666666666"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## 4. í”í•œ ì‹¤ìˆ˜ ì‚¬ë¡€\n","\n","```\n","ğŸ’¡ ëª©ì°¨ ê°œìš”: ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬í˜„í•˜ë©° í”íˆ ì‹¤ìˆ˜í•˜ëŠ” ë‚´ìš©ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n","   ì´ë²ˆ ì„¹ì…˜ì—ì„œ ì‹¤ìˆ˜í•˜ëŠ” ì‚¬ë¡€ë“¤ì€ ì½”ë“œì ì¸ ì˜¤ë¥˜ê°€ ì¡´ì¬í•˜ì§€ëŠ” ì•Šê¸° ë•Œë¬¸ì— ì—ëŸ¬ ë©”ì„¸ì§€ê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n","   í•˜ì§€ë§Œ ì‹¤ìˆ˜ì— ë”°ë¼ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ì¹˜ëª…ì ìœ¼ë¡œ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","```\n"],"metadata":{"id":"rSFUv0VErBkd"}},{"cell_type":"markdown","source":["#### ğŸ“ ì„¤ëª…: ì‹¤ìˆ˜ ì‚¬ë¡€\n","í”íˆ ì‹¤ìˆ˜í•˜ëŠ” ì‚¬ë¡€ë¡œëŠ” í¬ê²Œ ì„¸ ê°€ì§€ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n","1. **random seedë¥¼ ê³ ì •í•˜ì§€ ì•Šê³  í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹**: ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ê²°ê³¼ëŠ” ì´ˆê¸°í™”ì™€ ê°™ì€ random ìš”ì†Œì— í¬ê²Œ ì˜í–¥ì„ ë°›ìŠµë‹ˆë‹¤. ëª¨ë¸ì˜ í•™ìŠµì´ ë§¤ë²ˆ ë™ì¼í•œ ì¡°ê±´ì—ì„œ ì‹œì‘ë˜ë„ë¡ í•˜ê¸° ìœ„í•´, ì‹¤í—˜ì˜ ì¬í˜„ì„±ì„ ë³´ì¥í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•˜ëŠ” random seedë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n","\n","2. **`optim.zero_grad()`ë¥¼ í•˜ì§€ ì•ŠëŠ” ê²½ìš°**: PyTorchì—ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ gradientê°€ ëˆ„ì ë˜ë„ë¡ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ê° ë°°ì¹˜ì—ì„œ ì—­ì „íŒŒë¥¼ ì§„í–‰í•˜ê¸° ì „ì— ëª…ì‹œì ìœ¼ë¡œ gradientë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ë°ì´í„°ê°€ ëˆ„ì ë˜ì–´ í•™ìŠµì— ì‚¬ìš©ë˜ì§€ ì•Šë„ë¡ í•´ì•¼ í•©ë‹ˆë‹¤.\n","\n","3. **evaluation ë‹¨ê³„ì—ì„œ `model.eval()`ì„ í•˜ì§€ ì•Šì€ ê²½ìš°**: BatchNormì´ë‚˜ Dropout ê°™ì€ ì¼ë¶€ ë ˆì´ì–´ëŠ” í›ˆë ¨ ëª¨ë“œì™€ í‰ê°€ ëª¨ë“œì—ì„œ ë‹¤ë¥´ê²Œ ë™ì‘í•©ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬í˜„í•˜ë‹¤ ë³´ë©´, í•™ìŠµ ì½”ë“œì™€ í‰ê°€ ì½”ë“œë¥¼ ë‚˜ëˆ„ì–´ ë‘ëŠ” ê²½ìš°ê°€ ì¼ë°˜ì ì¸ë°, í‰ê°€ ì½”ë“œì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•˜ê¸°ë§Œ í•œë‹¤ë©´ BatchNorm, Dropout ë“±ì˜ ì¼ë¶€ ë ˆì´ì–´ëŠ” ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ í‰ê°€ ì‹œì—ëŠ” `model.eval()`ì„ ê¼­ í˜¸ì¶œí•˜ì—¬ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n","\n"],"metadata":{"id":"InZViRNZrrY0"}},{"cell_type":"code","source":["# 3ë²ˆ ì‚¬ë¡€ì—ì„œ dropout ë ˆì´ì–´ë¥¼ ëª¨ë¸ë¡œ ê°€ì •í•˜ê³  ì‹¤ìŠµí•©ë‹ˆë‹¤.\n","# dropout layerì—ì„œëŠ” tensorì˜ outputì´ '0'ë¡œ ì„¤ì •ë˜ê¸° ë•Œë¬¸ì—, í‰ê°€ ì‹œ ì‚¬ìš©í•  ë•ŒëŠ” dropoutì„ ë¹„í™œì„±í™” í•´ì•¼ í•©ë‹ˆë‹¤.\n","\n","model = nn.Dropout(0.5)\n","\n","# ëœë¤í•˜ê²Œ ìƒì„±í•œ tensor\n","input_tensor = torch.randn(5, 10)\n","\n","# Dropout in Training Mode\n","model.train()\n","output_train = model(input_tensor)\n","print(\"Output in Training Mode: \\n\", output_train)\n","\n","print(\"\\n\")\n","# Dropout in Evaluation Mode\n","model.eval()\n","output_eval = model(input_tensor)\n","print(\"Output in Evaluation Mode: \\n\", output_eval)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4_Vs3yAMrpG3","executionInfo":{"status":"ok","timestamp":1690148819598,"user_tz":-540,"elapsed":3,"user":{"displayName":"â€ìœ í™˜ìŠ¹[ì¡¸ì—…ìƒ / ë°”ì´ì˜¤ë©”ë””ì»¬ê³µí•™ì „ê³µ]","userId":"11562210152573735741"}},"outputId":"8d9bfe84-eec0-4daf-b2b1-e5612b594555"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Output in Training Mode: \n"," tensor([[-0.0000,  0.0800, -0.0000, -1.6276, -3.7987,  0.0000,  0.0224,  0.0000,\n","         -0.4158,  1.4847],\n","        [-0.0000, -0.0000, -1.5982, -0.2413, -0.0889,  2.8080, -0.0000,  0.0000,\n","         -1.9399, -0.0000],\n","        [ 0.9740,  0.0000,  0.0000,  1.6898, -0.4581,  0.0000, -0.0000, -1.2434,\n","         -2.6227,  0.0000],\n","        [ 0.0000, -1.0533,  1.1514,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000,\n","         -0.3282,  1.1166],\n","        [ 1.1275,  0.0000, -0.0000, -2.1059, -0.0000,  3.6567,  0.9929,  0.0000,\n","         -0.0000,  3.6460]])\n","\n","\n","Output in Evaluation Mode: \n"," tensor([[-0.1918,  0.0400, -1.2375, -0.8138, -1.8994,  0.0333,  0.0112,  0.3753,\n","         -0.2079,  0.7423],\n","        [-0.2489, -0.0378, -0.7991, -0.1207, -0.0444,  1.4040, -0.1574,  0.0917,\n","         -0.9700, -0.1417],\n","        [ 0.4870,  0.1062,  0.3865,  0.8449, -0.2290,  1.9565, -0.8436, -0.6217,\n","         -1.3114,  1.2831],\n","        [ 1.4974, -0.5266,  0.5757,  0.8682,  0.9398, -1.2513,  0.8596, -0.1509,\n","         -0.1641,  0.5583],\n","        [ 0.5637,  0.8667, -0.7867, -1.0529, -0.2489,  1.8284,  0.4965,  0.3708,\n","         -1.6801,  1.8230]])\n"]}]},{"cell_type":"markdown","source":["## Required Package\n","\n","> torch == 2.0.1\n","\n","> torchtext == 0.15.2"],"metadata":{"id":"B0XKnrD7uTns"}},{"cell_type":"markdown","source":["## ì½˜í…ì¸  ë¼ì´ì„ ìŠ¤\n","\n","ì €ì‘ê¶Œ : <font color='blue'> <b> Â©2023 by Upstage X fastcampus Co., Ltd. All rights reserved.</font></b>\n","\n","<font color='red'><b>WARNING</font> : ë³¸ êµìœ¡ ì½˜í…ì¸ ì˜ ì§€ì‹ì¬ì‚°ê¶Œì€ ì—…ìŠ¤í…Œì´ì§€ ë° íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ì— ê·€ì†ë©ë‹ˆë‹¤. ë³¸ ì½˜í…ì¸ ë¥¼ ì–´ë– í•œ ê²½ë¡œë¡œë“  ì™¸ë¶€ë¡œ ìœ ì¶œ ë° ìˆ˜ì •í•˜ëŠ” í–‰ìœ„ë¥¼ ì—„ê²©íˆ ê¸ˆí•©ë‹ˆë‹¤. </b>"],"metadata":{"id":"hivVGQ9Gubxp"}},{"cell_type":"code","source":[],"metadata":{"id":"sreOCGkNiBsI"},"execution_count":null,"outputs":[]}]}