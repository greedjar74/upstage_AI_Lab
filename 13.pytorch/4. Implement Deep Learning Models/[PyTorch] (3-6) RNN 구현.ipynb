{"cells":[{"cell_type":"markdown","metadata":{"id":"biI2UMXHon5o"},"source":["# RNN 구현"]},{"cell_type":"markdown","metadata":{"id":"zOtbGaE_ojQA"},"source":["## 실습 개요\n","\n","1) **실습 목적**\n","\n","이번 실습은 이론으로 배웠던 PyTorch를 이용하여 RNN 계열의 모델들을 직접 구현해보고 학습 및 평가를 하도록 합니다.\n","\n","\n","\n","2) **수강 목표**\n","\n","- Next word prediction을 위한 RNN계열의 모델을 직접 구현하고 학습 및 평가를 할 수 있다.\n","- 다양한 RNN모델들을 직접 구현할 수 있다.\n","- RNN의 다양한 변형을 직접 실습할 수 있다."]},{"cell_type":"markdown","metadata":{"id":"vUnGWX59ybEk"},"source":["### 실습 목차\n","* 1. Vanilla RNN\n","  * 1.1 Vanilla RNN 모델 구현하기\n","  * 1.2 훈련 및 평가\n","* 2. LSTM\n","  * 2.1 LSTM 모델 구현하기\n","  * 2.2 훈련 및 평가\n","* 3. GRU\n","  * 3.1 GRU 모델 구현하기\n","  * 3.2 훈련 및 평가\n","\n","* 4. bi-directional RNN/GRU/LSTM\n","  * 4.1 bi-direcitional RNN/GRU/LSTM 모델 구현하기\n","  * 4.2 훈련 및 평가"]},{"cell_type":"markdown","metadata":{"id":"3F2fMLWA31Ft"},"source":["### 환경 설정\n","\n","- 패키지 설치 및 임포트"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37891,"status":"ok","timestamp":1691914634464,"user":{"displayName":"김영민","userId":"04915862517565535031"},"user_tz":-540},"id":"_wvClBdFmDml","outputId":"82ae1a6b-7222-4f86-b8df-5acfe0b08643"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.11/site-packages/PyBioMed-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["#!pip install scikit-learn==1.3.0 -q\n","#!pip install torch==2.0.1 -q\n","#!pip install torchvision==0.15.2 -q\n","!pip install torchtext==0.15.2 -q"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"GKbkjkhbiPNt","tags":[]},"outputs":[],"source":["import numpy as np # 기본적인 연산을 위한 라이브러리\n","import matplotlib.pyplot as plt # 그림이나 그래프를 그리기 위한 라이브러리\n","from tqdm.notebook import tqdm # 상태 바를 나타내기 위한 라이브러리\n","import pandas as pd # 데이터프레임을 조작하기 위한 라이브러리\n","\n","import torch # PyTorch 라이브러리\n","import torch.nn as nn # 모델 구성을 위한 라이브러리\n","import torch.optim as optim # optimizer 설정을 위한 라이브러리\n","from torch.utils.data import Dataset, DataLoader # 데이터셋 설정을 위한 라이브러리\n","import torch.nn.functional as F # torch에서 수학적인 function을 쉽게 불러오기 위한 라이브러리\n","\n","from torchtext.data import get_tokenizer # torch에서 tokenizer를 얻기 위한 라이브러리\n","import torchtext # torch에서 text를 더 잘 처리하기 위한 라이브러리\n","\n","from sklearn.metrics import accuracy_score # 성능지표 측정\n","from sklearn.model_selection import train_test_split # train-validation-test set 나누는 라이브러리\n","\n","import re # text 전처리를 위한 라이브러리"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qnIkzdqds7t4","tags":[]},"outputs":[],"source":["# seed 고정\n","import random\n","import torch.backends.cudnn as cudnn\n","\n","def random_seed(seed_num):\n","    torch.manual_seed(seed_num)\n","    torch.cuda.manual_seed(seed_num)\n","    torch.cuda.manual_seed_all(seed_num)\n","    np.random.seed(seed_num)\n","    cudnn.benchmark = False\n","    cudnn.deterministic = True\n","    random.seed(seed_num)\n","\n","random_seed(42)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"PNQgFf_x4daH","tags":[]},"outputs":[],"source":["device = 'cpu'"]},{"cell_type":"markdown","metadata":{"id":"Fs0LWFQhdOsU"},"source":["###  데이터 셋 개요 </b>\n","\n","* 데이터셋: <a href='https://www.kaggle.com/datasets/dorianlazar/medium-articles-dataset'>Medium Dataset</a>\n","* 데이터셋 개요: \"Towards Data Science\", \"UX Collective\", \"The Startup\", \"The Writing Cooperative\", \"Data Driven Investor\", \"Better Humans\", \"Better Marketing\" 의 7개의 주제를 가지는 publication 에 대해서 크롤링을 한 데이터입니다. 원본 데이터는 총 6,508개의 블로그 이미지와 메타 데이터(.csv)로 구성됩니다. 실습에서는 메타데이터를 사용하여 CustomDataset을 구현합니다.\n","  * [How to collect ths dataset?](https://dorianlazar.medium.com/scraping-medium-with-python-beautiful-soup-3314f898bbf5)\n","- 메타 데이터 스키마: 메타 데이터는 총 **10**개의 column으로 구성됩니다.\n","  - id: 아이디\n","  - url: 포스팅 링크\n","  - title: 제목\n","  - subtitle: 부제목\n","  - image: 포스팅 이미지의 파일 이름\n","  - claps: 추천 수\n","  - reponses: 댓글 수\n","  - reading_time: 읽는데 걸리는 시간\n","  - publication: 주제 카테고리(e.g. Towards Data Science..)\n","  - date: 작성 날짜\n","- 데이터 셋 저작권: CC0: Public Domain"]},{"cell_type":"markdown","metadata":{"id":"ga4KpW8DED_Q"},"source":["## 1. Vanilla RNN 구현하기\n","\n","```\n","💡 목차 개요: 기본적인 RNN 구조를 이해하고, 이를 PyTorch로 RNN 모델을 구현해봅니다.\n","```\n","\n","- 1-1. Vanilla RNN 구현하기\n","- 1-2. 학습 및 평가\n"]},{"cell_type":"markdown","metadata":{"id":"7a3AnRDwEu4u"},"source":["### 1-1 Vanilla RNN 구현하기\n","\n","> `torch.nn.RNN`을 통해 RNN 모델을 구현할 수 있습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"_1mA-15ZFSwp"},"source":["#### 📝 설명: Vanilla RNN이란?\n","<img src='https://upload.wikimedia.org/wikipedia/commons/0/05/RNN.png'></img>\n","* RNN 모델은 recurrent neural network로 입력과 출력을 sequence 단위로 처리하는 모델입니다.\n","  * sequence는 순서대로 배열된 데이터들의 집합으로 순차적으로 연결되어 있고, 각 항목은 특정 순서에 따라 나열되어 있습니다.\n","  * ex)  \"Hello, how are you?\"라는 문장은 \"Hello\", \",\", \"how\", \"are\", \"you\", \"?\"라는 단어들이 순서대로 나열되어 있는 sequence 입니다.\n","* DNN과 달리 RNN은 시간의 흐름에 따라 정보를 공유할 수 있으며, 이로 인해 이전 단계에서 얻은 정보가 현재 단계에서 영향을 미치게 됩니다.\n","* RNN은 이전 단계의 은닉 상태(hidden states)와 현재 입력을 사용하여 다음 단계의 은닉 상태를 계산하는 방식으로 구성이 되어, 과거의 정보와 현재의 정보를 모두 이용하는 방식으로 구현되어 있습니다.\n","  * 처음에는 zero-vector로 초기화 되거나 random으로 초기화 됩니다.\n","\n","\n","\n","\n","\n","📚 참고할만한 자료:\n","* [이미지 출처](https://commons.wikimedia.org/wiki/File:RNN.png)\n","* [RNN 설명](https://wikidocs.net/22886)"]},{"cell_type":"markdown","metadata":{"id":"Rs0rlqgG4daI"},"source":["#### 📝 설명: Next word prediction을 위한 데이터셋을 구현\n","* DNN 구현(3)에서 다뤘던 데이터셋으로 custom dataset class를 구현합니다.\n","\n","📚 참고할만한 자료:\n","* [데이터 다운로드](https://www.kaggle.com/datasets/dorianlazar/medium-articles-dataset)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"caGRiSrk4daJ","tags":[]},"outputs":[],"source":["# DNN 에서 갖고 오기\n","data_csv = pd.read_csv('./data/medium_data.csv')\n","data = data_csv['title']"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url</th>\n","      <th>title</th>\n","      <th>subtitle</th>\n","      <th>image</th>\n","      <th>claps</th>\n","      <th>responses</th>\n","      <th>reading_time</th>\n","      <th>publication</th>\n","      <th>date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>https://towardsdatascience.com/a-beginners-gui...</td>\n","      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n","      <td>NaN</td>\n","      <td>1.png</td>\n","      <td>850</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>https://towardsdatascience.com/hands-on-graph-...</td>\n","      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n","      <td>NaN</td>\n","      <td>2.png</td>\n","      <td>1100</td>\n","      <td>11</td>\n","      <td>9</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>https://towardsdatascience.com/how-to-use-ggpl...</td>\n","      <td>How to Use ggplot2 in Python</td>\n","      <td>A Grammar of Graphics for Python</td>\n","      <td>3.png</td>\n","      <td>767</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>https://towardsdatascience.com/databricks-how-...</td>\n","      <td>Databricks: How to Save Files in CSV on Your L...</td>\n","      <td>When I work on Python projects dealing…</td>\n","      <td>4.jpeg</td>\n","      <td>354</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>https://towardsdatascience.com/a-step-by-step-...</td>\n","      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n","      <td>One example of building neural…</td>\n","      <td>5.jpeg</td>\n","      <td>211</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                                                url  \\\n","0   1  https://towardsdatascience.com/a-beginners-gui...   \n","1   2  https://towardsdatascience.com/hands-on-graph-...   \n","2   3  https://towardsdatascience.com/how-to-use-ggpl...   \n","3   4  https://towardsdatascience.com/databricks-how-...   \n","4   5  https://towardsdatascience.com/a-step-by-step-...   \n","\n","                                               title  \\\n","0  A Beginner’s Guide to Word Embedding with Gens...   \n","1  Hands-on Graph Neural Networks with PyTorch & ...   \n","2                       How to Use ggplot2 in Python   \n","3  Databricks: How to Save Files in CSV on Your L...   \n","4  A Step-by-Step Implementation of Gradient Desc...   \n","\n","                                  subtitle   image  claps responses  \\\n","0                                      NaN   1.png    850         8   \n","1                                      NaN   2.png   1100        11   \n","2         A Grammar of Graphics for Python   3.png    767         1   \n","3  When I work on Python projects dealing…  4.jpeg    354         0   \n","4          One example of building neural…  5.jpeg    211         3   \n","\n","   reading_time           publication        date  \n","0             8  Towards Data Science  2019-05-30  \n","1             9  Towards Data Science  2019-05-30  \n","2             5  Towards Data Science  2019-05-30  \n","3             4  Towards Data Science  2019-05-30  \n","4             4  Towards Data Science  2019-05-30  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data_csv.head()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"tt_g2TKY4daJ","tags":[]},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, data, vocab, tokenizer, max_len):\n","        self.data = data\n","        self.vocab = vocab\n","        self.max_len = max_len # 최대 길이 -> 각각의 데이터는 길이가 다르다 -> 모두 동일하게 맞춰주기 위해 사용\n","        self.tokenizer = tokenizer\n","        seq = self.make_sequence(self.data, self.vocab, self.tokenizer) # next word prediction을 하기 위한 형태로 변환\n","        self.seq = self.pre_zeropadding(seq, self.max_len) # zero padding으로 채워줌 -> 모든 데이터의 길이를 맞춰준다.\n","        self.X = torch.tensor(self.seq[:,:-1])\n","        self.label = torch.tensor(self.seq[:,-1])\n","\n","    def make_sequence(self, data, vocab, tokenizer):\n","        seq = []\n","        for i in data:\n","            token_id = vocab.lookup_indices(tokenizer(i))\n","            for j in range(1, len(token_id)):\n","                sequence = token_id[:j+1]\n","                seq.append(sequence)\n","        return seq\n","\n","    def pre_zeropadding(self, seq, max_len): # max_len 길이에 맞춰서 0 으로 padding 처리 (앞부분에 padding 처리)\n","        return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","\n","    def __len__(self): # dataset의 전체 길이 반환\n","        return len(self.X)\n","\n","    def __getitem__(self, idx): # dataset 접근\n","        X = self.X[idx]\n","        label = self.label[idx]\n","\n","        return X, label"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"xm-Sua4t4daJ","tags":[]},"outputs":[],"source":["def cleaning_text(text):\n","    cleaned_text = re.sub( r\"[^a-zA-Z0-9.,@#!\\s']+\", \"\", text) # 특수문자 를 모두 지우는 작업을 수행합니다.\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # No-break space를 unicode 빈칸으로 변환\n","    cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode 빈칸을 빈칸으로 변환\n","    return cleaned_text"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"IK7yCCNc4daJ","tags":[]},"outputs":[],"source":["data = list(map(cleaning_text, data))\n","tokenizer = get_tokenizer(\"basic_english\")\n","vocab = torchtext.vocab.build_vocab_from_iterator(map(tokenizer, data))\n","vocab.insert_token('<pad>',0)\n","max_len = 20"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"i_nUEtaz9jBi","outputId":"e22d7010-4be3-4ac2-9dcb-f9ec6cf1fb02","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Train 개수:  5206\n","Validation 개수:  651\n","Test 개수:  651\n"]}],"source":["# train set과 validation set, test set을 각각 나눕니다. 8 : 1 : 1 의 비율로 나눕니다.\n","train, test = train_test_split(data, test_size = .2, random_state = 42)\n","val, test = train_test_split(test, test_size = .5, random_state = 42)\n","print(\"Train 개수: \", len(train))\n","print(\"Validation 개수: \", len(val))\n","print(\"Test 개수: \", len(test))\n","\n","train_dataset = CustomDataset(train, vocab, tokenizer, max_len)\n","valid_dataset = CustomDataset(val, vocab, tokenizer, max_len)\n","test_dataset = CustomDataset(test, vocab, tokenizer, max_len)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"-YqQonc74daK","tags":[]},"outputs":[],"source":["batch_size = 32\n","\n","train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n","valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = False)\n","test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"]},{"cell_type":"markdown","metadata":{"id":"ovJAajj83_bq"},"source":["#### 📝 설명: PyTorch에서의 RNN 구현은 어떻게 할까?\n","* RNN은 `torch.nn.RNN`을 통해 쉽게 구현할 수 있습니다.\n","* torch.nn.RNN은 t시점의 hidden state를 계산해주는 역할을 합니다.\n","* torch.nn.RNN은 기본적으로 `input_size`와 `hidden_size`를 지정해줘야합니다.\n","  * `input_size`: embedding dimension\n","  * `hidden_size`: hidden state dimension\n","\n","📚 참고할만한 자료:\n","* [PyTorch RNN 공식 document](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)"]},{"cell_type":"markdown","metadata":{"id":"gw4zHH9v4daK"},"source":["#### 📝 설명: Next word prediction를 위한 RNN 모델 구현\n","* Next word prediction 작업에서는 주어진 입력 시퀀스로부터 다음 단어를 예측하는 것이 목표입니다.\n","* 이때, 일반적으로 주어진 시퀀스 내에서 **마지막 time step의 hidden state**를 사용합니다.\n","  * RNN은 이전 time step의 정보를 현재 time step으로 전달하는 방식이기 때문에, 모든 이전 time step의 정보를 담고 있는 마지막 time step의 hidden state를 사용하면 문맥 정보를 잘 반영할 수 있습니다.\n","* torch.RNN의 output은 모든 time step의 정보를 담고 있는 hidden state와 마지막 time_step의 정보만 담고 있는 hidden state 두개를 반환합니다.\n","  * 여기서 우리는 코딩의 편리성을 위해, 모든 정보를 담고 있는 hidden state를 사용하여 마지막 time_step의 정보만 따로 추출합니다.\n","  * 마지막 time_step의 정보만 담고 있는 hidden state의 shape은 RNN의 layer 개수와 나중에 학습하는 bidirectional 인자에 의해 영향을 받기 때문입니다."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"GdB2jJ4g4daK","tags":[]},"outputs":[],"source":["class RNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size):\n","        super(RNN, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0) # 단어 임베딩\n","\n","        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True) # batch_first=True는 입력의 첫 번째 차원이 batch 크기임을 나타냅니다.\n","\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, x):\n","        '''\n","        INPUT:\n","           x: [batch_size, seq_len]\n","        OUTPUT:\n","           output: [batch_size, vocab_size]\n","        '''\n","        x = self.embedding(x) # [batch_size, sequence_len, embedding_dim]\n","\n","        # 첫 번째 리턴값인 output은 모든 time step의 hidden state를 포함한 출력입니다.\n","        # 두 번째 리턴값인 h_0 는 마지막 time step의 hidden state를 의미합니다.\n","        output, h_0 = self.rnn(x) # output: [batch_size, seq_len, hidden_dim] / h_0: [1, batch_size, hidden_dim]\n","        return self.fc(output[:,-1,:]) # [batch_size, vocab_size]"]},{"cell_type":"markdown","metadata":{"id":"P4biQ_HH4daL"},"source":["### 1-2 학습 및 평가\n","\n","> 학습 및 평가 코드를 직접 작성하고, 다음에 나올 단어를 예측할 수 있는 추론 코드를 작성해봅니다.\n"]},{"cell_type":"markdown","metadata":{"id":"qLpA5JOW4daL"},"source":["#### 📝 설명: 학습 및 평가하기\n","* RNN의 학습 방법은 앞서 배웠던 DNN, CNN과 동일하게 진행됩니다.\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"U2SWum8-4daL","tags":[]},"outputs":[],"source":["# training 코드, evaluation 코드, training_loop 코드\n","def training(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs):\n","    model.train()  # 모델을 학습 모드로 설정\n","    train_loss = 0.0\n","    train_accuracy = 0\n","\n","    tbar = tqdm(dataloader)\n","    for texts, labels in tbar:\n","        # 순전파\n","        outputs = model(texts)\n","        loss = criterion(outputs, labels)\n","\n","        # 역전파 및 가중치 업데이트\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # 손실과 정확도 계산\n","        train_loss += loss.item()\n","        # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n","        _, predicted = torch.max(outputs, dim=1)\n","\n","\n","        train_accuracy += (predicted == labels).sum().item()\n","\n","        # tqdm의 진행바에 표시될 설명 텍스트를 설정\n","        tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}\")\n","\n","    # 에폭별 학습 결과 출력\n","    train_loss = train_loss / len(dataloader)\n","    train_accuracy = train_accuracy / len(train_dataset)\n","\n","    return model, train_loss, train_accuracy\n","\n","def evaluation(model, dataloader, valid_dataset, criterion, device, epoch, num_epochs):\n","    model.eval()  # 모델을 평가 모드로 설정\n","    valid_loss = 0.0\n","    valid_accuracy = 0\n","\n","    with torch.no_grad(): # model의 업데이트 막기\n","        tbar = tqdm(dataloader)\n","        for texts, labels in tbar:\n","            # 순전파\n","            outputs = model(texts)\n","            loss = criterion(outputs, labels)\n","\n","            # 손실과 정확도 계산\n","            valid_loss += loss.item()\n","            # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n","            _, predicted = torch.max(outputs, 1)\n","            # _, true_labels = torch.max(labels, dim=1)\n","            valid_accuracy += (predicted == labels).sum().item()\n","\n","\n","            # tqdm의 진행바에 표시될 설명 텍스트를 설정\n","            tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Valid Loss: {loss.item():.4f}\")\n","\n","    valid_loss = valid_loss / len(dataloader)\n","    valid_accuracy = valid_accuracy / len(valid_dataset)\n","\n","    return model, valid_loss, valid_accuracy\n","\n","\n","def training_loop(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name):\n","    best_valid_loss = float('inf')  # 가장 좋은 validation loss를 저장\n","    early_stop_counter = 0  # 카운터\n","    valid_max_accuracy = -1\n","\n","    for epoch in range(num_epochs):\n","        model, train_loss, train_accuracy = training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\n","        model, valid_loss, valid_accuracy = evaluation(model, valid_dataloader, val_dataset, criterion, device, epoch, num_epochs)\n","\n","        if valid_accuracy > valid_max_accuracy:\n","            valid_max_accuracy = valid_accuracy\n","\n","        # validation loss가 감소하면 모델 저장 및 카운터 리셋\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            torch.save(model.state_dict(), f\"./model_{model_name}.pt\")\n","            early_stop_counter = 0\n","\n","        # validation loss가 증가하거나 같으면 카운터 증가\n","        else:\n","            early_stop_counter += 1\n","\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f} Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\")\n","\n","        # 조기 종료 카운터가 설정한 patience를 초과하면 학습 종료\n","        if early_stop_counter >= patience:\n","            print(\"Early stopping\")\n","            break\n","\n","    return model, valid_max_accuracy"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"referenced_widgets":["feac82a744794495ba18c72a03aa6731","260c7b7ec92a4299879c186396627ad7","4c3497bee69740c9897c26b55ec4c3d0","167ea8861b2e40c0ba48f91462d037a6","70eeff7482854c348eab9dd855cc7ffa","cc89d602997646efb66d2892af40e072","3662fcf89f464975b1ee913ac71f52b6","9b937de5fde7426d8f42016d49766a23","75666c7ac1ab4116b2d3cbc79194cd67","b02de07f2650464093ce935e4c748a05","0ae76e0256724b69b3f9c0e9cd5546a9","bd1b0f64e29749e691a1f80af198207d","d5545591b7e340278d9067c770299768","a28d71d17d844db9ab8e1f1bfb61d727","1bb9763b449a4c108f19a50d83ecdeca","7f29b845c4254909a84d3ec613ee3c82"]},"id":"VgYMR1Hc4daL","outputId":"275e930e-a66f-47cb-e09d-7b16a3e0886e","tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8265207a341a451c9706033880e4a2e1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1159 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5007101a74fb458490fd33bfc0c16436","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/149 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch [1/100], Train Loss: 7.0220, Train Accuracy: 0.1110 Valid Loss: 6.8250, Valid Accuracy: 0.1334\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb53a23d64c540a8b6999f73e9ae6da9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1159 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"163d739195904fc8b68ebfa350a48075","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/149 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch [2/100], Train Loss: 5.3991, Train Accuracy: 0.1641 Valid Loss: 6.9634, Valid Accuracy: 0.1349\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d81ec6f2bd8345878251988985f83e2b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1159 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ebef1ccef4b431a8ecc170e55d5fed7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/149 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch [3/100], Train Loss: 4.2817, Train Accuracy: 0.2244 Valid Loss: 7.2059, Valid Accuracy: 0.1321\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20f1d08406b249d6aca365dcfaf7a82b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1159 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e063a2bd26345ceb1b7aeb9c3e6884e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/149 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch [4/100], Train Loss: 3.3846, Train Accuracy: 0.3325 Valid Loss: 7.4951, Valid Accuracy: 0.1254\n","Early stopping\n","Valid max accuracy :  0.1348670325031659\n"]}],"source":["num_epochs = 100\n","patience = 3\n","model_name = 'RNN'\n","\n","vocab_size = len(vocab)\n","embedding_dim = 512\n","hidden_size = 256\n","model = RNN(vocab_size, embedding_dim, hidden_size).to(device)\n","\n","lr = 1e-3\n","criterion = nn.CrossEntropyLoss(ignore_index = 0)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","model, valid_max_accuracy = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\n","print('Valid max accuracy : ', valid_max_accuracy)"]},{"cell_type":"markdown","metadata":{"id":"j73JhE3C4daL"},"source":["#### 📝 설명: Next word prediction 평가\n","* 학습한 RNN 모델을 accuracy score로 평가합니다."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"referenced_widgets":["875b229676a74855bda020cb76ff3eca","0509ce952a72425fa25bebbfed96fa0d"]},"id":"dY4ATZV_4daM","outputId":"52de8776-80d9-4932-fd94-21ae356f5404","tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c68bc93c6df4643b630003850895b43","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Next word prediction RNN model accuracy :  0.12860892388451445\n"]}],"source":["model.load_state_dict(torch.load(\"./model_RNN.pt\")) # 모델 불러오기\n","model = model.to(device)\n","model.eval()\n","total_labels = []\n","total_preds = []\n","with torch.no_grad():\n","    for texts, labels in tqdm(test_dataloader):\n","        texts = texts.to(device)\n","        labels = labels\n","\n","        outputs = model(texts)\n","        # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        total_preds.extend(predicted.detach().cpu().tolist())\n","        total_labels.extend(labels.tolist())\n","\n","total_preds = np.array(total_preds)\n","total_labels = np.array(total_labels)\n","nwp_rnn_acc = accuracy_score(total_labels, total_preds) # 정확도 계산\n","print(\"Next word prediction RNN model accuracy : \", nwp_rnn_acc)"]},{"cell_type":"markdown","metadata":{"id":"IyS_cf8mGGL3"},"source":["## 2. LSTM 구현하기\n","\n","```\n","💡 목차 개요: 기본적인 LSTM 구조를 이해하고, 이를 PyTorch로 LSTM 모델을 구축해봅니다.\n","```\n","\n","- 2-1. LSTM 구현하기\n","- 2-2. 학습 및 평가\n"]},{"cell_type":"markdown","metadata":{"id":"MoVwB9f-GGMD"},"source":["### 2-1 LSTM 구현하기\n","\n","> `torch.nn.LSTM`을 통해 LSTM 모델을 구현할 수 있습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"i_1Rj6B5__dh"},"source":["#### 📝 설명: LSTM이란?\n","<img src='https://upload.wikimedia.org/wikipedia/commons/9/98/LSTM.png'></img>\n","* LSTM (Long Short-Term Memory)의 약자로 RNN의 단점인 장기 의존성 문제를 해결하기 위해 고안된 모델입니다.\n","  * RNN의 장기 의존성 문제: 시퀀스가 길어질수록 앞부분의 정보가 뒷부분의 예측에 영향을 미치기 어려운 문제\n","\n","<!-- * LSTM의 게이트\n","  * Input gate: 새로운 입력을 기억하는데 사용됩니다. 이 게이트는 어떤 정보를 얼마만큼 기억할지 결정하는 역할을 합니다.\n","\n","  * Forget gate: 과거 정보를 얼마만큼 삭제할지 결정하는 역할을 합니다. 이를 통해 불필요한 정보를 제거하고 장기 의존성 문제를 완화합니다.\n","\n","  * Output gate: 현재 시점의 은닉 상태를 계산하는데 사용됩니다. LSTM이 다음 시점으로 얼마만큼 정보를 전달할지 결정하는 역할을 합니다. -->\n","\n","\n","📚 참고할만한 자료:\n","* [LSTM paper](https://dl.acm.org/doi/10.1162/neco.1997.9.8.1735)\n","* [LSTM 설명](https://dgkim5360.tistory.com/entry/understanding-long-short-term-memory-lstm-kr)\n","* [이미지 출처](https://commons.wikimedia.org/wiki/File:LSTM.png)\n"]},{"cell_type":"markdown","metadata":{"id":"tIzlbxBUEJPf"},"source":["#### 📝 설명: PyTorch에서의 LSTM 구현은 어떻게 할까?\n","* LSTM은 `torch.nn.LSTM`을 통해 쉽게 구현할 수 있습니다.\n","* torch.nn.LSTM RNN과 동일하게 기본적으로 `input_size`와 `hidden_size`를 지정해줘야합니다.\n","  * `input_size`: embedding dimension\n","  * `hidden_size`: hidden state dimension\n","* 일반적으로 RNN과 동일하게 마지막 time step의 hidden state 정보만 추출하여 사용합니다.\n","* torch.LSTM의 output은 모든 time step의 정보를 담고 있는 hidden state와 마지막 time_step의 정보만 담고 있는 hidden state, 그리고 마지막 time_step의 정보만 담고 있는 cell state까지 3개를 반환합니다.\n","📚 참고할만한 자료:\n","* [PyTorch LSTM 공식 document](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"ryXXTEN34daN","tags":[]},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class LSTM(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size):\n","        super(LSTM, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, x):\n","        '''\n","        INPUT:\n","           x: [batch_size, seq_len]\n","        OUTPUT:\n","           output: [batch_size, vocab_size]\n","        '''\n","        x = self.embedding(x) # [batch_size, sequence_len, embedding_dim]\n","        # lstm에선 마지막 time step에서의 cell state (c_n)도 반환합니다.\n","        output, h_0, c_0 = self.lstm(x) # output : [batch_size, seq_len, hidden_dim] # h_n: [1, batch_size, hidden_dim] # c_n: [1, batch_size, hidden_dim]\n","        return self.fc(output[:,-1,:]) # [batch_size, num_classes]\n"]},{"cell_type":"markdown","metadata":{"id":"putvSavw4daN"},"source":["#### 📝 설명: 학습 및 평가하기\n","* LSTM의 학습 방법은 앞서 배웠던 DNN, CNN과 동일하게 진행됩니다."]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"referenced_widgets":["e6dfadbea0dd43d191a31a092404d956","78d9a11989a34baebb903a4d245fe8dd","5ba8eeb79bd74a7c836a94b65e6e75af","9fe554fa3dca45b38d2b794aa9f51dbf","c20d5ed497724412bb131fd684826fbe","5860a075e8254093b54b12ce960b857d","916af6d32b344ce1af8e7bcaa9f4696b","0f920f9b46684f6a84078b360d542e3a","cadcfc6b16534bdaa1b0c89b94a3f552","04ad08c29e2047de83dd02d54c354a4a","35dbb80110124fb6ac41d21ece97f754","430959f2f2404f1a8ad7267e02f0edfb","0e676f673a404111bbcfd358917387a7","0a34926e16734958ba26e23f631f1772","5336d80808b149909890f00a2b8c3a1c","4195af8101e645e4b15e0b8498c4a1a3","04c1af917851464e88d063f812857ce1","4a112f6b17764aa7a9a1b04fbebd17ae"]},"id":"qLFTn4g54daN","outputId":"13183ec8-1d3b-4e6c-cd4f-6ea4787a0f74","tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ea8028e3e684d7ba18331d93a289c8f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1159 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"ValueError","evalue":"not enough values to unpack (expected 3, got 2)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m---> 14\u001b[0m model, valid_max_accuracy \u001b[38;5;241m=\u001b[39m training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValid max accuracy : \u001b[39m\u001b[38;5;124m'\u001b[39m, valid_max_accuracy)\n","Cell \u001b[0;32mIn[17], line 70\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\u001b[0m\n\u001b[1;32m     67\u001b[0m valid_max_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 70\u001b[0m     model, train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\n\u001b[1;32m     71\u001b[0m     model, valid_loss, valid_accuracy \u001b[38;5;241m=\u001b[39m evaluation(model, valid_dataloader, val_dataset, criterion, device, epoch, num_epochs)\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_accuracy \u001b[38;5;241m>\u001b[39m valid_max_accuracy:\n","Cell \u001b[0;32mIn[17], line 10\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m tbar \u001b[38;5;241m=\u001b[39m tqdm(dataloader)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m texts, labels \u001b[38;5;129;01min\u001b[39;00m tbar:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# 순전파\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(texts)\n\u001b[1;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# 역전파 및 가중치 업데이트\u001b[39;00m\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[24], line 20\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x) \u001b[38;5;66;03m# [batch_size, sequence_len, embedding_dim]\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# lstm에선 마지막 time step에서의 cell state (c_n)도 반환합니다.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m output, h_0, c_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x) \u001b[38;5;66;03m# output : [batch_size, seq_len, hidden_dim] # h_n: [1, batch_size, hidden_dim] # c_n: [1, batch_size, hidden_dim]\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:])\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"]}],"source":["num_epochs = 100\n","patience = 3\n","model_name = 'LSTM'\n","\n","vocab_size = len(vocab)\n","embedding_dim = 512\n","hidden_size = 256\n","model = LSTM(vocab_size, embedding_dim, hidden_size).to(device)\n","\n","lr = 1e-3\n","criterion = nn.CrossEntropyLoss(ignore_index = 0)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","model, valid_max_accuracy = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\n","print('Valid max accuracy : ', valid_max_accuracy)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"referenced_widgets":["7932fc6caeda44a3a0848c8f758f3a92","c0b82bd8cf1f4dc2a0204da681e069f3"]},"id":"1Z26-P_X4daN","outputId":"4fe6e4be-be10-496b-fe86-caf8d2429c5b","tags":[]},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './model_LSTM.pt'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./model_LSTM.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;66;03m# 모델 불러오기\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './model_LSTM.pt'"]}],"source":["model.load_state_dict(torch.load(\"./model_LSTM.pt\")) # 모델 불러오기\n","model = model.to(device)\n","model.eval()\n","total_labels = []\n","total_preds = []\n","with torch.no_grad():\n","    for texts, labels in tqdm(test_dataloader):\n","        texts = texts.to(device)\n","        labels = labels\n","\n","        outputs = model(texts)\n","        # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        total_preds.extend(predicted.detach().cpu().tolist())\n","        total_labels.extend(labels.tolist())\n","\n","total_preds = np.array(total_preds)\n","total_labels = np.array(total_labels)\n","nwp_lstm_acc = accuracy_score(total_labels, total_preds) # 정확도 계산\n","print(\"Next word prediction LSTM model accuracy : \", nwp_lstm_acc)"]},{"cell_type":"markdown","metadata":{"id":"_QLFPfgsGR44"},"source":["## 3. GRU 구현하기\n","\n","```\n","💡 목차 개요: 기본적인 GRU 구조를 이해하고, 이를 PyTorch로 GRU 모델을 구현해봅니다.\n","```\n","\n","- 3-1. GRU 구현하기\n","- 3-2. 학습 및 평가\n"]},{"cell_type":"markdown","metadata":{"id":"dcRGKfqwGR44"},"source":["### 3-1 GRU 구현하기\n","\n","> `torch.nn.GRU`을 통해 GRU 모델을 구현할 수 있습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"uIRB5FDTHAhw"},"source":["#### 📝 설명: GRU란?\n","<img src='https://upload.wikimedia.org/wikipedia/commons/b/b9/GRU.png'></img>\n","* GRU (Gated Recurrent Unit)는 LSTM과 마찬가지로 장기 의존성 문제를 해결하고 RNN의 성능을 향상시키기 위해 고안된 모델입니다.\n","<!-- * LSTM은 3개의 게이트 (Input gate, Forget gate, Output gate)를 가지는 반면에 GRU는 2개의 게이트를 가져, LSTM보다 더욱 간단한 구조를 가집니다. -->\n","* GRU는 LSTM에 비하여 파라미터수가 적기 때문에 연산 비용이 적게 들고, 구조도 더 간단하지만, 성능에서도 LSTM과 비슷한 결과를 냅니다.\n","<!-- * GRU의 게이트\n","  * Reset Gate: 이전 시점의 은닉 상태와 현재 시점의 입력을 조합하여 어떤 정보를 무시할지 결정하는 역할을 합니다.\n","\n","  * Update Gate: 이전 시점의 은닉 상태와 현재 시점의 입력을 조합하여 새로운 은닉 상태에 얼마나 많은 정보를 반영할지 결정하는 역할을 합니다. -->\n","\n","\n","📚 참고할만한 자료:\n","* [GRU paper](https://arxiv.org/abs/1406.1078)\n","* [GRU 설명](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be)\n","* [이미지 출처](https://commons.wikimedia.org/wiki/File:GRU.png)\n"]},{"cell_type":"markdown","metadata":{"id":"86GhT0f04daS"},"source":["#### 📝 설명: PyTorch에서의 GRU 구현은 어떻게 할까?\n","* GRU는 PyTorch에 `torch.nn.GRU`을 통해 쉽게 구현할 수 있습니다.\n","* torch.nn.GRU RNN, LSTM과 동일하게 기본적으로 `input_size`와 `hidden_size`를 지정해줘야합니다.\n","  * `input_size`: embedding dimension\n","  * `hidden_size`: hidden state dimension\n","* torch.LSTM의 output은 모든 time step의 정보를 담고 있는 hidden state와 마지막 time_step의 정보만 담고 있는 hidden state 2개를 반환합니다.\n","\n","📚 참고할만한 자료:\n","* [PyTorch GRU 공식 document](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"lzMT319l4daS","tags":[]},"outputs":[],"source":["class GRU(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size):\n","        super(GRU, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.gru = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, x):\n","        '''\n","        INPUT:\n","           x: [batch_size, seq_len]\n","        OUTPUT:\n","           output: [batch_size, vocab_size]\n","        '''\n","        x = self.embedding(x) # [batch_size, sequence_len, embedding_dim]\n","        output, h_0 = self.gru(x) # output : [batch_size, seq_len, hidden_dim] # h_0 는 [1, batch_size, hidden_dim]\n","        return self.fc(output[:,-1,:]) # [batch_size, vocab_size]"]},{"cell_type":"markdown","metadata":{"id":"GEOD96vg4daS"},"source":["### 3-2 학습 및 평가\n","\n","> 구축한 GRU 모델을 학습하고 평가해봅니다.\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"referenced_widgets":["37c30a1841c24c4089a3b2396b2b6472","3ea7087a15a1437690491a33ebc214cc","802b03cf7f5f43cea388dff88fb34361","e35975f4fc424019984615e146acd675","1eeba675a2a9414f853dd4d877a0e3a5","a88ac9b953be44798f36612c0677491b","1068a4013dc14c24bb3f83981d017dbc","9cda2d930e36405c9ef205abfa5c1b39","28e69aba7f4f44d9a3fd0e54cff88150","ec453c54720c4c85900efa79089ed8c2","40b6a0568ce948bbbd88b21f37b6fa68","911d34369bb24799bbfa9c01dbf89e4a","6643756d32274b5cb4453ca079784c6a","d374e2f8928548a1838b2def6ccff48e","4c91ec5eaa03449395397e54bca6106e","8e6e7656c0ea4f9da0d8ca06814d61bd"]},"id":"xyNTPD9k4daS","outputId":"290b1c32-55f2-4fba-b294-40d6d97a7190","tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"542976523a6845af80b3fa20003e1c65","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1159 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68517d7e555d483c90e7b7c223da76f8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/149 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch [1/100], Train Loss: 6.8902, Train Accuracy: 0.1141 Valid Loss: 6.6764, Valid Accuracy: 0.1317\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f22d20c9a7614726866db0fbfdd88f57","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1159 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m---> 14\u001b[0m model, valid_max_accuracy \u001b[38;5;241m=\u001b[39m training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValid max accuracy : \u001b[39m\u001b[38;5;124m'\u001b[39m, valid_max_accuracy)\n","Cell \u001b[0;32mIn[17], line 70\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\u001b[0m\n\u001b[1;32m     67\u001b[0m valid_max_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 70\u001b[0m     model, train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\n\u001b[1;32m     71\u001b[0m     model, valid_loss, valid_accuracy \u001b[38;5;241m=\u001b[39m evaluation(model, valid_dataloader, val_dataset, criterion, device, epoch, num_epochs)\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_accuracy \u001b[38;5;241m>\u001b[39m valid_max_accuracy:\n","Cell \u001b[0;32mIn[17], line 10\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m tbar \u001b[38;5;241m=\u001b[39m tqdm(dataloader)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m texts, labels \u001b[38;5;129;01min\u001b[39;00m tbar:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# 순전파\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(texts)\n\u001b[1;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# 역전파 및 가중치 업데이트\u001b[39;00m\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[27], line 17\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x) \u001b[38;5;66;03m# [batch_size, sequence_len, embedding_dim]\u001b[39;00m\n\u001b[1;32m     16\u001b[0m output, h_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru(x) \u001b[38;5;66;03m# output : [batch_size, seq_len, hidden_dim] # h_0 는 [1, batch_size, hidden_dim]\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:])\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["num_epochs = 100\n","patience = 3\n","model_name = 'GRU'\n","\n","vocab_size = len(vocab)\n","embedding_dim = 512\n","hidden_size = 256\n","model = GRU(vocab_size, embedding_dim, hidden_size).to(device)\n","\n","lr = 1e-3\n","criterion = nn.CrossEntropyLoss(ignore_index = 0)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","model, valid_max_accuracy = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\n","print('Valid max accuracy : ', valid_max_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["ce0d777efe9b4fbab5fa4db7b616c424","dba457913e314a7ab13ca45598d00c5a"]},"id":"gJBiAiTw4daT","outputId":"003ea6a5-fef3-4cd6-bc96-56b2688cc780","tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dba457913e314a7ab13ca45598d00c5a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Next word prediction GRU model accuracy :  0.1384514435695538\n"]}],"source":["model.load_state_dict(torch.load(\"./model_GRU.pt\")) # 모델 불러오기\n","model = model.to(device)\n","model.eval()\n","total_labels = []\n","total_preds = []\n","with torch.no_grad():\n","    for texts, labels in tqdm(test_dataloader):\n","        texts = texts.to(device)\n","        labels = labels\n","\n","        outputs = model(texts)\n","        # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        total_preds.extend(predicted.detach().cpu().tolist())\n","        total_labels.extend(labels.tolist())\n","\n","total_preds = np.array(total_preds)\n","total_labels = np.array(total_labels)\n","nwp_gru_acc = accuracy_score(total_labels, total_preds) # 정확도 계산\n","print(\"Next word prediction GRU model accuracy : \", nwp_gru_acc)"]},{"cell_type":"markdown","metadata":{"id":"6fk7uBULLALr"},"source":["## 4. Bi-directional RNN/LSTM/GRU\n","\n","```\n","💡 목차 개요: 기본적인 Bi-directional RNN/LSTM/GRU 구조를 이해하고, 이를 PyTorch로 Bi-directional RNN/LSTM/GRU 모델을 구축해봅니다.\n","```\n","\n","- 4-1. Bi-directional RNN/LSTM/GRU 구현하기\n","- 4-2. 학습 및 평가\n"]},{"cell_type":"markdown","metadata":{"id":"3VDFqcZcLALs"},"source":["### 4-1 Bi-directional RNN/LSTM/GRU 구현하기\n","\n","> `bidirectional=True`를 통해 Bi-directional RNN/LSTM/GRU 모델을 구현할 수 있습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"dnFM1q9mIylb"},"source":["#### 📝 설명: Bi-directional RNN이란?\n","<img src='https://upload.wikimedia.org/wikipedia/commons/3/35/Structural_diagrams_of_unidirectional_and_bidirectional_recurrent_neural_networks.png'></img>\n","* RNN/LSTM/GRU은 **과거**의 정보만 이용하여 다음을 예측하는 방식으로 구성되어 있었습니다. 그러나 Bi-directional RNN/LSTM/GRU은 **과거 뿐만 아니라 미래**의 정보를 이용하여 다음을 예측하는 방식입니다.\n","* 예를 들어 다음과 같은 3가지 문장이 있다고 해봅시다.\n","  1. I'm ____.\n","    \n","    * sad, happy, hungry와 같은 다양한 단어들이 들어갈 수 있습니다.\n","  2. I'm ____ hungry.\n","\n","   * very 또는 not과 같은 단어들이 들어갈 수 있습니다. 1번보단 들어갈 수 있는 단어가 적습니다.\n","  3. I'm ____ hungry, so I can eat more.\n","    * not 이라는 단어가 매우 적절합니다.\n","\n","* 이와 같은 예시처럼, 앞의 단어들 뿐만 아니라 뒤의 단어들을 고려하여 문맥을 이해할 수 있고, 더욱 적절한 단어를 예측할 수 있습니다.\n","\n","\n","\n","📚 참고할만한 자료:\n","* [bi-directional RNN paper](https://ieeexplore.ieee.org/document/650093)\n","* [bi-directional RNN 설명](https://hyen4110.tistory.com/29)\n","* [이미지 출처](https://commons.wikimedia.org/wiki/File:Structural_diagrams_of_unidirectional_and_bidirectional_recurrent_neural_networks.png)\n","<!-- * [이미지 출처](https://d2l.ai/chapter_recurrent-modern/bi-rnn.html) -->\n"]},{"cell_type":"markdown","metadata":{"id":"ogmtD1jr4daU"},"source":["#### 📝 설명: PyTorch에서의 양방향 RNN/GRU/LSTM 모델은 어떻게 구현할까?\n","* 양방향 모델을 구현하기 위해선, `torch.nn.RNN/LSTM/GRU`의 `bidirectional` 인자를 True로 설정해주면 됩니다.\n","* 이 때, **양방향** RNN/GRU/LSTM이므로 hidden state의 크기가 bidirectional=False 일 때 보다 2배 더 커집니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ke01atpl4daU","tags":[]},"outputs":[],"source":["class Bidirectional(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size, model_name):\n","        super(Bidirectional, self).__init__()\n","\n","        self.model_name = model_name # 구현할 모델의 이름을 지정해줍니다.\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","\n","        if self.model_name == 'bi_RNN':\n","            self.model = nn.RNN(embedding_dim, hidden_size, batch_first=True, bidirectional=True) # 양방향성 모델을 구축합니다.\n","        elif self.model_name == 'bi_LSTM':\n","            self.model = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n","        elif self.model_name == 'bi_GRU':\n","            self.model = nn.GRU(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size * 2, vocab_size)\n","\n","    def forward(self, x):\n","        '''\n","        INPUT:\n","           x: [batch_size, seq_len]\n","        OUTPUT:\n","           output: [batch_size, vocab_size]\n","        '''\n","        x = self.embedding(x) # [batch_size, sequence_len, embedding_dim]\n","\n","        output, _ = self.model(x)\n","        return self.fc(output[:,-1,:]) # [batch_size, vocab_size]\n"]},{"cell_type":"markdown","metadata":{"id":"ccjxx1QG4daU"},"source":["### 4-1 학습 및 평가\n","\n","> bidirectional RNN/LSTM/GRU를 학습하고 평가하여 비교해봅니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"glzyyCbh4daU","tags":[]},"outputs":[],"source":["# training 코드, evaluation 코드, training_loop 코드\n","def training(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs):\n","  model.train()  # 모델을 학습 모드로 설정\n","  train_loss = 0.0\n","  train_accuracy = 0\n","\n","  for texts, labels in dataloader:\n","      texts = texts.to(device)\n","      labels = labels.to(device)\n","\n","      # 순전파\n","      outputs = model(texts)\n","      loss = criterion(outputs, labels)\n","\n","      # 역전파 및 가중치 업데이트\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","      # 손실과 정확도 계산\n","      train_loss += loss.item()\n","      # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n","      _, predicted = torch.max(outputs, 1)\n","      train_accuracy += (predicted == labels).sum().item()\n","\n","\n","  # 에폭별 학습 결과 출력\n","  train_loss = train_loss / len(dataloader)\n","  train_accuracy = train_accuracy / len(train_dataset)\n","\n","  return model, train_loss, train_accuracy\n","\n","def evaluation(model, dataloader, val_dataset, criterion, device, epoch, num_epochs):\n","  model.eval()  # 모델을 평가 모드로 설정\n","  valid_loss = 0.0\n","  valid_accuracy = 0\n","\n","  with torch.no_grad(): # model의 업데이트 막기\n","      for texts, labels in dataloader:\n","          texts = texts.to(device)\n","          labels = labels.to(device)\n","\n","          # 순전파\n","          outputs = model(texts)\n","          loss = criterion(outputs, labels)\n","\n","          # 손실과 정확도 계산\n","          valid_loss += loss.item()\n","          # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n","          _, predicted = torch.max(outputs, 1)\n","          valid_accuracy += (predicted == labels).sum().item()\n","\n","\n","  valid_loss = valid_loss / len(dataloader)\n","  valid_accuracy = valid_accuracy / len(val_dataset)\n","\n","  return model, valid_loss, valid_accuracy\n","\n","\n","def training_loop(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name):\n","    best_valid_loss = float('inf')  # 가장 좋은 validation loss를 저장\n","    early_stop_counter = 0  # 카운터\n","    valid_max_accuracy = -1\n","\n","    for epoch in range(num_epochs):\n","        model, train_loss, train_accuracy = training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\n","        model, valid_loss, valid_accuracy = evaluation(model, valid_dataloader, val_dataset, criterion, device, epoch, num_epochs)\n","\n","        if valid_accuracy > valid_max_accuracy:\n","          valid_max_accuracy = valid_accuracy\n","\n","        # validation loss가 감소하면 모델 저장 및 카운터 리셋\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            torch.save(model.state_dict(), f\"./model_{model_name}.pt\")\n","            early_stop_counter = 0\n","\n","        # validation loss가 증가하거나 같으면 카운터 증가\n","        else:\n","            early_stop_counter += 1\n","\n","\n","        # 조기 종료 카운터가 설정한 patience를 초과하면 학습 종료\n","        if early_stop_counter >= patience:\n","            print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n","            break\n","\n","    return model, valid_max_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"phhqHOOG4daV","tags":[]},"outputs":[],"source":["def test(model, model_name, test_dataloader, device):\n","    model.load_state_dict(torch.load(f\"./model_{model_name}.pt\")) # 모델 불러오기\n","    model = model.to(device)\n","    model.eval()\n","    total_labels = []\n","    total_preds = []\n","    total_probs = []\n","    with torch.no_grad():\n","        for texts, labels in test_dataloader:\n","            texts = texts.to(device)\n","            labels = labels\n","\n","            outputs = model(texts)\n","            # torch.max에서 dim 인자에 값을 추가할 경우, 해당 dimension에서 최댓값과 최댓값에 해당하는 인덱스를 반환\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            total_preds.extend(predicted.detach().cpu().tolist())\n","            total_labels.extend(labels.tolist())\n","            total_probs.append(outputs.detach().cpu().numpy())\n","\n","    total_preds = np.array(total_preds)\n","    total_labels = np.array(total_labels)\n","    total_probs = np.concatenate(total_probs, axis= 0)\n","    acc = accuracy_score(total_labels, total_preds) # 정확도 계산\n","    print(f\"{model_name} accuracy : \", acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sL2rzOT34daV","outputId":"10f9ee85-4326-46f4-e863-34096d9693ba","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [4/100]\n","bi_RNN valid max accuracy :  0.12494723512030392\n","bi_RNN accuracy :  0.12270341207349081\n","------------------------------------------------------------\n","\n","Epoch [4/100]\n","bi_LSTM valid max accuracy :  0.1409877585479105\n","bi_LSTM accuracy :  0.1388888888888889\n","------------------------------------------------------------\n","\n","Epoch [4/100]\n","bi_GRU valid max accuracy :  0.13782186576614605\n","bi_GRU accuracy :  0.13757655293088364\n","------------------------------------------------------------\n","\n"]}],"source":["model_name_list = ['bi_RNN', 'bi_LSTM', 'bi_GRU'] # 훈련 및 평가할 모델 리스트\n","\n","patience = 3\n","num_epochs = 100\n","\n","vocab_size = len(vocab)\n","embedding_dim = 512\n","hidden_size = 256\n","lr = 1e-3\n","for model_name in model_name_list:\n","    model = Bidirectional(vocab_size, embedding_dim, hidden_size, model_name).to(device)\n","    criterion = nn.CrossEntropyLoss(ignore_index = 0)\n","    optimizer = optim.Adam(model.parameters(), lr = lr)\n","    model, valid_max_accuracy = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\n","    print(f'{model_name} valid max accuracy : ', valid_max_accuracy)\n","    test(model, model_name, test_dataloader, device)\n","    print('---'*20)\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"c1HHIbXrp5pZ"},"source":["## Required Package\n","\n","> torch == 2.0.1\n","\n","> torchvision == 0.15.2\n","\n","> sklearn == 1.3.0\n","\n","> torchtext == 0.15.2"]},{"cell_type":"markdown","metadata":{"id":"k6fnxdyLp2Qk"},"source":["## 콘텐츠 라이선스\n","\n","저작권 : <font color='blue'> <b> ©2023 by Upstage X fastcampus Co., Ltd. All rights reserved.</font></b>\n","\n","<font color='red'><b>WARNING</font> : 본 교육 콘텐츠의 지식재산권은 업스테이지 및 패스트캠퍼스에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다. </b>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FhNyMAYsh2v3"},"outputs":[],"source":[]}],"metadata":{"colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
