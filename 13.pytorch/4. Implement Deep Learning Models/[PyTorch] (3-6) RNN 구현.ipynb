{"cells":[{"cell_type":"markdown","metadata":{"id":"biI2UMXHon5o"},"source":["# RNN êµ¬í˜„"]},{"cell_type":"markdown","metadata":{"id":"zOtbGaE_ojQA"},"source":["## ì‹¤ìŠµ ê°œìš”\n","\n","1) **ì‹¤ìŠµ ëª©ì **\n","\n","ì´ë²ˆ ì‹¤ìŠµì€ ì´ë¡ ìœ¼ë¡œ ë°°ì› ë˜ PyTorchë¥¼ ì´ìš©í•˜ì—¬ RNN ê³„ì—´ì˜ ëª¨ë¸ë“¤ì„ ì§ì ‘ êµ¬í˜„í•´ë³´ê³  í•™ìŠµ ë° í‰ê°€ë¥¼ í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n","\n","\n","\n","2) **ìˆ˜ê°• ëª©í‘œ**\n","\n","- Next word predictionì„ ìœ„í•œ RNNê³„ì—´ì˜ ëª¨ë¸ì„ ì§ì ‘ êµ¬í˜„í•˜ê³  í•™ìŠµ ë° í‰ê°€ë¥¼ í•  ìˆ˜ ìˆë‹¤.\n","- ë‹¤ì–‘í•œ RNNëª¨ë¸ë“¤ì„ ì§ì ‘ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n","- RNNì˜ ë‹¤ì–‘í•œ ë³€í˜•ì„ ì§ì ‘ ì‹¤ìŠµí•  ìˆ˜ ìˆë‹¤."]},{"cell_type":"markdown","metadata":{"id":"vUnGWX59ybEk"},"source":["### ì‹¤ìŠµ ëª©ì°¨\n","* 1. Vanilla RNN\n","  * 1.1 Vanilla RNN ëª¨ë¸ êµ¬í˜„í•˜ê¸°\n","  * 1.2 í›ˆë ¨ ë° í‰ê°€\n","* 2. LSTM\n","  * 2.1 LSTM ëª¨ë¸ êµ¬í˜„í•˜ê¸°\n","  * 2.2 í›ˆë ¨ ë° í‰ê°€\n","* 3. GRU\n","  * 3.1 GRU ëª¨ë¸ êµ¬í˜„í•˜ê¸°\n","  * 3.2 í›ˆë ¨ ë° í‰ê°€\n","\n","* 4. bi-directional RNN/GRU/LSTM\n","  * 4.1 bi-direcitional RNN/GRU/LSTM ëª¨ë¸ êµ¬í˜„í•˜ê¸°\n","  * 4.2 í›ˆë ¨ ë° í‰ê°€"]},{"cell_type":"markdown","metadata":{"id":"3F2fMLWA31Ft"},"source":["### í™˜ê²½ ì„¤ì •\n","\n","- íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„í¬íŠ¸"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37891,"status":"ok","timestamp":1691914634464,"user":{"displayName":"ê¹€ì˜ë¯¼","userId":"04915862517565535031"},"user_tz":-540},"id":"_wvClBdFmDml","outputId":"82ae1a6b-7222-4f86-b8df-5acfe0b08643"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.11/site-packages/PyBioMed-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["#!pip install scikit-learn==1.3.0 -q\n","#!pip install torch==2.0.1 -q\n","#!pip install torchvision==0.15.2 -q\n","!pip install torchtext==0.15.2 -q"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"GKbkjkhbiPNt","tags":[]},"outputs":[],"source":["import numpy as np # ê¸°ë³¸ì ì¸ ì—°ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","import matplotlib.pyplot as plt # ê·¸ë¦¼ì´ë‚˜ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","from tqdm.notebook import tqdm # ìƒíƒœ ë°”ë¥¼ ë‚˜íƒ€ë‚´ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","import pandas as pd # ë°ì´í„°í”„ë ˆì„ì„ ì¡°ì‘í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","\n","import torch # PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬\n","import torch.nn as nn # ëª¨ë¸ êµ¬ì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","import torch.optim as optim # optimizer ì„¤ì •ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","from torch.utils.data import Dataset, DataLoader # ë°ì´í„°ì…‹ ì„¤ì •ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","import torch.nn.functional as F # torchì—ì„œ ìˆ˜í•™ì ì¸ functionì„ ì‰½ê²Œ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","\n","from torchtext.data import get_tokenizer # torchì—ì„œ tokenizerë¥¼ ì–»ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","import torchtext # torchì—ì„œ textë¥¼ ë” ì˜ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","\n","from sklearn.metrics import accuracy_score # ì„±ëŠ¥ì§€í‘œ ì¸¡ì •\n","from sklearn.model_selection import train_test_split # train-validation-test set ë‚˜ëˆ„ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n","\n","import re # text ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qnIkzdqds7t4","tags":[]},"outputs":[],"source":["# seed ê³ ì •\n","import random\n","import torch.backends.cudnn as cudnn\n","\n","def random_seed(seed_num):\n","    torch.manual_seed(seed_num)\n","    torch.cuda.manual_seed(seed_num)\n","    torch.cuda.manual_seed_all(seed_num)\n","    np.random.seed(seed_num)\n","    cudnn.benchmark = False\n","    cudnn.deterministic = True\n","    random.seed(seed_num)\n","\n","random_seed(42)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"PNQgFf_x4daH","tags":[]},"outputs":[],"source":["device = 'cpu'"]},{"cell_type":"markdown","metadata":{"id":"Fs0LWFQhdOsU"},"source":["###  ë°ì´í„° ì…‹ ê°œìš” </b>\n","\n","* ë°ì´í„°ì…‹: <a href='https://www.kaggle.com/datasets/dorianlazar/medium-articles-dataset'>Medium Dataset</a>\n","* ë°ì´í„°ì…‹ ê°œìš”: \"Towards Data Science\", \"UX Collective\", \"The Startup\", \"The Writing Cooperative\", \"Data Driven Investor\", \"Better Humans\", \"Better Marketing\" ì˜ 7ê°œì˜ ì£¼ì œë¥¼ ê°€ì§€ëŠ” publication ì— ëŒ€í•´ì„œ í¬ë¡¤ë§ì„ í•œ ë°ì´í„°ì…ë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°ëŠ” ì´ 6,508ê°œì˜ ë¸”ë¡œê·¸ ì´ë¯¸ì§€ì™€ ë©”íƒ€ ë°ì´í„°(.csv)ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ì‹¤ìŠµì—ì„œëŠ” ë©”íƒ€ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ CustomDatasetì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n","  * [How to collect ths dataset?](https://dorianlazar.medium.com/scraping-medium-with-python-beautiful-soup-3314f898bbf5)\n","- ë©”íƒ€ ë°ì´í„° ìŠ¤í‚¤ë§ˆ: ë©”íƒ€ ë°ì´í„°ëŠ” ì´ **10**ê°œì˜ columnìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n","  - id: ì•„ì´ë””\n","  - url: í¬ìŠ¤íŒ… ë§í¬\n","  - title: ì œëª©\n","  - subtitle: ë¶€ì œëª©\n","  - image: í¬ìŠ¤íŒ… ì´ë¯¸ì§€ì˜ íŒŒì¼ ì´ë¦„\n","  - claps: ì¶”ì²œ ìˆ˜\n","  - reponses: ëŒ“ê¸€ ìˆ˜\n","  - reading_time: ì½ëŠ”ë° ê±¸ë¦¬ëŠ” ì‹œê°„\n","  - publication: ì£¼ì œ ì¹´í…Œê³ ë¦¬(e.g. Towards Data Science..)\n","  - date: ì‘ì„± ë‚ ì§œ\n","- ë°ì´í„° ì…‹ ì €ì‘ê¶Œ: CC0: Public Domain"]},{"cell_type":"markdown","metadata":{"id":"ga4KpW8DED_Q"},"source":["## 1. Vanilla RNN êµ¬í˜„í•˜ê¸°\n","\n","```\n","ğŸ’¡ ëª©ì°¨ ê°œìš”: ê¸°ë³¸ì ì¸ RNN êµ¬ì¡°ë¥¼ ì´í•´í•˜ê³ , ì´ë¥¼ PyTorchë¡œ RNN ëª¨ë¸ì„ êµ¬í˜„í•´ë´…ë‹ˆë‹¤.\n","```\n","\n","- 1-1. Vanilla RNN êµ¬í˜„í•˜ê¸°\n","- 1-2. í•™ìŠµ ë° í‰ê°€\n"]},{"cell_type":"markdown","metadata":{"id":"7a3AnRDwEu4u"},"source":["### 1-1 Vanilla RNN êµ¬í˜„í•˜ê¸°\n","\n","> `torch.nn.RNN`ì„ í†µí•´ RNN ëª¨ë¸ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"]},{"cell_type":"markdown","metadata":{"id":"_1mA-15ZFSwp"},"source":["#### ğŸ“ ì„¤ëª…: Vanilla RNNì´ë€?\n","<img src='https://upload.wikimedia.org/wikipedia/commons/0/05/RNN.png'></img>\n","* RNN ëª¨ë¸ì€ recurrent neural networkë¡œ ì…ë ¥ê³¼ ì¶œë ¥ì„ sequence ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.\n","  * sequenceëŠ” ìˆœì„œëŒ€ë¡œ ë°°ì—´ëœ ë°ì´í„°ë“¤ì˜ ì§‘í•©ìœ¼ë¡œ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ ìˆê³ , ê° í•­ëª©ì€ íŠ¹ì • ìˆœì„œì— ë”°ë¼ ë‚˜ì—´ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n","  * ex)  \"Hello, how are you?\"ë¼ëŠ” ë¬¸ì¥ì€ \"Hello\", \",\", \"how\", \"are\", \"you\", \"?\"ë¼ëŠ” ë‹¨ì–´ë“¤ì´ ìˆœì„œëŒ€ë¡œ ë‚˜ì—´ë˜ì–´ ìˆëŠ” sequence ì…ë‹ˆë‹¤.\n","* DNNê³¼ ë‹¬ë¦¬ RNNì€ ì‹œê°„ì˜ íë¦„ì— ë”°ë¼ ì •ë³´ë¥¼ ê³µìœ í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë¡œ ì¸í•´ ì´ì „ ë‹¨ê³„ì—ì„œ ì–»ì€ ì •ë³´ê°€ í˜„ì¬ ë‹¨ê³„ì—ì„œ ì˜í–¥ì„ ë¯¸ì¹˜ê²Œ ë©ë‹ˆë‹¤.\n","* RNNì€ ì´ì „ ë‹¨ê³„ì˜ ì€ë‹‰ ìƒíƒœ(hidden states)ì™€ í˜„ì¬ ì…ë ¥ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ì˜ ì€ë‹‰ ìƒíƒœë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬ì„±ì´ ë˜ì–´, ê³¼ê±°ì˜ ì •ë³´ì™€ í˜„ì¬ì˜ ì •ë³´ë¥¼ ëª¨ë‘ ì´ìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n","  * ì²˜ìŒì—ëŠ” zero-vectorë¡œ ì´ˆê¸°í™” ë˜ê±°ë‚˜ randomìœ¼ë¡œ ì´ˆê¸°í™” ë©ë‹ˆë‹¤.\n","\n","\n","\n","\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [ì´ë¯¸ì§€ ì¶œì²˜](https://commons.wikimedia.org/wiki/File:RNN.png)\n","* [RNN ì„¤ëª…](https://wikidocs.net/22886)"]},{"cell_type":"markdown","metadata":{"id":"Rs0rlqgG4daI"},"source":["#### ğŸ“ ì„¤ëª…: Next word predictionì„ ìœ„í•œ ë°ì´í„°ì…‹ì„ êµ¬í˜„\n","* DNN êµ¬í˜„(3)ì—ì„œ ë‹¤ë¤˜ë˜ ë°ì´í„°ì…‹ìœ¼ë¡œ custom dataset classë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [ë°ì´í„° ë‹¤ìš´ë¡œë“œ](https://www.kaggle.com/datasets/dorianlazar/medium-articles-dataset)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"caGRiSrk4daJ","tags":[]},"outputs":[],"source":["# DNN ì—ì„œ ê°–ê³  ì˜¤ê¸°\n","data_csv = pd.read_csv('./data/medium_data.csv')\n","data = data_csv['title']"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url</th>\n","      <th>title</th>\n","      <th>subtitle</th>\n","      <th>image</th>\n","      <th>claps</th>\n","      <th>responses</th>\n","      <th>reading_time</th>\n","      <th>publication</th>\n","      <th>date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>https://towardsdatascience.com/a-beginners-gui...</td>\n","      <td>A Beginnerâ€™s Guide to Word Embedding with Gens...</td>\n","      <td>NaN</td>\n","      <td>1.png</td>\n","      <td>850</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>https://towardsdatascience.com/hands-on-graph-...</td>\n","      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n","      <td>NaN</td>\n","      <td>2.png</td>\n","      <td>1100</td>\n","      <td>11</td>\n","      <td>9</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>https://towardsdatascience.com/how-to-use-ggpl...</td>\n","      <td>How to Use ggplot2 inÂ Python</td>\n","      <td>A Grammar of Graphics forÂ Python</td>\n","      <td>3.png</td>\n","      <td>767</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>https://towardsdatascience.com/databricks-how-...</td>\n","      <td>Databricks: How to Save Files in CSV on Your L...</td>\n","      <td>When I work on Python projectsÂ dealingâ€¦</td>\n","      <td>4.jpeg</td>\n","      <td>354</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>https://towardsdatascience.com/a-step-by-step-...</td>\n","      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n","      <td>One example of buildingÂ neuralâ€¦</td>\n","      <td>5.jpeg</td>\n","      <td>211</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>Towards Data Science</td>\n","      <td>2019-05-30</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                                                url  \\\n","0   1  https://towardsdatascience.com/a-beginners-gui...   \n","1   2  https://towardsdatascience.com/hands-on-graph-...   \n","2   3  https://towardsdatascience.com/how-to-use-ggpl...   \n","3   4  https://towardsdatascience.com/databricks-how-...   \n","4   5  https://towardsdatascience.com/a-step-by-step-...   \n","\n","                                               title  \\\n","0  A Beginnerâ€™s Guide to Word Embedding with Gens...   \n","1  Hands-on Graph Neural Networks with PyTorch & ...   \n","2                       How to Use ggplot2 inÂ Python   \n","3  Databricks: How to Save Files in CSV on Your L...   \n","4  A Step-by-Step Implementation of Gradient Desc...   \n","\n","                                  subtitle   image  claps responses  \\\n","0                                      NaN   1.png    850         8   \n","1                                      NaN   2.png   1100        11   \n","2         A Grammar of Graphics forÂ Python   3.png    767         1   \n","3  When I work on Python projectsÂ dealingâ€¦  4.jpeg    354         0   \n","4          One example of buildingÂ neuralâ€¦  5.jpeg    211         3   \n","\n","   reading_time           publication        date  \n","0             8  Towards Data Science  2019-05-30  \n","1             9  Towards Data Science  2019-05-30  \n","2             5  Towards Data Science  2019-05-30  \n","3             4  Towards Data Science  2019-05-30  \n","4             4  Towards Data Science  2019-05-30  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data_csv.head()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"tt_g2TKY4daJ","tags":[]},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, data, vocab, tokenizer, max_len):\n","        self.data = data\n","        self.vocab = vocab\n","        self.max_len = max_len # ìµœëŒ€ ê¸¸ì´ -> ê°ê°ì˜ ë°ì´í„°ëŠ” ê¸¸ì´ê°€ ë‹¤ë¥´ë‹¤ -> ëª¨ë‘ ë™ì¼í•˜ê²Œ ë§ì¶°ì£¼ê¸° ìœ„í•´ ì‚¬ìš©\n","        self.tokenizer = tokenizer\n","        seq = self.make_sequence(self.data, self.vocab, self.tokenizer) # next word predictionì„ í•˜ê¸° ìœ„í•œ í˜•íƒœë¡œ ë³€í™˜\n","        self.seq = self.pre_zeropadding(seq, self.max_len) # zero paddingìœ¼ë¡œ ì±„ì›Œì¤Œ -> ëª¨ë“  ë°ì´í„°ì˜ ê¸¸ì´ë¥¼ ë§ì¶°ì¤€ë‹¤.\n","        self.X = torch.tensor(self.seq[:,:-1])\n","        self.label = torch.tensor(self.seq[:,-1])\n","\n","    def make_sequence(self, data, vocab, tokenizer):\n","        seq = []\n","        for i in data:\n","            token_id = vocab.lookup_indices(tokenizer(i))\n","            for j in range(1, len(token_id)):\n","                sequence = token_id[:j+1]\n","                seq.append(sequence)\n","        return seq\n","\n","    def pre_zeropadding(self, seq, max_len): # max_len ê¸¸ì´ì— ë§ì¶°ì„œ 0 ìœ¼ë¡œ padding ì²˜ë¦¬ (ì•ë¶€ë¶„ì— padding ì²˜ë¦¬)\n","        return np.array([i[:max_len] if len(i) >= max_len else [0] * (max_len - len(i)) + i for i in seq])\n","\n","\n","    def __len__(self): # datasetì˜ ì „ì²´ ê¸¸ì´ ë°˜í™˜\n","        return len(self.X)\n","\n","    def __getitem__(self, idx): # dataset ì ‘ê·¼\n","        X = self.X[idx]\n","        label = self.label[idx]\n","\n","        return X, label"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"xm-Sua4t4daJ","tags":[]},"outputs":[],"source":["def cleaning_text(text):\n","    cleaned_text = re.sub( r\"[^a-zA-Z0-9.,@#!\\s']+\", \"\", text) # íŠ¹ìˆ˜ë¬¸ì ë¥¼ ëª¨ë‘ ì§€ìš°ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n","    cleaned_text = cleaned_text.replace(u'\\xa0',u' ') # No-break spaceë¥¼ unicode ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","    cleaned_text = cleaned_text.replace('\\u200a',' ') # unicode ë¹ˆì¹¸ì„ ë¹ˆì¹¸ìœ¼ë¡œ ë³€í™˜\n","    return cleaned_text"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"IK7yCCNc4daJ","tags":[]},"outputs":[],"source":["data = list(map(cleaning_text, data))\n","tokenizer = get_tokenizer(\"basic_english\")\n","vocab = torchtext.vocab.build_vocab_from_iterator(map(tokenizer, data))\n","vocab.insert_token('<pad>',0)\n","max_len = 20"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"i_nUEtaz9jBi","outputId":"e22d7010-4be3-4ac2-9dcb-f9ec6cf1fb02","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Train ê°œìˆ˜:  5206\n","Validation ê°œìˆ˜:  651\n","Test ê°œìˆ˜:  651\n"]}],"source":["# train setê³¼ validation set, test setì„ ê°ê° ë‚˜ëˆ•ë‹ˆë‹¤. 8 : 1 : 1 ì˜ ë¹„ìœ¨ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\n","train, test = train_test_split(data, test_size = .2, random_state = 42)\n","val, test = train_test_split(test, test_size = .5, random_state = 42)\n","print(\"Train ê°œìˆ˜: \", len(train))\n","print(\"Validation ê°œìˆ˜: \", len(val))\n","print(\"Test ê°œìˆ˜: \", len(test))\n","\n","train_dataset = CustomDataset(train, vocab, tokenizer, max_len)\n","valid_dataset = CustomDataset(val, vocab, tokenizer, max_len)\n","test_dataset = CustomDataset(test, vocab, tokenizer, max_len)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"-YqQonc74daK","tags":[]},"outputs":[],"source":["batch_size = 32\n","\n","train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n","valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = False)\n","test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"]},{"cell_type":"markdown","metadata":{"id":"ovJAajj83_bq"},"source":["#### ğŸ“ ì„¤ëª…: PyTorchì—ì„œì˜ RNN êµ¬í˜„ì€ ì–´ë–»ê²Œ í• ê¹Œ?\n","* RNNì€ `torch.nn.RNN`ì„ í†µí•´ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","* torch.nn.RNNì€ tì‹œì ì˜ hidden stateë¥¼ ê³„ì‚°í•´ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n","* torch.nn.RNNì€ ê¸°ë³¸ì ìœ¼ë¡œ `input_size`ì™€ `hidden_size`ë¥¼ ì§€ì •í•´ì¤˜ì•¼í•©ë‹ˆë‹¤.\n","  * `input_size`: embedding dimension\n","  * `hidden_size`: hidden state dimension\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [PyTorch RNN ê³µì‹ document](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)"]},{"cell_type":"markdown","metadata":{"id":"gw4zHH9v4daK"},"source":["#### ğŸ“ ì„¤ëª…: Next word predictionë¥¼ ìœ„í•œ RNN ëª¨ë¸ êµ¬í˜„\n","* Next word prediction ì‘ì—…ì—ì„œëŠ” ì£¼ì–´ì§„ ì…ë ¥ ì‹œí€€ìŠ¤ë¡œë¶€í„° ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\n","* ì´ë•Œ, ì¼ë°˜ì ìœ¼ë¡œ ì£¼ì–´ì§„ ì‹œí€€ìŠ¤ ë‚´ì—ì„œ **ë§ˆì§€ë§‰ time stepì˜ hidden state**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n","  * RNNì€ ì´ì „ time stepì˜ ì •ë³´ë¥¼ í˜„ì¬ time stepìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ë°©ì‹ì´ê¸° ë•Œë¬¸ì—, ëª¨ë“  ì´ì „ time stepì˜ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” ë§ˆì§€ë§‰ time stepì˜ hidden stateë¥¼ ì‚¬ìš©í•˜ë©´ ë¬¸ë§¥ ì •ë³´ë¥¼ ì˜ ë°˜ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","* torch.RNNì˜ outputì€ ëª¨ë“  time stepì˜ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” hidden stateì™€ ë§ˆì§€ë§‰ time_stepì˜ ì •ë³´ë§Œ ë‹´ê³  ìˆëŠ” hidden state ë‘ê°œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n","  * ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ì½”ë”©ì˜ í¸ë¦¬ì„±ì„ ìœ„í•´, ëª¨ë“  ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” hidden stateë¥¼ ì‚¬ìš©í•˜ì—¬ ë§ˆì§€ë§‰ time_stepì˜ ì •ë³´ë§Œ ë”°ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n","  * ë§ˆì§€ë§‰ time_stepì˜ ì •ë³´ë§Œ ë‹´ê³  ìˆëŠ” hidden stateì˜ shapeì€ RNNì˜ layer ê°œìˆ˜ì™€ ë‚˜ì¤‘ì— í•™ìŠµí•˜ëŠ” bidirectional ì¸ìì— ì˜í•´ ì˜í–¥ì„ ë°›ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"GdB2jJ4g4daK","tags":[]},"outputs":[],"source":["class RNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size):\n","        super(RNN, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0) # ë‹¨ì–´ ì„ë² ë”©\n","\n","        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True) # batch_first=TrueëŠ” ì…ë ¥ì˜ ì²« ë²ˆì§¸ ì°¨ì›ì´ batch í¬ê¸°ì„ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n","\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, x):\n","        '''\n","        INPUT:\n","           x: [batch_size, seq_len]\n","        OUTPUT:\n","           output: [batch_size, vocab_size]\n","        '''\n","        x = self.embedding(x) # [batch_size, sequence_len, embedding_dim]\n","\n","        # ì²« ë²ˆì§¸ ë¦¬í„´ê°’ì¸ outputì€ ëª¨ë“  time stepì˜ hidden stateë¥¼ í¬í•¨í•œ ì¶œë ¥ì…ë‹ˆë‹¤.\n","        # ë‘ ë²ˆì§¸ ë¦¬í„´ê°’ì¸ h_0 ëŠ” ë§ˆì§€ë§‰ time stepì˜ hidden stateë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n","        output, h_0 = self.rnn(x) # output: [batch_size, seq_len, hidden_dim] / h_0: [1, batch_size, hidden_dim]\n","        return self.fc(output[:,-1,:]) # [batch_size, vocab_size]"]},{"cell_type":"markdown","metadata":{"id":"P4biQ_HH4daL"},"source":["### 1-2 í•™ìŠµ ë° í‰ê°€\n","\n","> í•™ìŠµ ë° í‰ê°€ ì½”ë“œë¥¼ ì§ì ‘ ì‘ì„±í•˜ê³ , ë‹¤ìŒì— ë‚˜ì˜¬ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ì¶”ë¡  ì½”ë“œë¥¼ ì‘ì„±í•´ë´…ë‹ˆë‹¤.\n"]},{"cell_type":"markdown","metadata":{"id":"qLpA5JOW4daL"},"source":["#### ğŸ“ ì„¤ëª…: í•™ìŠµ ë° í‰ê°€í•˜ê¸°\n","* RNNì˜ í•™ìŠµ ë°©ë²•ì€ ì•ì„œ ë°°ì› ë˜ DNN, CNNê³¼ ë™ì¼í•˜ê²Œ ì§„í–‰ë©ë‹ˆë‹¤.\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"U2SWum8-4daL","tags":[]},"outputs":[],"source":["# training ì½”ë“œ, evaluation ì½”ë“œ, training_loop ì½”ë“œ\n","def training(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs):\n","    model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •\n","    train_loss = 0.0\n","    train_accuracy = 0\n","\n","    tbar = tqdm(dataloader)\n","    for texts, labels in tbar:\n","        # ìˆœì „íŒŒ\n","        outputs = model(texts)\n","        loss = criterion(outputs, labels)\n","\n","        # ì—­ì „íŒŒ ë° ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # ì†ì‹¤ê³¼ ì •í™•ë„ ê³„ì‚°\n","        train_loss += loss.item()\n","        # torch.maxì—ì„œ dim ì¸ìì— ê°’ì„ ì¶”ê°€í•  ê²½ìš°, í•´ë‹¹ dimensionì—ì„œ ìµœëŒ“ê°’ê³¼ ìµœëŒ“ê°’ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n","        _, predicted = torch.max(outputs, dim=1)\n","\n","\n","        train_accuracy += (predicted == labels).sum().item()\n","\n","        # tqdmì˜ ì§„í–‰ë°”ì— í‘œì‹œë  ì„¤ëª… í…ìŠ¤íŠ¸ë¥¼ ì„¤ì •\n","        tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}\")\n","\n","    # ì—í­ë³„ í•™ìŠµ ê²°ê³¼ ì¶œë ¥\n","    train_loss = train_loss / len(dataloader)\n","    train_accuracy = train_accuracy / len(train_dataset)\n","\n","    return model, train_loss, train_accuracy\n","\n","def evaluation(model, dataloader, valid_dataset, criterion, device, epoch, num_epochs):\n","    model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n","    valid_loss = 0.0\n","    valid_accuracy = 0\n","\n","    with torch.no_grad(): # modelì˜ ì—…ë°ì´íŠ¸ ë§‰ê¸°\n","        tbar = tqdm(dataloader)\n","        for texts, labels in tbar:\n","            # ìˆœì „íŒŒ\n","            outputs = model(texts)\n","            loss = criterion(outputs, labels)\n","\n","            # ì†ì‹¤ê³¼ ì •í™•ë„ ê³„ì‚°\n","            valid_loss += loss.item()\n","            # torch.maxì—ì„œ dim ì¸ìì— ê°’ì„ ì¶”ê°€í•  ê²½ìš°, í•´ë‹¹ dimensionì—ì„œ ìµœëŒ“ê°’ê³¼ ìµœëŒ“ê°’ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n","            _, predicted = torch.max(outputs, 1)\n","            # _, true_labels = torch.max(labels, dim=1)\n","            valid_accuracy += (predicted == labels).sum().item()\n","\n","\n","            # tqdmì˜ ì§„í–‰ë°”ì— í‘œì‹œë  ì„¤ëª… í…ìŠ¤íŠ¸ë¥¼ ì„¤ì •\n","            tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Valid Loss: {loss.item():.4f}\")\n","\n","    valid_loss = valid_loss / len(dataloader)\n","    valid_accuracy = valid_accuracy / len(valid_dataset)\n","\n","    return model, valid_loss, valid_accuracy\n","\n","\n","def training_loop(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name):\n","    best_valid_loss = float('inf')  # ê°€ì¥ ì¢‹ì€ validation lossë¥¼ ì €ì¥\n","    early_stop_counter = 0  # ì¹´ìš´í„°\n","    valid_max_accuracy = -1\n","\n","    for epoch in range(num_epochs):\n","        model, train_loss, train_accuracy = training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\n","        model, valid_loss, valid_accuracy = evaluation(model, valid_dataloader, val_dataset, criterion, device, epoch, num_epochs)\n","\n","        if valid_accuracy > valid_max_accuracy:\n","            valid_max_accuracy = valid_accuracy\n","\n","        # validation lossê°€ ê°ì†Œí•˜ë©´ ëª¨ë¸ ì €ì¥ ë° ì¹´ìš´í„° ë¦¬ì…‹\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            torch.save(model.state_dict(), f\"./model_{model_name}.pt\")\n","            early_stop_counter = 0\n","\n","        # validation lossê°€ ì¦ê°€í•˜ê±°ë‚˜ ê°™ìœ¼ë©´ ì¹´ìš´í„° ì¦ê°€\n","        else:\n","            early_stop_counter += 1\n","\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f} Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}\")\n","\n","        # ì¡°ê¸° ì¢…ë£Œ ì¹´ìš´í„°ê°€ ì„¤ì •í•œ patienceë¥¼ ì´ˆê³¼í•˜ë©´ í•™ìŠµ ì¢…ë£Œ\n","        if early_stop_counter >= patience:\n","            print(\"Early stopping\")\n","            break\n","\n","    return model, valid_max_accuracy"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"referenced_widgets":["feac82a744794495ba18c72a03aa6731","260c7b7ec92a4299879c186396627ad7","4c3497bee69740c9897c26b55ec4c3d0","167ea8861b2e40c0ba48f91462d037a6","70eeff7482854c348eab9dd855cc7ffa","cc89d602997646efb66d2892af40e072","3662fcf89f464975b1ee913ac71f52b6","9b937de5fde7426d8f42016d49766a23","75666c7ac1ab4116b2d3cbc79194cd67","b02de07f2650464093ce935e4c748a05","0ae76e0256724b69b3f9c0e9cd5546a9","bd1b0f64e29749e691a1f80af198207d","d5545591b7e340278d9067c770299768","a28d71d17d844db9ab8e1f1bfb61d727","1bb9763b449a4c108f19a50d83ecdeca","7f29b845c4254909a84d3ec613ee3c82"]},"id":"VgYMR1Hc4daL","outputId":"275e930e-a66f-47cb-e09d-7b16a3e0886e","tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8265207a341a451c9706033880e4a2e1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1159 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5007101a74fb458490fd33bfc0c16436","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/149 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch [1/100], Train Loss: 7.0220, Train Accuracy: 0.1110 Valid Loss: 6.8250, Valid Accuracy: 0.1334\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb53a23d64c540a8b6999f73e9ae6da9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1159 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"163d739195904fc8b68ebfa350a48075","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/149 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch [2/100], Train Loss: 5.3991, Train Accuracy: 0.1641 Valid Loss: 6.9634, Valid Accuracy: 0.1349\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d81ec6f2bd8345878251988985f83e2b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1159 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ebef1ccef4b431a8ecc170e55d5fed7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/149 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch [3/100], Train Loss: 4.2817, Train Accuracy: 0.2244 Valid Loss: 7.2059, Valid Accuracy: 0.1321\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20f1d08406b249d6aca365dcfaf7a82b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1159 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e063a2bd26345ceb1b7aeb9c3e6884e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/149 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch [4/100], Train Loss: 3.3846, Train Accuracy: 0.3325 Valid Loss: 7.4951, Valid Accuracy: 0.1254\n","Early stopping\n","Valid max accuracy :  0.1348670325031659\n"]}],"source":["num_epochs = 100\n","patience = 3\n","model_name = 'RNN'\n","\n","vocab_size = len(vocab)\n","embedding_dim = 512\n","hidden_size = 256\n","model = RNN(vocab_size, embedding_dim, hidden_size).to(device)\n","\n","lr = 1e-3\n","criterion = nn.CrossEntropyLoss(ignore_index = 0)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","model, valid_max_accuracy = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\n","print('Valid max accuracy : ', valid_max_accuracy)"]},{"cell_type":"markdown","metadata":{"id":"j73JhE3C4daL"},"source":["#### ğŸ“ ì„¤ëª…: Next word prediction í‰ê°€\n","* í•™ìŠµí•œ RNN ëª¨ë¸ì„ accuracy scoreë¡œ í‰ê°€í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"referenced_widgets":["875b229676a74855bda020cb76ff3eca","0509ce952a72425fa25bebbfed96fa0d"]},"id":"dY4ATZV_4daM","outputId":"52de8776-80d9-4932-fd94-21ae356f5404","tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c68bc93c6df4643b630003850895b43","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Next word prediction RNN model accuracy :  0.12860892388451445\n"]}],"source":["model.load_state_dict(torch.load(\"./model_RNN.pt\")) # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n","model = model.to(device)\n","model.eval()\n","total_labels = []\n","total_preds = []\n","with torch.no_grad():\n","    for texts, labels in tqdm(test_dataloader):\n","        texts = texts.to(device)\n","        labels = labels\n","\n","        outputs = model(texts)\n","        # torch.maxì—ì„œ dim ì¸ìì— ê°’ì„ ì¶”ê°€í•  ê²½ìš°, í•´ë‹¹ dimensionì—ì„œ ìµœëŒ“ê°’ê³¼ ìµœëŒ“ê°’ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        total_preds.extend(predicted.detach().cpu().tolist())\n","        total_labels.extend(labels.tolist())\n","\n","total_preds = np.array(total_preds)\n","total_labels = np.array(total_labels)\n","nwp_rnn_acc = accuracy_score(total_labels, total_preds) # ì •í™•ë„ ê³„ì‚°\n","print(\"Next word prediction RNN model accuracy : \", nwp_rnn_acc)"]},{"cell_type":"markdown","metadata":{"id":"IyS_cf8mGGL3"},"source":["## 2. LSTM êµ¬í˜„í•˜ê¸°\n","\n","```\n","ğŸ’¡ ëª©ì°¨ ê°œìš”: ê¸°ë³¸ì ì¸ LSTM êµ¬ì¡°ë¥¼ ì´í•´í•˜ê³ , ì´ë¥¼ PyTorchë¡œ LSTM ëª¨ë¸ì„ êµ¬ì¶•í•´ë´…ë‹ˆë‹¤.\n","```\n","\n","- 2-1. LSTM êµ¬í˜„í•˜ê¸°\n","- 2-2. í•™ìŠµ ë° í‰ê°€\n"]},{"cell_type":"markdown","metadata":{"id":"MoVwB9f-GGMD"},"source":["### 2-1 LSTM êµ¬í˜„í•˜ê¸°\n","\n","> `torch.nn.LSTM`ì„ í†µí•´ LSTM ëª¨ë¸ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"]},{"cell_type":"markdown","metadata":{"id":"i_1Rj6B5__dh"},"source":["#### ğŸ“ ì„¤ëª…: LSTMì´ë€?\n","<img src='https://upload.wikimedia.org/wikipedia/commons/9/98/LSTM.png'></img>\n","* LSTM (Long Short-Term Memory)ì˜ ì•½ìë¡œ RNNì˜ ë‹¨ì ì¸ ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê³ ì•ˆëœ ëª¨ë¸ì…ë‹ˆë‹¤.\n","  * RNNì˜ ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œ: ì‹œí€€ìŠ¤ê°€ ê¸¸ì–´ì§ˆìˆ˜ë¡ ì•ë¶€ë¶„ì˜ ì •ë³´ê°€ ë’·ë¶€ë¶„ì˜ ì˜ˆì¸¡ì— ì˜í–¥ì„ ë¯¸ì¹˜ê¸° ì–´ë ¤ìš´ ë¬¸ì œ\n","\n","<!-- * LSTMì˜ ê²Œì´íŠ¸\n","  * Input gate: ìƒˆë¡œìš´ ì…ë ¥ì„ ê¸°ì–µí•˜ëŠ”ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ ê²Œì´íŠ¸ëŠ” ì–´ë–¤ ì •ë³´ë¥¼ ì–¼ë§ˆë§Œí¼ ê¸°ì–µí• ì§€ ê²°ì •í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n","\n","  * Forget gate: ê³¼ê±° ì •ë³´ë¥¼ ì–¼ë§ˆë§Œí¼ ì‚­ì œí• ì§€ ê²°ì •í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë¶ˆí•„ìš”í•œ ì •ë³´ë¥¼ ì œê±°í•˜ê³  ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œë¥¼ ì™„í™”í•©ë‹ˆë‹¤.\n","\n","  * Output gate: í˜„ì¬ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœë¥¼ ê³„ì‚°í•˜ëŠ”ë° ì‚¬ìš©ë©ë‹ˆë‹¤. LSTMì´ ë‹¤ìŒ ì‹œì ìœ¼ë¡œ ì–¼ë§ˆë§Œí¼ ì •ë³´ë¥¼ ì „ë‹¬í• ì§€ ê²°ì •í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. -->\n","\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [LSTM paper](https://dl.acm.org/doi/10.1162/neco.1997.9.8.1735)\n","* [LSTM ì„¤ëª…](https://dgkim5360.tistory.com/entry/understanding-long-short-term-memory-lstm-kr)\n","* [ì´ë¯¸ì§€ ì¶œì²˜](https://commons.wikimedia.org/wiki/File:LSTM.png)\n"]},{"cell_type":"markdown","metadata":{"id":"tIzlbxBUEJPf"},"source":["#### ğŸ“ ì„¤ëª…: PyTorchì—ì„œì˜ LSTM êµ¬í˜„ì€ ì–´ë–»ê²Œ í• ê¹Œ?\n","* LSTMì€ `torch.nn.LSTM`ì„ í†µí•´ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","* torch.nn.LSTM RNNê³¼ ë™ì¼í•˜ê²Œ ê¸°ë³¸ì ìœ¼ë¡œ `input_size`ì™€ `hidden_size`ë¥¼ ì§€ì •í•´ì¤˜ì•¼í•©ë‹ˆë‹¤.\n","  * `input_size`: embedding dimension\n","  * `hidden_size`: hidden state dimension\n","* ì¼ë°˜ì ìœ¼ë¡œ RNNê³¼ ë™ì¼í•˜ê²Œ ë§ˆì§€ë§‰ time stepì˜ hidden state ì •ë³´ë§Œ ì¶”ì¶œí•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.\n","* torch.LSTMì˜ outputì€ ëª¨ë“  time stepì˜ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” hidden stateì™€ ë§ˆì§€ë§‰ time_stepì˜ ì •ë³´ë§Œ ë‹´ê³  ìˆëŠ” hidden state, ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ time_stepì˜ ì •ë³´ë§Œ ë‹´ê³  ìˆëŠ” cell stateê¹Œì§€ 3ê°œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [PyTorch LSTM ê³µì‹ document](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"ryXXTEN34daN","tags":[]},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class LSTM(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size):\n","        super(LSTM, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, x):\n","        '''\n","        INPUT:\n","           x: [batch_size, seq_len]\n","        OUTPUT:\n","           output: [batch_size, vocab_size]\n","        '''\n","        x = self.embedding(x) # [batch_size, sequence_len, embedding_dim]\n","        # lstmì—ì„  ë§ˆì§€ë§‰ time stepì—ì„œì˜ cell state (c_n)ë„ ë°˜í™˜í•©ë‹ˆë‹¤.\n","        output, h_0, c_0 = self.lstm(x) # output : [batch_size, seq_len, hidden_dim] # h_n: [1, batch_size, hidden_dim] # c_n: [1, batch_size, hidden_dim]\n","        return self.fc(output[:,-1,:]) # [batch_size, num_classes]\n"]},{"cell_type":"markdown","metadata":{"id":"putvSavw4daN"},"source":["#### ğŸ“ ì„¤ëª…: í•™ìŠµ ë° í‰ê°€í•˜ê¸°\n","* LSTMì˜ í•™ìŠµ ë°©ë²•ì€ ì•ì„œ ë°°ì› ë˜ DNN, CNNê³¼ ë™ì¼í•˜ê²Œ ì§„í–‰ë©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"referenced_widgets":["e6dfadbea0dd43d191a31a092404d956","78d9a11989a34baebb903a4d245fe8dd","5ba8eeb79bd74a7c836a94b65e6e75af","9fe554fa3dca45b38d2b794aa9f51dbf","c20d5ed497724412bb131fd684826fbe","5860a075e8254093b54b12ce960b857d","916af6d32b344ce1af8e7bcaa9f4696b","0f920f9b46684f6a84078b360d542e3a","cadcfc6b16534bdaa1b0c89b94a3f552","04ad08c29e2047de83dd02d54c354a4a","35dbb80110124fb6ac41d21ece97f754","430959f2f2404f1a8ad7267e02f0edfb","0e676f673a404111bbcfd358917387a7","0a34926e16734958ba26e23f631f1772","5336d80808b149909890f00a2b8c3a1c","4195af8101e645e4b15e0b8498c4a1a3","04c1af917851464e88d063f812857ce1","4a112f6b17764aa7a9a1b04fbebd17ae"]},"id":"qLFTn4g54daN","outputId":"13183ec8-1d3b-4e6c-cd4f-6ea4787a0f74","tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ea8028e3e684d7ba18331d93a289c8f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1159 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"ValueError","evalue":"not enough values to unpack (expected 3, got 2)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m---> 14\u001b[0m model, valid_max_accuracy \u001b[38;5;241m=\u001b[39m training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValid max accuracy : \u001b[39m\u001b[38;5;124m'\u001b[39m, valid_max_accuracy)\n","Cell \u001b[0;32mIn[17], line 70\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\u001b[0m\n\u001b[1;32m     67\u001b[0m valid_max_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 70\u001b[0m     model, train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\n\u001b[1;32m     71\u001b[0m     model, valid_loss, valid_accuracy \u001b[38;5;241m=\u001b[39m evaluation(model, valid_dataloader, val_dataset, criterion, device, epoch, num_epochs)\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_accuracy \u001b[38;5;241m>\u001b[39m valid_max_accuracy:\n","Cell \u001b[0;32mIn[17], line 10\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m tbar \u001b[38;5;241m=\u001b[39m tqdm(dataloader)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m texts, labels \u001b[38;5;129;01min\u001b[39;00m tbar:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# ìˆœì „íŒŒ\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(texts)\n\u001b[1;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# ì—­ì „íŒŒ ë° ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\u001b[39;00m\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[24], line 20\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x) \u001b[38;5;66;03m# [batch_size, sequence_len, embedding_dim]\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# lstmì—ì„  ë§ˆì§€ë§‰ time stepì—ì„œì˜ cell state (c_n)ë„ ë°˜í™˜í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m output, h_0, c_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x) \u001b[38;5;66;03m# output : [batch_size, seq_len, hidden_dim] # h_n: [1, batch_size, hidden_dim] # c_n: [1, batch_size, hidden_dim]\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:])\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"]}],"source":["num_epochs = 100\n","patience = 3\n","model_name = 'LSTM'\n","\n","vocab_size = len(vocab)\n","embedding_dim = 512\n","hidden_size = 256\n","model = LSTM(vocab_size, embedding_dim, hidden_size).to(device)\n","\n","lr = 1e-3\n","criterion = nn.CrossEntropyLoss(ignore_index = 0)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","model, valid_max_accuracy = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\n","print('Valid max accuracy : ', valid_max_accuracy)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"referenced_widgets":["7932fc6caeda44a3a0848c8f758f3a92","c0b82bd8cf1f4dc2a0204da681e069f3"]},"id":"1Z26-P_X4daN","outputId":"4fe6e4be-be10-496b-fe86-caf8d2429c5b","tags":[]},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './model_LSTM.pt'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./model_LSTM.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;66;03m# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './model_LSTM.pt'"]}],"source":["model.load_state_dict(torch.load(\"./model_LSTM.pt\")) # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n","model = model.to(device)\n","model.eval()\n","total_labels = []\n","total_preds = []\n","with torch.no_grad():\n","    for texts, labels in tqdm(test_dataloader):\n","        texts = texts.to(device)\n","        labels = labels\n","\n","        outputs = model(texts)\n","        # torch.maxì—ì„œ dim ì¸ìì— ê°’ì„ ì¶”ê°€í•  ê²½ìš°, í•´ë‹¹ dimensionì—ì„œ ìµœëŒ“ê°’ê³¼ ìµœëŒ“ê°’ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        total_preds.extend(predicted.detach().cpu().tolist())\n","        total_labels.extend(labels.tolist())\n","\n","total_preds = np.array(total_preds)\n","total_labels = np.array(total_labels)\n","nwp_lstm_acc = accuracy_score(total_labels, total_preds) # ì •í™•ë„ ê³„ì‚°\n","print(\"Next word prediction LSTM model accuracy : \", nwp_lstm_acc)"]},{"cell_type":"markdown","metadata":{"id":"_QLFPfgsGR44"},"source":["## 3. GRU êµ¬í˜„í•˜ê¸°\n","\n","```\n","ğŸ’¡ ëª©ì°¨ ê°œìš”: ê¸°ë³¸ì ì¸ GRU êµ¬ì¡°ë¥¼ ì´í•´í•˜ê³ , ì´ë¥¼ PyTorchë¡œ GRU ëª¨ë¸ì„ êµ¬í˜„í•´ë´…ë‹ˆë‹¤.\n","```\n","\n","- 3-1. GRU êµ¬í˜„í•˜ê¸°\n","- 3-2. í•™ìŠµ ë° í‰ê°€\n"]},{"cell_type":"markdown","metadata":{"id":"dcRGKfqwGR44"},"source":["### 3-1 GRU êµ¬í˜„í•˜ê¸°\n","\n","> `torch.nn.GRU`ì„ í†µí•´ GRU ëª¨ë¸ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"]},{"cell_type":"markdown","metadata":{"id":"uIRB5FDTHAhw"},"source":["#### ğŸ“ ì„¤ëª…: GRUë€?\n","<img src='https://upload.wikimedia.org/wikipedia/commons/b/b9/GRU.png'></img>\n","* GRU (Gated Recurrent Unit)ëŠ” LSTMê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  RNNì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ê³ ì•ˆëœ ëª¨ë¸ì…ë‹ˆë‹¤.\n","<!-- * LSTMì€ 3ê°œì˜ ê²Œì´íŠ¸ (Input gate, Forget gate, Output gate)ë¥¼ ê°€ì§€ëŠ” ë°˜ë©´ì— GRUëŠ” 2ê°œì˜ ê²Œì´íŠ¸ë¥¼ ê°€ì ¸, LSTMë³´ë‹¤ ë”ìš± ê°„ë‹¨í•œ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤. -->\n","* GRUëŠ” LSTMì— ë¹„í•˜ì—¬ íŒŒë¼ë¯¸í„°ìˆ˜ê°€ ì ê¸° ë•Œë¬¸ì— ì—°ì‚° ë¹„ìš©ì´ ì ê²Œ ë“¤ê³ , êµ¬ì¡°ë„ ë” ê°„ë‹¨í•˜ì§€ë§Œ, ì„±ëŠ¥ì—ì„œë„ LSTMê³¼ ë¹„ìŠ·í•œ ê²°ê³¼ë¥¼ ëƒ…ë‹ˆë‹¤.\n","<!-- * GRUì˜ ê²Œì´íŠ¸\n","  * Reset Gate: ì´ì „ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœì™€ í˜„ì¬ ì‹œì ì˜ ì…ë ¥ì„ ì¡°í•©í•˜ì—¬ ì–´ë–¤ ì •ë³´ë¥¼ ë¬´ì‹œí• ì§€ ê²°ì •í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n","\n","  * Update Gate: ì´ì „ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœì™€ í˜„ì¬ ì‹œì ì˜ ì…ë ¥ì„ ì¡°í•©í•˜ì—¬ ìƒˆë¡œìš´ ì€ë‹‰ ìƒíƒœì— ì–¼ë§ˆë‚˜ ë§ì€ ì •ë³´ë¥¼ ë°˜ì˜í• ì§€ ê²°ì •í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. -->\n","\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [GRU paper](https://arxiv.org/abs/1406.1078)\n","* [GRU ì„¤ëª…](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be)\n","* [ì´ë¯¸ì§€ ì¶œì²˜](https://commons.wikimedia.org/wiki/File:GRU.png)\n"]},{"cell_type":"markdown","metadata":{"id":"86GhT0f04daS"},"source":["#### ğŸ“ ì„¤ëª…: PyTorchì—ì„œì˜ GRU êµ¬í˜„ì€ ì–´ë–»ê²Œ í• ê¹Œ?\n","* GRUëŠ” PyTorchì— `torch.nn.GRU`ì„ í†µí•´ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","* torch.nn.GRU RNN, LSTMê³¼ ë™ì¼í•˜ê²Œ ê¸°ë³¸ì ìœ¼ë¡œ `input_size`ì™€ `hidden_size`ë¥¼ ì§€ì •í•´ì¤˜ì•¼í•©ë‹ˆë‹¤.\n","  * `input_size`: embedding dimension\n","  * `hidden_size`: hidden state dimension\n","* torch.LSTMì˜ outputì€ ëª¨ë“  time stepì˜ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” hidden stateì™€ ë§ˆì§€ë§‰ time_stepì˜ ì •ë³´ë§Œ ë‹´ê³  ìˆëŠ” hidden state 2ê°œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [PyTorch GRU ê³µì‹ document](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"lzMT319l4daS","tags":[]},"outputs":[],"source":["class GRU(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size):\n","        super(GRU, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.gru = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, x):\n","        '''\n","        INPUT:\n","           x: [batch_size, seq_len]\n","        OUTPUT:\n","           output: [batch_size, vocab_size]\n","        '''\n","        x = self.embedding(x) # [batch_size, sequence_len, embedding_dim]\n","        output, h_0 = self.gru(x) # output : [batch_size, seq_len, hidden_dim] # h_0 ëŠ” [1, batch_size, hidden_dim]\n","        return self.fc(output[:,-1,:]) # [batch_size, vocab_size]"]},{"cell_type":"markdown","metadata":{"id":"GEOD96vg4daS"},"source":["### 3-2 í•™ìŠµ ë° í‰ê°€\n","\n","> êµ¬ì¶•í•œ GRU ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•´ë´…ë‹ˆë‹¤.\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"referenced_widgets":["37c30a1841c24c4089a3b2396b2b6472","3ea7087a15a1437690491a33ebc214cc","802b03cf7f5f43cea388dff88fb34361","e35975f4fc424019984615e146acd675","1eeba675a2a9414f853dd4d877a0e3a5","a88ac9b953be44798f36612c0677491b","1068a4013dc14c24bb3f83981d017dbc","9cda2d930e36405c9ef205abfa5c1b39","28e69aba7f4f44d9a3fd0e54cff88150","ec453c54720c4c85900efa79089ed8c2","40b6a0568ce948bbbd88b21f37b6fa68","911d34369bb24799bbfa9c01dbf89e4a","6643756d32274b5cb4453ca079784c6a","d374e2f8928548a1838b2def6ccff48e","4c91ec5eaa03449395397e54bca6106e","8e6e7656c0ea4f9da0d8ca06814d61bd"]},"id":"xyNTPD9k4daS","outputId":"290b1c32-55f2-4fba-b294-40d6d97a7190","tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"542976523a6845af80b3fa20003e1c65","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1159 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68517d7e555d483c90e7b7c223da76f8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/149 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch [1/100], Train Loss: 6.8902, Train Accuracy: 0.1141 Valid Loss: 6.6764, Valid Accuracy: 0.1317\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f22d20c9a7614726866db0fbfdd88f57","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1159 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m---> 14\u001b[0m model, valid_max_accuracy \u001b[38;5;241m=\u001b[39m training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValid max accuracy : \u001b[39m\u001b[38;5;124m'\u001b[39m, valid_max_accuracy)\n","Cell \u001b[0;32mIn[17], line 70\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\u001b[0m\n\u001b[1;32m     67\u001b[0m valid_max_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 70\u001b[0m     model, train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\n\u001b[1;32m     71\u001b[0m     model, valid_loss, valid_accuracy \u001b[38;5;241m=\u001b[39m evaluation(model, valid_dataloader, val_dataset, criterion, device, epoch, num_epochs)\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_accuracy \u001b[38;5;241m>\u001b[39m valid_max_accuracy:\n","Cell \u001b[0;32mIn[17], line 10\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m tbar \u001b[38;5;241m=\u001b[39m tqdm(dataloader)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m texts, labels \u001b[38;5;129;01min\u001b[39;00m tbar:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# ìˆœì „íŒŒ\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(texts)\n\u001b[1;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# ì—­ì „íŒŒ ë° ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\u001b[39;00m\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[27], line 17\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x) \u001b[38;5;66;03m# [batch_size, sequence_len, embedding_dim]\u001b[39;00m\n\u001b[1;32m     16\u001b[0m output, h_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru(x) \u001b[38;5;66;03m# output : [batch_size, seq_len, hidden_dim] # h_0 ëŠ” [1, batch_size, hidden_dim]\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:])\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["num_epochs = 100\n","patience = 3\n","model_name = 'GRU'\n","\n","vocab_size = len(vocab)\n","embedding_dim = 512\n","hidden_size = 256\n","model = GRU(vocab_size, embedding_dim, hidden_size).to(device)\n","\n","lr = 1e-3\n","criterion = nn.CrossEntropyLoss(ignore_index = 0)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","model, valid_max_accuracy = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\n","print('Valid max accuracy : ', valid_max_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["ce0d777efe9b4fbab5fa4db7b616c424","dba457913e314a7ab13ca45598d00c5a"]},"id":"gJBiAiTw4daT","outputId":"003ea6a5-fef3-4cd6-bc96-56b2688cc780","tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dba457913e314a7ab13ca45598d00c5a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/143 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Next word prediction GRU model accuracy :  0.1384514435695538\n"]}],"source":["model.load_state_dict(torch.load(\"./model_GRU.pt\")) # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n","model = model.to(device)\n","model.eval()\n","total_labels = []\n","total_preds = []\n","with torch.no_grad():\n","    for texts, labels in tqdm(test_dataloader):\n","        texts = texts.to(device)\n","        labels = labels\n","\n","        outputs = model(texts)\n","        # torch.maxì—ì„œ dim ì¸ìì— ê°’ì„ ì¶”ê°€í•  ê²½ìš°, í•´ë‹¹ dimensionì—ì„œ ìµœëŒ“ê°’ê³¼ ìµœëŒ“ê°’ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        total_preds.extend(predicted.detach().cpu().tolist())\n","        total_labels.extend(labels.tolist())\n","\n","total_preds = np.array(total_preds)\n","total_labels = np.array(total_labels)\n","nwp_gru_acc = accuracy_score(total_labels, total_preds) # ì •í™•ë„ ê³„ì‚°\n","print(\"Next word prediction GRU model accuracy : \", nwp_gru_acc)"]},{"cell_type":"markdown","metadata":{"id":"6fk7uBULLALr"},"source":["## 4. Bi-directional RNN/LSTM/GRU\n","\n","```\n","ğŸ’¡ ëª©ì°¨ ê°œìš”: ê¸°ë³¸ì ì¸ Bi-directional RNN/LSTM/GRU êµ¬ì¡°ë¥¼ ì´í•´í•˜ê³ , ì´ë¥¼ PyTorchë¡œ Bi-directional RNN/LSTM/GRU ëª¨ë¸ì„ êµ¬ì¶•í•´ë´…ë‹ˆë‹¤.\n","```\n","\n","- 4-1. Bi-directional RNN/LSTM/GRU êµ¬í˜„í•˜ê¸°\n","- 4-2. í•™ìŠµ ë° í‰ê°€\n"]},{"cell_type":"markdown","metadata":{"id":"3VDFqcZcLALs"},"source":["### 4-1 Bi-directional RNN/LSTM/GRU êµ¬í˜„í•˜ê¸°\n","\n","> `bidirectional=True`ë¥¼ í†µí•´ Bi-directional RNN/LSTM/GRU ëª¨ë¸ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"]},{"cell_type":"markdown","metadata":{"id":"dnFM1q9mIylb"},"source":["#### ğŸ“ ì„¤ëª…: Bi-directional RNNì´ë€?\n","<img src='https://upload.wikimedia.org/wikipedia/commons/3/35/Structural_diagrams_of_unidirectional_and_bidirectional_recurrent_neural_networks.png'></img>\n","* RNN/LSTM/GRUì€ **ê³¼ê±°**ì˜ ì •ë³´ë§Œ ì´ìš©í•˜ì—¬ ë‹¤ìŒì„ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Bi-directional RNN/LSTM/GRUì€ **ê³¼ê±° ë¿ë§Œ ì•„ë‹ˆë¼ ë¯¸ë˜**ì˜ ì •ë³´ë¥¼ ì´ìš©í•˜ì—¬ ë‹¤ìŒì„ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\n","* ì˜ˆë¥¼ ë“¤ì–´ ë‹¤ìŒê³¼ ê°™ì€ 3ê°€ì§€ ë¬¸ì¥ì´ ìˆë‹¤ê³  í•´ë´…ì‹œë‹¤.\n","  1. I'm ____.\n","    \n","    * sad, happy, hungryì™€ ê°™ì€ ë‹¤ì–‘í•œ ë‹¨ì–´ë“¤ì´ ë“¤ì–´ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","  2. I'm ____ hungry.\n","\n","   * very ë˜ëŠ” notê³¼ ê°™ì€ ë‹¨ì–´ë“¤ì´ ë“¤ì–´ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 1ë²ˆë³´ë‹¨ ë“¤ì–´ê°ˆ ìˆ˜ ìˆëŠ” ë‹¨ì–´ê°€ ì ìŠµë‹ˆë‹¤.\n","  3. I'm ____ hungry, so I can eat more.\n","    * not ì´ë¼ëŠ” ë‹¨ì–´ê°€ ë§¤ìš° ì ì ˆí•©ë‹ˆë‹¤.\n","\n","* ì´ì™€ ê°™ì€ ì˜ˆì‹œì²˜ëŸ¼, ì•ì˜ ë‹¨ì–´ë“¤ ë¿ë§Œ ì•„ë‹ˆë¼ ë’¤ì˜ ë‹¨ì–´ë“¤ì„ ê³ ë ¤í•˜ì—¬ ë¬¸ë§¥ì„ ì´í•´í•  ìˆ˜ ìˆê³ , ë”ìš± ì ì ˆí•œ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","\n","\n","ğŸ“š ì°¸ê³ í• ë§Œí•œ ìë£Œ:\n","* [bi-directional RNN paper](https://ieeexplore.ieee.org/document/650093)\n","* [bi-directional RNN ì„¤ëª…](https://hyen4110.tistory.com/29)\n","* [ì´ë¯¸ì§€ ì¶œì²˜](https://commons.wikimedia.org/wiki/File:Structural_diagrams_of_unidirectional_and_bidirectional_recurrent_neural_networks.png)\n","<!-- * [ì´ë¯¸ì§€ ì¶œì²˜](https://d2l.ai/chapter_recurrent-modern/bi-rnn.html) -->\n"]},{"cell_type":"markdown","metadata":{"id":"ogmtD1jr4daU"},"source":["#### ğŸ“ ì„¤ëª…: PyTorchì—ì„œì˜ ì–‘ë°©í–¥ RNN/GRU/LSTM ëª¨ë¸ì€ ì–´ë–»ê²Œ êµ¬í˜„í• ê¹Œ?\n","* ì–‘ë°©í–¥ ëª¨ë¸ì„ êµ¬í˜„í•˜ê¸° ìœ„í•´ì„ , `torch.nn.RNN/LSTM/GRU`ì˜ `bidirectional` ì¸ìë¥¼ Trueë¡œ ì„¤ì •í•´ì£¼ë©´ ë©ë‹ˆë‹¤.\n","* ì´ ë•Œ, **ì–‘ë°©í–¥** RNN/GRU/LSTMì´ë¯€ë¡œ hidden stateì˜ í¬ê¸°ê°€ bidirectional=False ì¼ ë•Œ ë³´ë‹¤ 2ë°° ë” ì»¤ì§‘ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ke01atpl4daU","tags":[]},"outputs":[],"source":["class Bidirectional(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size, model_name):\n","        super(Bidirectional, self).__init__()\n","\n","        self.model_name = model_name # êµ¬í˜„í•  ëª¨ë¸ì˜ ì´ë¦„ì„ ì§€ì •í•´ì¤ë‹ˆë‹¤.\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","\n","        if self.model_name == 'bi_RNN':\n","            self.model = nn.RNN(embedding_dim, hidden_size, batch_first=True, bidirectional=True) # ì–‘ë°©í–¥ì„± ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n","        elif self.model_name == 'bi_LSTM':\n","            self.model = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n","        elif self.model_name == 'bi_GRU':\n","            self.model = nn.GRU(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size * 2, vocab_size)\n","\n","    def forward(self, x):\n","        '''\n","        INPUT:\n","           x: [batch_size, seq_len]\n","        OUTPUT:\n","           output: [batch_size, vocab_size]\n","        '''\n","        x = self.embedding(x) # [batch_size, sequence_len, embedding_dim]\n","\n","        output, _ = self.model(x)\n","        return self.fc(output[:,-1,:]) # [batch_size, vocab_size]\n"]},{"cell_type":"markdown","metadata":{"id":"ccjxx1QG4daU"},"source":["### 4-1 í•™ìŠµ ë° í‰ê°€\n","\n","> bidirectional RNN/LSTM/GRUë¥¼ í•™ìŠµí•˜ê³  í‰ê°€í•˜ì—¬ ë¹„êµí•´ë´…ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"glzyyCbh4daU","tags":[]},"outputs":[],"source":["# training ì½”ë“œ, evaluation ì½”ë“œ, training_loop ì½”ë“œ\n","def training(model, dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs):\n","  model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •\n","  train_loss = 0.0\n","  train_accuracy = 0\n","\n","  for texts, labels in dataloader:\n","      texts = texts.to(device)\n","      labels = labels.to(device)\n","\n","      # ìˆœì „íŒŒ\n","      outputs = model(texts)\n","      loss = criterion(outputs, labels)\n","\n","      # ì—­ì „íŒŒ ë° ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","      # ì†ì‹¤ê³¼ ì •í™•ë„ ê³„ì‚°\n","      train_loss += loss.item()\n","      # torch.maxì—ì„œ dim ì¸ìì— ê°’ì„ ì¶”ê°€í•  ê²½ìš°, í•´ë‹¹ dimensionì—ì„œ ìµœëŒ“ê°’ê³¼ ìµœëŒ“ê°’ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n","      _, predicted = torch.max(outputs, 1)\n","      train_accuracy += (predicted == labels).sum().item()\n","\n","\n","  # ì—í­ë³„ í•™ìŠµ ê²°ê³¼ ì¶œë ¥\n","  train_loss = train_loss / len(dataloader)\n","  train_accuracy = train_accuracy / len(train_dataset)\n","\n","  return model, train_loss, train_accuracy\n","\n","def evaluation(model, dataloader, val_dataset, criterion, device, epoch, num_epochs):\n","  model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n","  valid_loss = 0.0\n","  valid_accuracy = 0\n","\n","  with torch.no_grad(): # modelì˜ ì—…ë°ì´íŠ¸ ë§‰ê¸°\n","      for texts, labels in dataloader:\n","          texts = texts.to(device)\n","          labels = labels.to(device)\n","\n","          # ìˆœì „íŒŒ\n","          outputs = model(texts)\n","          loss = criterion(outputs, labels)\n","\n","          # ì†ì‹¤ê³¼ ì •í™•ë„ ê³„ì‚°\n","          valid_loss += loss.item()\n","          # torch.maxì—ì„œ dim ì¸ìì— ê°’ì„ ì¶”ê°€í•  ê²½ìš°, í•´ë‹¹ dimensionì—ì„œ ìµœëŒ“ê°’ê³¼ ìµœëŒ“ê°’ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n","          _, predicted = torch.max(outputs, 1)\n","          valid_accuracy += (predicted == labels).sum().item()\n","\n","\n","  valid_loss = valid_loss / len(dataloader)\n","  valid_accuracy = valid_accuracy / len(val_dataset)\n","\n","  return model, valid_loss, valid_accuracy\n","\n","\n","def training_loop(model, train_dataloader, valid_dataloader, train_dataset, val_dataset, criterion, optimizer, device, num_epochs, patience, model_name):\n","    best_valid_loss = float('inf')  # ê°€ì¥ ì¢‹ì€ validation lossë¥¼ ì €ì¥\n","    early_stop_counter = 0  # ì¹´ìš´í„°\n","    valid_max_accuracy = -1\n","\n","    for epoch in range(num_epochs):\n","        model, train_loss, train_accuracy = training(model, train_dataloader, train_dataset, criterion, optimizer, device, epoch, num_epochs)\n","        model, valid_loss, valid_accuracy = evaluation(model, valid_dataloader, val_dataset, criterion, device, epoch, num_epochs)\n","\n","        if valid_accuracy > valid_max_accuracy:\n","          valid_max_accuracy = valid_accuracy\n","\n","        # validation lossê°€ ê°ì†Œí•˜ë©´ ëª¨ë¸ ì €ì¥ ë° ì¹´ìš´í„° ë¦¬ì…‹\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            torch.save(model.state_dict(), f\"./model_{model_name}.pt\")\n","            early_stop_counter = 0\n","\n","        # validation lossê°€ ì¦ê°€í•˜ê±°ë‚˜ ê°™ìœ¼ë©´ ì¹´ìš´í„° ì¦ê°€\n","        else:\n","            early_stop_counter += 1\n","\n","\n","        # ì¡°ê¸° ì¢…ë£Œ ì¹´ìš´í„°ê°€ ì„¤ì •í•œ patienceë¥¼ ì´ˆê³¼í•˜ë©´ í•™ìŠµ ì¢…ë£Œ\n","        if early_stop_counter >= patience:\n","            print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n","            break\n","\n","    return model, valid_max_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"phhqHOOG4daV","tags":[]},"outputs":[],"source":["def test(model, model_name, test_dataloader, device):\n","    model.load_state_dict(torch.load(f\"./model_{model_name}.pt\")) # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n","    model = model.to(device)\n","    model.eval()\n","    total_labels = []\n","    total_preds = []\n","    total_probs = []\n","    with torch.no_grad():\n","        for texts, labels in test_dataloader:\n","            texts = texts.to(device)\n","            labels = labels\n","\n","            outputs = model(texts)\n","            # torch.maxì—ì„œ dim ì¸ìì— ê°’ì„ ì¶”ê°€í•  ê²½ìš°, í•´ë‹¹ dimensionì—ì„œ ìµœëŒ“ê°’ê³¼ ìµœëŒ“ê°’ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            total_preds.extend(predicted.detach().cpu().tolist())\n","            total_labels.extend(labels.tolist())\n","            total_probs.append(outputs.detach().cpu().numpy())\n","\n","    total_preds = np.array(total_preds)\n","    total_labels = np.array(total_labels)\n","    total_probs = np.concatenate(total_probs, axis= 0)\n","    acc = accuracy_score(total_labels, total_preds) # ì •í™•ë„ ê³„ì‚°\n","    print(f\"{model_name} accuracy : \", acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sL2rzOT34daV","outputId":"10f9ee85-4326-46f4-e863-34096d9693ba","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [4/100]\n","bi_RNN valid max accuracy :  0.12494723512030392\n","bi_RNN accuracy :  0.12270341207349081\n","------------------------------------------------------------\n","\n","Epoch [4/100]\n","bi_LSTM valid max accuracy :  0.1409877585479105\n","bi_LSTM accuracy :  0.1388888888888889\n","------------------------------------------------------------\n","\n","Epoch [4/100]\n","bi_GRU valid max accuracy :  0.13782186576614605\n","bi_GRU accuracy :  0.13757655293088364\n","------------------------------------------------------------\n","\n"]}],"source":["model_name_list = ['bi_RNN', 'bi_LSTM', 'bi_GRU'] # í›ˆë ¨ ë° í‰ê°€í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸\n","\n","patience = 3\n","num_epochs = 100\n","\n","vocab_size = len(vocab)\n","embedding_dim = 512\n","hidden_size = 256\n","lr = 1e-3\n","for model_name in model_name_list:\n","    model = Bidirectional(vocab_size, embedding_dim, hidden_size, model_name).to(device)\n","    criterion = nn.CrossEntropyLoss(ignore_index = 0)\n","    optimizer = optim.Adam(model.parameters(), lr = lr)\n","    model, valid_max_accuracy = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, patience, model_name)\n","    print(f'{model_name} valid max accuracy : ', valid_max_accuracy)\n","    test(model, model_name, test_dataloader, device)\n","    print('---'*20)\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"c1HHIbXrp5pZ"},"source":["## Required Package\n","\n","> torch == 2.0.1\n","\n","> torchvision == 0.15.2\n","\n","> sklearn == 1.3.0\n","\n","> torchtext == 0.15.2"]},{"cell_type":"markdown","metadata":{"id":"k6fnxdyLp2Qk"},"source":["## ì½˜í…ì¸  ë¼ì´ì„ ìŠ¤\n","\n","ì €ì‘ê¶Œ : <font color='blue'> <b> Â©2023 by Upstage X fastcampus Co., Ltd. All rights reserved.</font></b>\n","\n","<font color='red'><b>WARNING</font> : ë³¸ êµìœ¡ ì½˜í…ì¸ ì˜ ì§€ì‹ì¬ì‚°ê¶Œì€ ì—…ìŠ¤í…Œì´ì§€ ë° íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ì— ê·€ì†ë©ë‹ˆë‹¤. ë³¸ ì½˜í…ì¸ ë¥¼ ì–´ë– í•œ ê²½ë¡œë¡œë“  ì™¸ë¶€ë¡œ ìœ ì¶œ ë° ìˆ˜ì •í•˜ëŠ” í–‰ìœ„ë¥¼ ì—„ê²©íˆ ê¸ˆí•©ë‹ˆë‹¤. </b>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FhNyMAYsh2v3"},"outputs":[],"source":[]}],"metadata":{"colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
