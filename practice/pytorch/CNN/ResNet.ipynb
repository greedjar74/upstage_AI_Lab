{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BottleNeck Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(torch.nn.Module): # bottleneck buliding block\n",
    "    def __init__(self, in_channels, out_channels, stride=1, mul=4):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        self.mul = mul # 출력 채널 수를 몇 배로 늘릴 것인지\n",
    "        #첫 Convolution은 너비와 높이 downsampling\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False) # 1 x 1 conv\n",
    "        self.bn1 = torch.nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = torch.nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False) # 3 x 3 conv\n",
    "        self.bn2 = torch.nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv3 = torch.nn.Conv2d(out_channels, out_channels*self.mul, kernel_size=1, stride=1, bias=False) # 1 x 1 conv\n",
    "        self.bn3 = torch.nn.BatchNorm2d(out_channels*self.mul)\n",
    "\n",
    "\n",
    "        self.shortcut = torch.nn.Sequential() # input 값이 그대로 반환됩니다.\n",
    "\n",
    "        # shortcut connection: 입력 x의 크기를 맞추기 위해 1x1 컨볼루션 및 배치 정규화 수행\n",
    "        # stride 같은 요소 때문에 출력의 크기가 달라질 수 있습니다.\n",
    "        if stride != 1 or in_channels != out_channels*self.mul:\n",
    "            self.shortcut = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels, out_channels*self.mul, kernel_size=1, stride=stride, bias=False), # 1 x 1 conv\n",
    "                torch.nn.BatchNorm2d(out_channels*self.mul)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x) # [batch_size, out_channels, height, width]\n",
    "        out = self.bn1(out) # [batch_size, out_channels, height, width]\n",
    "        out = F.relu(out) # [batch_size, out_channels, height, width]\n",
    "        out = self.conv2(out) # [batch_size, out_channels, height, width]\n",
    "        out = self.bn2(out) # [batch_size, out_channels, height, width]\n",
    "        out = F.relu(out) # [batch_size, out_channels, height, width]\n",
    "        out = self.conv3(out) # [batch_size, out_channels*mul, height, width]\n",
    "        out = self.bn3(out) # [batch_size, out_channels*mul, height, width]\n",
    "        # skip connection\n",
    "        out += self.shortcut(x) # [batch_size, out_channels*mul, height, width] or [batch_size, out_channels*mul*mul, height, width]\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, block_mul, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        #RGB 3개채널에서 64개의 Kernel 사용\n",
    "        self.in_channels = 64\n",
    "\n",
    "        # Resnet 논문 구조 그대로 구현\n",
    "        self.conv1 = torch.nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding = 3)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(self.in_channels)\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self.make_layer(block_mul, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self.make_layer(block_mul, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self.make_layer(block_mul, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self.make_layer(block_mul, 512, num_blocks[3], stride=2)\n",
    "        # Global Average Pooling 레이어 => 1차원 벡터로 만들기 위함\n",
    "        # Global average pooling 참고자료: https://gaussian37.github.io/dl-concept-global_average_pooling/\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = torch.nn.Linear(512 * block_mul, num_classes)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    def make_layer(self, block_mul, out_channels, num_blocks, stride):\n",
    "        # layer 앞부분에서만 크기를 절반으로 줄이므로, 아래와 같은 구조\n",
    "        '''\n",
    "        ex) stride = 2이고 num_blocks = 3인 경우, strides는 [2, 1, 1]로 생성되며,\n",
    "        Bottleneck 블록들이 stride=2로 시작하여 앞부분에서 크기를 절반으로 줄이고, 나머지 블록들은 크기를 그대로 유지\n",
    "        '''\n",
    "        strides = [stride] + [1] * (num_blocks-1) # BottleNeck block의 stride 리스트 설정\n",
    "        layers = []\n",
    "        for i in range(num_blocks):\n",
    "            layers.append(BottleNeck(self.in_channels, out_channels, strides[i], block_mul))\n",
    "            self.in_channels = block_mul * out_channels\n",
    "        return torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        INPUT :\n",
    "            x = [batch_size, channel, height, width]\n",
    "        OUTPUT :\n",
    "            output = [batch_size, num_classes]\n",
    "        '''\n",
    "        out = self.conv1(x) # [batch_size, 64, height//2, width//2]\n",
    "        out = self.bn1(out) # [batch_size, 64, height//2, width//2]\n",
    "        out = F.relu(out) # [batch_size, 64, height//2, width//2]\n",
    "        out = self.maxpool1(out) # [batch_size, 64, height//4, width//4]\n",
    "        out = self.layer1(out) # [batch_size, 256, height//4, width//4]\n",
    "        out = self.layer2(out) # [batch_size, 512, height//8, width//8]\n",
    "        out = self.layer3(out) # [batch_size, 1024, height//16, width//16]\n",
    "        out = self.layer4(out) # [batch_size, 2048, height//32, width//32]\n",
    "        out = self.avgpool(out) # [batch_size, 2048, height//32, width//32]\n",
    "        out = torch.flatten(out, 1) # [batch_size, 2048, 1, 1]\n",
    "        out = self.linear(out) # [batch_size, 2048]\n",
    "        out = self.softmax(out) # [batch_size, num_classes]\n",
    "        return out\n",
    "\n",
    "    def count_parameters(self):\n",
    "            return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(4, [3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 total parameters:  23528586\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50()\n",
    "print(\"ResNet50 total parameters: \", model.count_parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
