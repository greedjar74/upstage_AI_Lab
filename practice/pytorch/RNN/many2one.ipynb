{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many to One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(torch.nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super().__init__()\n",
    "        self.I = n_input\n",
    "        self.H = n_hidden\n",
    "        self.O = n_output\n",
    "\n",
    "        self.rnn = torch.nn.RNN(input_size=self.I,\n",
    "                                hidden_size=self.H,\n",
    "                                nonlinearity='tanh',\n",
    "                                batch_first=True)\n",
    "        \n",
    "        self.fc = torch.nn.Linear(self.H, self.O)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.H).to(device)\n",
    "\n",
    "        out, h_0 = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out\n",
    "    \n",
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super().__init__()\n",
    "        self.I = n_input\n",
    "        self.H = n_hidden\n",
    "        self.O = n_output\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(input_size=self.I,\n",
    "                                 hidden_size=self.H,\n",
    "                                 batch_first=True)\n",
    "        \n",
    "        self.fc = torch.nn.Linear(self.H, self.O)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.H).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.H).to(device)\n",
    "\n",
    "        out, (h_0, c_0) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out\n",
    "    \n",
    "class GRU(torch.nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super().__init__()\n",
    "        self.I = n_input\n",
    "        self.H = n_hidden\n",
    "        self.O = n_output\n",
    "\n",
    "        self.gru = torch.nn.GRU(input_size=self.I,\n",
    "                                hidden_size=self.H,\n",
    "                                batch_first=True)\n",
    "        \n",
    "        self.fc = torch.nn.Linear(self.H, self.O)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.H).to(device)\n",
    "\n",
    "        out, h_0= self.gru(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = SimpleRNN(n_input=1, n_hidden=40, n_output=1).to(device)\n",
    "lstm_model = LSTM(n_input=1, n_hidden=40, n_output=1).to(device)\n",
    "gru_model = GRU(n_input=1, n_hidden=40, n_output=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(1, 15, size=(50000, 6, 1)) # 입력 데이터 생성, 1~14 사이의 정수 50000개를 랜덤하게 생성\n",
    "Y = np.array([np.sum(x) for x in X]) # 타겟 데이터 생성, 모든 입력 데이터의 총합이 타겟\n",
    "\n",
    "X = torch.from_numpy(X.astype(np.float32)).to(device) # 입력 데이터를 텐서로 변환\n",
    "Y = torch.from_numpy(Y.astype(np.float32)).to(device) # 타겟 데이터를 텐서로 변환\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "rnn_optimizer = torch.optim.Adam(rnn_model.parameters())\n",
    "lstm_optimizer = torch.optim.Adam(lstm_model.parameters())\n",
    "gru_optimizer = torch.optim.Adam(gru_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/4000], Loss: 1588.6315\n",
      "Epoch [200/4000], Loss: 1279.7161\n",
      "Epoch [300/4000], Loss: 1031.8058\n",
      "Epoch [400/4000], Loss: 828.5258\n",
      "Epoch [500/4000], Loss: 662.2735\n",
      "Epoch [600/4000], Loss: 527.5439\n",
      "Epoch [700/4000], Loss: 419.7122\n",
      "Epoch [800/4000], Loss: 334.6778\n",
      "Epoch [900/4000], Loss: 268.7424\n",
      "Epoch [1000/4000], Loss: 218.5683\n",
      "Epoch [1100/4000], Loss: 181.1699\n",
      "Epoch [1200/4000], Loss: 153.9168\n",
      "Epoch [1300/4000], Loss: 134.5372\n",
      "Epoch [1400/4000], Loss: 121.1149\n",
      "Epoch [1500/4000], Loss: 112.0772\n",
      "Epoch [1600/4000], Loss: 106.1717\n",
      "Epoch [1700/4000], Loss: 102.4336\n",
      "Epoch [1800/4000], Loss: 100.1453\n",
      "Epoch [1900/4000], Loss: 98.7928\n",
      "Epoch [2000/4000], Loss: 98.0217\n",
      "Epoch [2100/4000], Loss: 97.5979\n",
      "Epoch [2200/4000], Loss: 97.3722\n",
      "Epoch [2300/4000], Loss: 97.2523\n",
      "Epoch [2400/4000], Loss: 97.0127\n",
      "Epoch [2500/4000], Loss: 87.2679\n",
      "Epoch [2600/4000], Loss: 59.3742\n",
      "Epoch [2700/4000], Loss: 36.2427\n",
      "Epoch [2800/4000], Loss: 28.0536\n",
      "Epoch [2900/4000], Loss: 21.9977\n",
      "Epoch [3000/4000], Loss: 17.7769\n",
      "Epoch [3100/4000], Loss: 14.6933\n",
      "Epoch [3200/4000], Loss: 12.3046\n",
      "Epoch [3300/4000], Loss: 10.4113\n",
      "Epoch [3400/4000], Loss: 8.8848\n",
      "Epoch [3500/4000], Loss: 7.6484\n",
      "Epoch [3600/4000], Loss: 6.6237\n",
      "Epoch [3700/4000], Loss: 5.7775\n",
      "Epoch [3800/4000], Loss: 5.0668\n",
      "Epoch [3900/4000], Loss: 4.4748\n",
      "Epoch [4000/4000], Loss: 3.9528\n",
      "-------------------- 추론 결과 --------------------\n",
      "Input: [2.0, 4.0, 6.0, 8.0, 10.0, 11.0]\n",
      "Output: 40.7, 정답: 41.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4000):\n",
    "    outputs = rnn_model(X)\n",
    "    loss = criterion(outputs.squeeze(), Y)\n",
    "\n",
    "    rnn_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    rnn_optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0: # 100회마다 손실 출력\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 4000, loss.item()))\n",
    "\n",
    "# Inference\n",
    "X_test = torch.tensor([[[2.0], [4.0], [6.0], [8.0], [10.0], [11.0]]], dtype=torch.float32).to(device)\n",
    "print('-' * 20, '추론 결과', '-' * 20)\n",
    "print(f\"Input: {X_test.squeeze().tolist()}\")\n",
    "output = round(rnn_model(X_test).item(), 1)\n",
    "answer = round(sum(X_test.squeeze().tolist()), 1)\n",
    "\n",
    "print(f\"Output: {output}, 정답: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
