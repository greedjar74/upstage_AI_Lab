{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV_M3nx_3b8R"
   },
   "source": [
    "# **<font color=white> 16.XGBoost Code 실습**\n",
    "\n",
    "[목적]\n",
    "  - GBM Model을 획기적인 System Design을 활용하여 개선한 XGBoost Model 실습 및 해석\n",
    "  - XGBoost의 경우 Missing Value를 Model 자체 내에서 처리해주기 때문에 삭제하지 않아도 됨\n",
    "  - Big Data를 빠르게 학습함\n",
    "\n",
    "[Process]\n",
    "  1. Define X's & Y\n",
    "  2. Split Train & Valid dataset\n",
    "  3. Modeling\n",
    "  4. Model 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2604,
     "status": "ok",
     "timestamp": 1677301944239,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "CV3nB_-Z3-Wm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1677301944240,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "L1DRYMD94N6U"
   },
   "outputs": [],
   "source": [
    "# Data Loading (수술 時 사망 데이터)\n",
    "data=pd.read_csv(\"https://raw.githubusercontent.com/GonieAhn/Data-Science-online-course-from-gonie/main/Data%20Store/example_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677301951073,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "jXDJeDSD4PPw",
    "outputId": "5a93da45-301d-4fc2-8d5a-2685f84c663c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>censor</th>\n",
       "      <th>event</th>\n",
       "      <th>age</th>\n",
       "      <th>wtkg</th>\n",
       "      <th>hemo</th>\n",
       "      <th>homo</th>\n",
       "      <th>drugs</th>\n",
       "      <th>karnof</th>\n",
       "      <th>oprior</th>\n",
       "      <th>z30</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>str2</th>\n",
       "      <th>strat</th>\n",
       "      <th>symptom</th>\n",
       "      <th>cd40</th>\n",
       "      <th>cd420</th>\n",
       "      <th>cd496</th>\n",
       "      <th>r</th>\n",
       "      <th>cd80</th>\n",
       "      <th>cd820</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>532.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.340226</td>\n",
       "      <td>801.236842</td>\n",
       "      <td>35.225564</td>\n",
       "      <td>76.061855</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.640977</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>95.432331</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.546992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.580827</td>\n",
       "      <td>1.981203</td>\n",
       "      <td>0.167293</td>\n",
       "      <td>353.204887</td>\n",
       "      <td>336.139098</td>\n",
       "      <td>173.146617</td>\n",
       "      <td>0.603383</td>\n",
       "      <td>987.250000</td>\n",
       "      <td>928.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474231</td>\n",
       "      <td>326.887929</td>\n",
       "      <td>8.852094</td>\n",
       "      <td>13.224698</td>\n",
       "      <td>0.269910</td>\n",
       "      <td>0.480165</td>\n",
       "      <td>0.323410</td>\n",
       "      <td>5.981856</td>\n",
       "      <td>0.170955</td>\n",
       "      <td>0.498255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391056</td>\n",
       "      <td>0.493888</td>\n",
       "      <td>0.905946</td>\n",
       "      <td>0.373589</td>\n",
       "      <td>114.105253</td>\n",
       "      <td>130.961573</td>\n",
       "      <td>191.455406</td>\n",
       "      <td>0.489656</td>\n",
       "      <td>475.223907</td>\n",
       "      <td>438.569798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>47.401000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>535.750000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>243.750000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>653.250000</td>\n",
       "      <td>626.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>933.500000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>74.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>330.500000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>881.000000</td>\n",
       "      <td>818.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1081.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>83.502000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1231.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>771.000000</td>\n",
       "      <td>909.000000</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4255.000000</td>\n",
       "      <td>3130.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           censor        event         age        wtkg        hemo  \\\n",
       "count  532.000000   532.000000  532.000000  532.000000  532.000000   \n",
       "mean     0.340226   801.236842   35.225564   76.061855    0.078947   \n",
       "std      0.474231   326.887929    8.852094   13.224698    0.269910   \n",
       "min      0.000000    33.000000   13.000000   47.401000    0.000000   \n",
       "25%      0.000000   535.750000   29.000000   67.500000    0.000000   \n",
       "50%      0.000000   933.500000   34.000000   74.600000    0.000000   \n",
       "75%      1.000000  1081.000000   40.000000   83.502000    0.000000   \n",
       "max      1.000000  1231.000000   70.000000  149.000000    1.000000   \n",
       "\n",
       "             homo       drugs      karnof      oprior         z30  ...  \\\n",
       "count  532.000000  532.000000  532.000000  532.000000  532.000000  ...   \n",
       "mean     0.640977    0.118421   95.432331    0.030075    0.546992  ...   \n",
       "std      0.480165    0.323410    5.981856    0.170955    0.498255  ...   \n",
       "min      0.000000    0.000000   70.000000    0.000000    0.000000  ...   \n",
       "25%      0.000000    0.000000   90.000000    0.000000    0.000000  ...   \n",
       "50%      1.000000    0.000000  100.000000    0.000000    1.000000  ...   \n",
       "75%      1.000000    0.000000  100.000000    0.000000    1.000000  ...   \n",
       "max      1.000000    1.000000  100.000000    1.000000    1.000000  ...   \n",
       "\n",
       "           gender        str2       strat     symptom        cd40       cd420  \\\n",
       "count  532.000000  532.000000  532.000000  532.000000  532.000000  532.000000   \n",
       "mean     0.812030    0.580827    1.981203    0.167293  353.204887  336.139098   \n",
       "std      0.391056    0.493888    0.905946    0.373589  114.105253  130.961573   \n",
       "min      0.000000    0.000000    1.000000    0.000000  103.000000   49.000000   \n",
       "25%      1.000000    0.000000    1.000000    0.000000  271.000000  243.750000   \n",
       "50%      1.000000    1.000000    2.000000    0.000000  346.000000  330.500000   \n",
       "75%      1.000000    1.000000    3.000000    0.000000  422.000000  418.000000   \n",
       "max      1.000000    1.000000    3.000000    1.000000  771.000000  909.000000   \n",
       "\n",
       "            cd496           r         cd80        cd820  \n",
       "count  532.000000  532.000000   532.000000   532.000000  \n",
       "mean   173.146617    0.603383   987.250000   928.214286  \n",
       "std    191.455406    0.489656   475.223907   438.569798  \n",
       "min     -1.000000    0.000000   221.000000   150.000000  \n",
       "25%     -1.000000    0.000000   653.250000   626.500000  \n",
       "50%    113.000000    1.000000   881.000000   818.000000  \n",
       "75%    324.000000    1.000000  1190.000000  1164.000000  \n",
       "max    857.000000    1.000000  4255.000000  3130.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fS03dCWY4LPd"
   },
   "source": [
    "[Data Condition Check]\n",
    "\n",
    "XGBoost Package의 경우 변수 Name 중 특수 문자가 들어가면 오류가 나게 되어 있음\n",
    "따라서 변수이름들을 모두 전처리 해줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1677301993949,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "6BwHmQ-e4J2N"
   },
   "outputs": [],
   "source": [
    "# Feature Name Cleaning\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in data.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677302171863,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "663J2lmm_0MK",
    "outputId": "751c54ba-5eed-420d-8c22-4c1470086588"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [1, 1, 1]\n",
    "set(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1677302223870,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "k-boV-i94gXT",
    "outputId": "1d14389e-d8e2-4bbf-8700-a1929db3bd70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Data Shape : (532, 22)\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Checking\n",
    "col = []\n",
    "missing = []\n",
    "level = [] \n",
    "for name in data.columns:\n",
    "    \n",
    "    # Missing\n",
    "    missper = data[name].isnull().sum() / data.shape[0]\n",
    "    missing.append(round(missper, 4))\n",
    "\n",
    "    # Leveling\n",
    "    lel = data[name].dropna()\n",
    "    level.append(len(list(set(lel))))\n",
    "\n",
    "    # Columns\n",
    "    col.append(name)\n",
    "\n",
    "summary = pd.concat([pd.DataFrame(col, columns=['name']), \n",
    "                     pd.DataFrame(missing, columns=['Missing Percentage']), \n",
    "                     pd.DataFrame(level, columns=['Level'])], axis=1)\n",
    "\n",
    "drop_col = summary['name'][(summary['Level'] <= 1) | (summary['Missing Percentage'] >= 0.8)]\n",
    "data.drop(columns=drop_col, inplace=True)\n",
    "print(\">>>> Data Shape : {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1677302229324,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "7FiDUO1z4na_",
    "outputId": "48f305ba-43dc-421f-f2a0-0188ab0260a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    zprior\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677065466803,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "jApmK82y4xz1",
    "outputId": "9579d215-5e07-4826-aeb0-077feab8c8ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Missing Percentage</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>censor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>event</td>\n",
       "      <td>0.0</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wtkg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hemo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>homo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>drugs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>karnof</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oprior</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>z30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zprior</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>preanti</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>race</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>str2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>strat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>symptom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cd40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cd420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cd496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cd80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cd820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  Missing Percentage  Level\n",
       "0    censor                 0.0      2\n",
       "1     event                 0.0    358\n",
       "2       age                 0.0     52\n",
       "3      wtkg                 0.0    312\n",
       "4      hemo                 0.0      2\n",
       "5      homo                 0.0      2\n",
       "6     drugs                 0.0      2\n",
       "7    karnof                 0.0      4\n",
       "8    oprior                 0.0      2\n",
       "9       z30                 0.0      2\n",
       "10   zprior                 0.0      1\n",
       "11  preanti                 0.0    273\n",
       "12     race                 0.0      2\n",
       "13   gender                 0.0      2\n",
       "14     str2                 0.0      2\n",
       "15    strat                 0.0      3\n",
       "16  symptom                 0.0      2\n",
       "17     cd40                 0.0    278\n",
       "18    cd420                 0.0    314\n",
       "19    cd496                 0.0    231\n",
       "20        r                 0.0      2\n",
       "21     cd80                 0.0    416\n",
       "22    cd820                 0.0    423"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1677302277144,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "-N1EjmMeAY_w",
    "outputId": "4d265a70-3c3b-4ece-b89a-1ad2d0951907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532, 22)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1677302283728,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "TdH-w_ql5DF3"
   },
   "outputs": [],
   "source": [
    "# X's & Y Split\n",
    "Y = data['censor']\n",
    "X = data.drop(columns=['censor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1677302288038,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "b2bx0VQQ5JoK",
    "outputId": "a73a5587-2321-43cc-ef6d-66d18036ccbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> # of Train data : 372\n",
      ">>>> # of valid data : 160\n",
      ">>>> # of Train data Y : Counter({0: 241, 1: 131})\n",
      ">>>> # of valid data Y : Counter({0: 110, 1: 50})\n"
     ]
    }
   ],
   "source": [
    "idx = list(range(X.shape[0]))\n",
    "train_idx, valid_idx = train_test_split(idx, test_size=0.3, random_state=2021)\n",
    "print(\">>>> # of Train data : {}\".format(len(train_idx)))\n",
    "print(\">>>> # of valid data : {}\".format(len(valid_idx)))\n",
    "print(\">>>> # of Train data Y : {}\".format(Counter(Y.iloc[train_idx])))\n",
    "print(\">>>> # of valid data Y : {}\".format(Counter(Y.iloc[valid_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DClZBr495NpI"
   },
   "source": [
    "[XGBoost Parameters]\n",
    "  - Package : https://xgboost.readthedocs.io/en/stable/\n",
    "  - booster : Iteration 마다의 Model Run Type을 고를수 있음 (2가지)\n",
    "    - gbtree : tree-based models\n",
    "    - gblinear : linear models\n",
    "  - silent : 학습하면서 running message를 프린트해줌 (Parameter 실험 시 안좋음)\n",
    "    - 0은 프린트 안해주고, 1은 프린트해줌\n",
    "  - nthread : 병렬처리 할때 core를 몇개 잡을 것인지\n",
    "    - default로 잡을 수 있는 모든 core를 잡을 수 있도록 해줌\n",
    "  - learning_rate : GBM에서 shrinking 하는 것과 같은 것\n",
    "  - reg_lambda : L2 regularization term on weights (analogous to Ridge regression)\n",
    "  - reg_alpha : L1 regularization term on weight (analogous to Lasso regression)\n",
    "  - objective [default=reg:linear]\n",
    "     - This defines the loss function to be minimized. Mostly used values are:\n",
    "         - binary:logistic –logistic regression for binary classification, returns predicted probability (not class)\n",
    "         - multi:softmax –multiclass classification using the softmax objective, returns predicted class (not probabilities)\n",
    "you also need to set an additional num_class (number of classes) parameter defining the number of unique classes\n",
    "         - multi:softprob –same as softmax, but returns predicted probability of each data point belonging to each class.\n",
    "  - eval_metric [ default according to objective ]\n",
    "    - The metric to be used for validation data.\n",
    "    - The default values are rmse for regression and error for classification.\n",
    "    - Typical values are:\n",
    "        -    rmse – root mean square error\n",
    "        -    mae – mean absolute error\n",
    "        -    logloss – negative log-likelihood\n",
    "        -    error – Binary classification error rate (0.5 threshold)\n",
    "        -    merror – Multiclass classification error rate\n",
    "        -    mlogloss – Multiclass logloss\n",
    "        -    auc: Area under the curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9Rz2V-38kha"
   },
   "source": [
    "[XGBoost]\n",
    "\n",
    "  - Hyperparameter tuning\n",
    "  - n_estimators, learning_rate, max_depth, reg_alpha\n",
    "  - XGBoost은 Hyperparam이 굉장히 많은 알고리즘 중에 하나임\n",
    "  - 위에 4가지만 잘 조정해도 좋은 결과를 얻을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1957,
     "status": "ok",
     "timestamp": 1677302980673,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "TvZHL6A55K9j",
    "outputId": "e1519ff5-bb01-409c-fba4-9d3012d82319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 0 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[238   3]\n",
      " [ 60  71]]\n",
      "Train Acc : 0.8306451612903226\n",
      "Train F1-Score : 0.6926829268292682\n",
      "Test Confusion Matrix\n",
      "[[105   5]\n",
      " [ 19  31]]\n",
      "TesT Acc : 0.85\n",
      "Test F1-Score : 0.7209302325581396\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 1 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[238   3]\n",
      " [ 60  71]]\n",
      "Train Acc : 0.8306451612903226\n",
      "Train F1-Score : 0.6926829268292682\n",
      "Test Confusion Matrix\n",
      "[[105   5]\n",
      " [ 19  31]]\n",
      "TesT Acc : 0.85\n",
      "Test F1-Score : 0.7209302325581396\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 2 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[238   3]\n",
      " [ 60  71]]\n",
      "Train Acc : 0.8306451612903226\n",
      "Train F1-Score : 0.6926829268292682\n",
      "Test Confusion Matrix\n",
      "[[105   5]\n",
      " [ 19  31]]\n",
      "TesT Acc : 0.85\n",
      "Test F1-Score : 0.7209302325581396\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 3 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[240   1]\n",
      " [ 39  92]]\n",
      "Train Acc : 0.8924731182795699\n",
      "Train F1-Score : 0.8214285714285715\n",
      "Test Confusion Matrix\n",
      "[[102   8]\n",
      " [ 19  31]]\n",
      "TesT Acc : 0.83125\n",
      "Test F1-Score : 0.6966292134831461\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 4 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[240   1]\n",
      " [ 39  92]]\n",
      "Train Acc : 0.8924731182795699\n",
      "Train F1-Score : 0.8214285714285715\n",
      "Test Confusion Matrix\n",
      "[[102   8]\n",
      " [ 18  32]]\n",
      "TesT Acc : 0.8375\n",
      "Test F1-Score : 0.7111111111111111\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 5 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[239   2]\n",
      " [ 43  88]]\n",
      "Train Acc : 0.8790322580645161\n",
      "Train F1-Score : 0.7963800904977376\n",
      "Test Confusion Matrix\n",
      "[[103   7]\n",
      " [ 17  33]]\n",
      "TesT Acc : 0.85\n",
      "Test F1-Score : 0.7333333333333334\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 6 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[226  15]\n",
      " [ 15 116]]\n",
      "Train Acc : 0.9193548387096774\n",
      "Train F1-Score : 0.8854961832061069\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8275862068965517\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 7 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[226  15]\n",
      " [ 15 116]]\n",
      "Train Acc : 0.9193548387096774\n",
      "Train F1-Score : 0.8854961832061069\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8275862068965517\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 8 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[226  15]\n",
      " [ 19 112]]\n",
      "Train Acc : 0.9086021505376344\n",
      "Train F1-Score : 0.868217054263566\n",
      "Test Confusion Matrix\n",
      "[[91 19]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.8625\n",
      "Test F1-Score : 0.810344827586207\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 9 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[234   7]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9543010752688172\n",
      "Train F1-Score : 0.9343629343629344\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 5 45]]\n",
      "TesT Acc : 0.8625\n",
      "Test F1-Score : 0.8035714285714286\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 10 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[234   7]\n",
      " [ 11 120]]\n",
      "Train Acc : 0.9516129032258065\n",
      "Train F1-Score : 0.9302325581395349\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.86875\n",
      "Test F1-Score : 0.8141592920353983\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 11 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[236   5]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9596774193548387\n",
      "Train F1-Score : 0.9416342412451363\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8214285714285714\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 12 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[234   7]\n",
      " [ 34  97]]\n",
      "Train Acc : 0.8897849462365591\n",
      "Train F1-Score : 0.8255319148936171\n",
      "Test Confusion Matrix\n",
      "[[100  10]\n",
      " [  7  43]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8349514563106797\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 13 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[233   8]\n",
      " [ 32  99]]\n",
      "Train Acc : 0.8924731182795699\n",
      "Train F1-Score : 0.8319327731092436\n",
      "Test Confusion Matrix\n",
      "[[99 11]\n",
      " [ 8 42]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8155339805825242\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 14 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[233   8]\n",
      " [ 32  99]]\n",
      "Train Acc : 0.8924731182795699\n",
      "Train F1-Score : 0.8319327731092436\n",
      "Test Confusion Matrix\n",
      "[[99 11]\n",
      " [ 7 43]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.826923076923077\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 15 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[238   3]\n",
      " [ 19 112]]\n",
      "Train Acc : 0.9408602150537635\n",
      "Train F1-Score : 0.9105691056910569\n",
      "Test Confusion Matrix\n",
      "[[97 13]\n",
      " [10 40]]\n",
      "TesT Acc : 0.85625\n",
      "Test F1-Score : 0.7766990291262137\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 16 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[238   3]\n",
      " [ 19 112]]\n",
      "Train Acc : 0.9408602150537635\n",
      "Train F1-Score : 0.9105691056910569\n",
      "Test Confusion Matrix\n",
      "[[97 13]\n",
      " [ 7 43]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8113207547169812\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 17 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [ 20 111]]\n",
      "Train Acc : 0.9354838709677419\n",
      "Train F1-Score : 0.9024390243902439\n",
      "Test Confusion Matrix\n",
      "[[98 12]\n",
      " [ 9 41]]\n",
      "TesT Acc : 0.86875\n",
      "Test F1-Score : 0.796116504854369\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 18 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[232   9]\n",
      " [  9 122]]\n",
      "Train Acc : 0.9516129032258065\n",
      "Train F1-Score : 0.931297709923664\n",
      "Test Confusion Matrix\n",
      "[[91 19]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8305084745762712\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 19 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[231  10]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9408602150537635\n",
      "Train F1-Score : 0.9153846153846152\n",
      "Test Confusion Matrix\n",
      "[[91 19]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8305084745762712\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 20 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[225  16]\n",
      " [ 11 120]]\n",
      "Train Acc : 0.9274193548387096\n",
      "Train F1-Score : 0.898876404494382\n",
      "Test Confusion Matrix\n",
      "[[90 20]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.86875\n",
      "Test F1-Score : 0.823529411764706\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 21 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [  4 127]]\n",
      "Train Acc : 0.978494623655914\n",
      "Train F1-Score : 0.9694656488549618\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 5 45]]\n",
      "TesT Acc : 0.86875\n",
      "Test F1-Score : 0.8108108108108109\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 22 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [  5 126]]\n",
      "Train Acc : 0.9758064516129032\n",
      "Train F1-Score : 0.9655172413793103\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 5 45]]\n",
      "TesT Acc : 0.86875\n",
      "Test F1-Score : 0.8108108108108109\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 23 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[238   3]\n",
      " [  5 126]]\n",
      "Train Acc : 0.978494623655914\n",
      "Train F1-Score : 0.9692307692307692\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8275862068965517\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 24 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[227  14]\n",
      " [ 11 120]]\n",
      "Train Acc : 0.9327956989247311\n",
      "Train F1-Score : 0.9056603773584906\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8521739130434782\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 25 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[227  14]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9301075268817204\n",
      "Train F1-Score : 0.9015151515151515\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8448275862068965\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 26 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[227  14]\n",
      " [ 15 116]]\n",
      "Train Acc : 0.9220430107526881\n",
      "Train F1-Score : 0.888888888888889\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8448275862068965\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 27 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[238   3]\n",
      " [  9 122]]\n",
      "Train Acc : 0.967741935483871\n",
      "Train F1-Score : 0.953125\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8288288288288288\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 28 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[238   3]\n",
      " [  8 123]]\n",
      "Train Acc : 0.9704301075268817\n",
      "Train F1-Score : 0.9571984435797665\n",
      "Test Confusion Matrix\n",
      "[[96 14]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8468468468468469\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 29 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [  8 123]]\n",
      "Train Acc : 0.967741935483871\n",
      "Train F1-Score : 0.9534883720930233\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8288288288288288\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 30 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[235   6]\n",
      " [  3 128]]\n",
      "Train Acc : 0.9758064516129032\n",
      "Train F1-Score : 0.9660377358490565\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8448275862068965\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 31 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[234   7]\n",
      " [  5 126]]\n",
      "Train Acc : 0.967741935483871\n",
      "Train F1-Score : 0.9545454545454546\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.8625\n",
      "Test F1-Score : 0.8070175438596492\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 32 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[233   8]\n",
      " [  5 126]]\n",
      "Train Acc : 0.9650537634408602\n",
      "Train F1-Score : 0.9509433962264152\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8376068376068375\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 33 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[241   0]\n",
      " [  0 131]]\n",
      "Train Acc : 1.0\n",
      "Train F1-Score : 1.0\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.86875\n",
      "Test F1-Score : 0.8141592920353983\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 34 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[240   1]\n",
      " [  0 131]]\n",
      "Train Acc : 0.9973118279569892\n",
      "Train F1-Score : 0.9961977186311787\n",
      "Test Confusion Matrix\n",
      "[[91 19]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.85625\n",
      "Test F1-Score : 0.8\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 35 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[240   1]\n",
      " [  0 131]]\n",
      "Train Acc : 0.9973118279569892\n",
      "Train F1-Score : 0.9961977186311787\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8275862068965517\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# n_estimators\n",
    "n_tree = [5, 10, 20]\n",
    "# learning_rate\n",
    "l_rate = [0.1, 0.3]\n",
    "# max_depth\n",
    "m_depth = [3, 5]\n",
    "# reg_alpha\n",
    "L1_norm = [0.1, 0.3, 0.5]\n",
    "\n",
    "# Modeling\n",
    "save_n = []\n",
    "save_l = []\n",
    "save_m = []\n",
    "save_L1 = []\n",
    "f1_score_ = []\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for n in n_tree:\n",
    "    for l in l_rate:\n",
    "        for m in m_depth:\n",
    "            for L1 in L1_norm:\n",
    "                \n",
    "                print(\">>> {} <<<\".format(cnt))\n",
    "                cnt +=1\n",
    "                print(\"n_estimators : {}, learning_rate : {}, max_depth : {}, reg_alpha : {}\".format(n, l, m, L1))\n",
    "                model = XGBClassifier(n_estimators=n, learning_rate=l, \n",
    "                                      max_depth=m, reg_alpha=L1, objective='binary:logistic', random_state=119)\n",
    "                model.fit(X.iloc[train_idx], Y.iloc[train_idx])\n",
    "                \n",
    "                \n",
    "                # Train Acc\n",
    "                y_pre_train = model.predict(X.iloc[train_idx])\n",
    "                cm_train = confusion_matrix(Y.iloc[train_idx], y_pre_train)\n",
    "                print(\"Train Confusion Matrix\")\n",
    "                print(cm_train)\n",
    "                print(\"Train Acc : {}\".format((cm_train[0,0] + cm_train[1,1])/cm_train.sum()))\n",
    "                print(\"Train F1-Score : {}\".format(f1_score(Y.iloc[train_idx], y_pre_train)))\n",
    "\n",
    "                # Test Acc\n",
    "                y_pre_test = model.predict(X.iloc[valid_idx])\n",
    "                cm_test = confusion_matrix(Y.iloc[valid_idx], y_pre_test)\n",
    "                print(\"Test Confusion Matrix\")\n",
    "                print(cm_test)\n",
    "                print(\"TesT Acc : {}\".format((cm_test[0,0] + cm_test[1,1])/cm_test.sum()))\n",
    "                print(\"Test F1-Score : {}\".format(f1_score(Y.iloc[valid_idx], y_pre_test)))\n",
    "                print(\"-----------------------------------------------------------------------\")\n",
    "                print(\"-----------------------------------------------------------------------\")\n",
    "                save_n.append(n)\n",
    "                save_l.append(l)\n",
    "                save_m.append(m)\n",
    "                save_L1.append(L1)\n",
    "                f1_score_.append(f1_score(Y.iloc[valid_idx], y_pre_test))\n",
    "                \n",
    "                # Model 저장\n",
    "                #import joblib\n",
    "                #joblib.dump(model, './XGBoost_model/Result_{}_{}_{}_{}_{}.pkl'.format(n, l, m, L1, round(f1_score_[-1], 4)))\n",
    "                #gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1677303149229,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "Q619anmB9J8N",
    "outputId": "3f100f54-9a11-4eed-a323-ff4affd777eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 24 <<<\n",
      "Best Test f1-score : 0.8521739130434782\n",
      "Best n_estimators : 20\n",
      "Best Learning Rate : 0.1\n",
      "Best Max_depth : 3\n",
      "Best L1-norm : 0.1\n"
     ]
    }
   ],
   "source": [
    "print(\">>> {} <<<\\nBest Test f1-score : {}\\nBest n_estimators : {}\\nBest Learning Rate : {}\\nBest Max_depth : {}\\nBest L1-norm : {}\".format(np.argmax(f1_score_),\n",
    "                                                                                                                                            f1_score_[np.argmax(f1_score_)], \n",
    "                                                                                                                                            save_n[np.argmax(f1_score_)],\n",
    "                                                                                                                                            save_l[np.argmax(f1_score_)],\n",
    "                                                                                                                                            save_m[np.argmax(f1_score_)],\n",
    "                                                                                                                                            save_L1[np.argmax(f1_score_)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1677303163175,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "E2GPrsz_-fwb",
    "outputId": "685ecec1-b4c3-4a83-c987-53c175308642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix\n",
      "[[227  14]\n",
      " [ 11 120]]\n",
      "Train Acc : 0.9327956989247311\n",
      "Train F1-Score : 0.9056603773584906\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8521739130434782\n"
     ]
    }
   ],
   "source": [
    "best_model = XGBClassifier(n_estimators=save_n[np.argmax(f1_score_)], learning_rate=save_l[np.argmax(f1_score_)], \n",
    "                           max_depth=save_m[np.argmax(f1_score_)], reg_alpha=save_L1[np.argmax(f1_score_)], objective='binary:logistic', \n",
    "                           random_state=119)\n",
    "best_model.fit(X.iloc[train_idx], Y.iloc[train_idx])\n",
    "\n",
    "# Train Acc\n",
    "y_pre_train = best_model.predict(X.iloc[train_idx])\n",
    "cm_train = confusion_matrix(Y.iloc[train_idx], y_pre_train)\n",
    "print(\"Train Confusion Matrix\")\n",
    "print(cm_train)\n",
    "print(\"Train Acc : {}\".format((cm_train[0,0] + cm_train[1,1])/cm_train.sum()))\n",
    "print(\"Train F1-Score : {}\".format(f1_score(Y.iloc[train_idx], y_pre_train)))\n",
    "\n",
    "# Test Acc\n",
    "y_pre_test = best_model.predict(X.iloc[valid_idx])\n",
    "cm_test = confusion_matrix(Y.iloc[valid_idx], y_pre_test)\n",
    "print(\"Test Confusion Matrix\")\n",
    "print(cm_test)\n",
    "print(\"TesT Acc : {}\".format((cm_test[0,0] + cm_test[1,1])/cm_test.sum()))\n",
    "print(\"Test F1-Score : {}\".format(f1_score(Y.iloc[valid_idx], y_pre_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1677303185397,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "A4PN7P53_OaG",
    "outputId": "6008eb09-570b-4fee-a901-546ef7a3d10a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Score  Feature\n",
      "0   0.384801    event\n",
      "1   0.115327    cd496\n",
      "2   0.089598  preanti\n",
      "3   0.089240    cd420\n",
      "4   0.078008     race\n",
      "5   0.055997    cd820\n",
      "6   0.048826     wtkg\n",
      "7   0.032533      z30\n",
      "8   0.027505     cd80\n",
      "9   0.027451   karnof\n",
      "10  0.026762     cd40\n",
      "11  0.023951      age\n",
      "12  0.000000  symptom\n",
      "13  0.000000    strat\n",
      "14  0.000000     str2\n",
      "15  0.000000        r\n",
      "16  0.000000   oprior\n",
      "17  0.000000     homo\n",
      "18  0.000000     hemo\n",
      "19  0.000000   gender\n",
      "20  0.000000    drugs\n"
     ]
    }
   ],
   "source": [
    "feature_map = pd.DataFrame(sorted(zip(best_model.feature_importances_, X.columns), reverse=True), columns=['Score', 'Feature'])\n",
    "print(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "executionInfo": {
     "elapsed": 1161,
     "status": "ok",
     "timestamp": 1677303194083,
     "user": {
      "displayName": "안건이",
      "userId": "00323974519415085515"
     },
     "user_tz": -540
    },
    "id": "IUnGD5Y8_QXl",
    "outputId": "c19158f0-804a-4045-d269-8e287b26a2bb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importance Score Top 10\n",
    "feature_map_10 = feature_map.iloc[:10]\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Score\", y=\"Feature\", data=feature_map_10.sort_values(by=\"Score\", ascending=False), errwidth=40)\n",
    "plt.title('XGBoost Importance Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPnl/10QvOZnSVBK7EL/h7D",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
