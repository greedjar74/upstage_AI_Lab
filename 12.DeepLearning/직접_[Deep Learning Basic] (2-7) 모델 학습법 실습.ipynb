{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import random\n",
    "import platform\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 scailing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_images/255.\n",
    "test_X = test_images/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2abcf8450>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _onehot(labels):\n",
    "    onehot = np.zeros((len(labels), len(labels)), dtype='uint8')\n",
    "    onehot[np.arange(len(labels)), labels] = 1\n",
    "\n",
    "    return onehot\n",
    "\n",
    "train_y = _onehot(train_labels)\n",
    "test_y = _onehot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "# sigmoid 미분\n",
    "def sigmoid_prime(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid layer 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid():\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 순전파시 결과물을 attribute로 저장 및 리턴\n",
    "        self.out = sigmoid(x)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        # 역전파시 그래디언트 값을 리턴\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      " [[ 0.33994424  0.73903127]\n",
      " [-1.49076399  0.8070138 ]\n",
      " [-0.52041393  0.86163554]\n",
      " [-1.29583146 -0.2225015 ]\n",
      " [-0.18043494 -1.39695172]]\n",
      "\n",
      "sigmoid_layer.forward(x) =\n",
      " [[0.58417698 0.67678398]\n",
      " [0.18380708 0.6914728 ]\n",
      " [0.37275545 0.70300225]\n",
      " [0.21486741 0.44460298]\n",
      " [0.45501325 0.19830027]]\n",
      "\n",
      "sigmoid_layer.backward(1) =\n",
      " [[0.24291424 0.21874742]\n",
      " [0.15002204 0.21333817]\n",
      " [0.23380882 0.20879009]\n",
      " [0.16869941 0.24693117]\n",
      " [0.24797619 0.15897728]]\n"
     ]
    }
   ],
   "source": [
    "# 시그모이드 레이어의 순전파/역전파가 잘 작동하는지 테스트\n",
    "# 임의의 사이즈에 대해 모두 동일한 크기의 결과가 출력되어야 하며, 각각 단순하게 시그모이드 함수를 적용한 값과 도함수를 적용한 값이 된다면 성공\n",
    "\n",
    "x = np.random.randn(5, 2)\n",
    "print('x =\\n', x)\n",
    "\n",
    "sigmoid_layer = Sigmoid()\n",
    "print('\\nsigmoid_layer.forward(x) =\\n', sigmoid_layer.forward(x))\n",
    "print('\\nsigmoid_layer.backward(1) =\\n', sigmoid_layer.backward(1)) # 최종 출력물의 미분값이 1일 경우 역전파의 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer():\n",
    "    def __init__(self, input_size, output_size, weight_init_std=0.01):\n",
    "        self.W = np.random.randn(input_size, output_size)\n",
    "        self.b = np.random.randn(output_size)\n",
    "\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      " [[ 0.1341428   0.50698011]\n",
      " [-0.09124876  1.01298656]\n",
      " [-1.20229058 -1.95331856]\n",
      " [-0.10288817 -0.61541472]\n",
      " [ 1.41882148  0.50177454]]\n",
      "\n",
      "fc_layer.forward(x) =\n",
      " [[-1.68152948 -2.66681342 -0.66095653]\n",
      " [-3.30449187 -2.66939375 -0.68016535]\n",
      " [ 0.80538729 -2.02223888 -3.02854982]\n",
      " [ 0.28098274 -2.46958891 -1.36401437]\n",
      " [ 1.18435745 -3.0000016   0.63671131]]\n",
      "\n",
      "fc_layer.backward(y) =\n",
      " [[ 0.60545793 -0.87614727]\n",
      " [ 1.13858277 -0.13627992]\n",
      " [ 4.99266136 -2.44755773]\n",
      " [-0.99435403  1.41079113]\n",
      " [-2.68662646  2.8552916 ]]\n"
     ]
    }
   ],
   "source": [
    "# FCLayer 레이어가 임의의 입출력 데이터에 대해 잘 작동하는지 테스트\n",
    "\n",
    "x = np.random.randn(5, 2)\n",
    "y = np.random.randn(5, 3)\n",
    "print('x =\\n', x)\n",
    "\n",
    "fc_layer = FCLayer(2, 3)\n",
    "print('\\nfc_layer.forward(x) =\\n', fc_layer.forward(x))\n",
    "print('\\nfc_layer.backward(y) =\\n', fc_layer.backward(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss():\n",
    "    '''Mean Squared Error Loss'''\n",
    "    def __init__(self):\n",
    "        self.loss = None    # 손실 함수 값. 역전파 계산을 위해 인스턴스 내에 저장됨\n",
    "        self.y = None       # 추론값 (y)\n",
    "        self.t = None       # 실제값 (target)\n",
    "\n",
    "    def forward(self, y, t):\n",
    "        '''Forward Propagation of Mean Squared Error Loss'''\n",
    "        # L = 1/N * sum((y - t)^2)\n",
    "        self.y = y\n",
    "        self.t = t\n",
    "        self.loss = np.mean((t - y) ** 2)\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        '''Backward Propagation (Backpropagation) of Mean Squared Error Loss'''\n",
    "        # dL/dy = 2(y - t) / N  ->  dy = 2(y - t) / N\n",
    "        dx = dout * (self.y - self.t) * 2 / self.t.shape[0]\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss():\n",
    "    '''교차 엔트로피(Cross Entropy) 레이어'''\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "\n",
    "    def forward(self, y, t):\n",
    "        '''교차 엔트로피 레이어의 순방향 전파'''\n",
    "        # L = -1/N * sum(t * log(y) + (1 - t) * log(1 - y))\n",
    "        self.y = y\n",
    "        self.t = t\n",
    "        self.loss = - np.sum(t * np.log(y + 1e-7) + (1 - t) * np.log(1 - y + 1e-7)) / len(y)\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        '''교차 엔트로피 레이어의 역방향 전파'''\n",
    "        # dL/dy = -t/y + (1 - t)/(1 - y)  ->  dy = (-t/y + (1 - t)/(1 - y))\n",
    "        dx =  dout * (self.y - self.t) / (self.t.shape[0] * (1-self.y) * self.y + 1e-7)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    '''다층 퍼셉트론(Multi Layer Perceptron, MLP) 모델'''\n",
    "    def __init__(self, input_size, hidden_size_list, output_size, loss_type='MSE'):\n",
    "        '''신경망의 구조와 손실 함수 정의\n",
    "        input_size: 입력 데이터의 차원 수\n",
    "        hidden_size_list: 은닉층 차원 수의 리스트 (e.g. [100, 100, 100])\n",
    "        output_size: 출력 데이터의 차원 수\n",
    "        loss_type: 손실 함수의 종류 ('MSE' or 'CrossEntropy')\n",
    "        '''\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size_list = hidden_size_list\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layer_num = len(hidden_size_list)\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "        ### 레이어 쌓기 : FCLayer -> Sigmoid -> ... -> FCLayer -> Sigmoid\n",
    "        # 입력층\n",
    "        self.layers = [\n",
    "            FCLayer(input_size, hidden_size_list[0]),\n",
    "            Sigmoid()\n",
    "        ]\n",
    "        # 은닉층\n",
    "        for idx in range(1, self.hidden_layer_num):\n",
    "            self.layers.append(FCLayer(hidden_size_list[idx-1], hidden_size_list[idx]))\n",
    "            self.layers.append(Sigmoid())\n",
    "        # 출력층\n",
    "        self.layers.append(FCLayer(hidden_size_list[-1], output_size))\n",
    "        self.layers.append(Sigmoid())\n",
    "\n",
    "        # 인자로 받은 `loss_type`에 맞게 손실 함수 레이어 정하기\n",
    "        if self.loss_type == 'MSE':\n",
    "            self.loss_layer = MSELoss()\n",
    "        elif self.loss_type == 'CrossEntropy':\n",
    "            self.loss_layer = CrossEntropyLoss()\n",
    "        else:\n",
    "            self.loss_layer = None\n",
    "\n",
    "\n",
    "        self.loss = None\n",
    "\n",
    "    def predict(self, x):\n",
    "        '''입력값을 받았을 때 순방향 전파를 통한 출력물 산출(예측)'''\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        '''MLP 모델의 순방향 전파'''\n",
    "        y = self.predict(x)\n",
    "        self.loss = self.loss_layer.forward(y, t)\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        '''MLP 모델의 역방향 전파'''\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      " [[-1.68969121  0.13537494]\n",
      " [ 0.56437682  0.71196519]\n",
      " [ 1.06277838 -0.26555085]\n",
      " [ 0.73983243  0.1949527 ]\n",
      " [-0.2899809  -0.47756757]]\n",
      "\n",
      "mlp.predict(x) =\n",
      " [[0.22589135]\n",
      " [0.2180116 ]\n",
      " [0.22122904]\n",
      " [0.2196382 ]\n",
      " [0.23448836]]\n",
      "\n",
      "mlp.forward(x, y) =\n",
      " 0.8785953306251664\n",
      "\n",
      "mlp.backward() =\n",
      " [[ 0.00086094 -0.00166005]\n",
      " [ 0.00460587  0.00191726]\n",
      " [-0.00151301 -0.00236224]\n",
      " [ 0.00404507  0.00336504]\n",
      " [ 0.00237073  0.00281788]]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입출력 데이터와 하이퍼파라미터에 대해 MLP 모델이 에러 없이 작동하는지 테스트\n",
    "\n",
    "x = np.random.randn(5, 2)\n",
    "y = np.random.randn(5, 1)\n",
    "print('x =\\n', x)\n",
    "\n",
    "mlp = MLP(input_size=2, hidden_size_list=[10, 5], output_size=1, loss_type='MSE')\n",
    "print('\\nmlp.predict(x) =\\n', mlp.predict(x))\n",
    "print('\\nmlp.forward(x, y) =\\n', mlp.forward(x, y))\n",
    "print('\\nmlp.backward() =\\n', mlp.backward())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =\n",
      " [[ 1.0839564   1.50019329]\n",
      " [ 0.16281826 -0.04426101]\n",
      " [-0.08312976  0.23833026]\n",
      " [-0.31740008  1.52891704]\n",
      " [ 0.9788983   0.06602767]]\n",
      "\n",
      "mlp.predict(x) =\n",
      " [[0.3081354 ]\n",
      " [0.31333168]\n",
      " [0.29265639]\n",
      " [0.24760672]\n",
      " [0.33453433]]\n",
      "\n",
      "mlp.forward(x, y) =\n",
      " 0.9384739103189131\n",
      "\n",
      "mlp.backward() =\n",
      " [[ 1.62338350e-04 -8.73421351e-05]\n",
      " [ 2.93543181e-02 -2.66775515e-02]\n",
      " [-2.83359359e-04  2.24954044e-04]\n",
      " [-1.60955765e-02  7.22871721e-03]\n",
      " [ 1.77820017e-03 -1.86034763e-03]]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입출력 데이터와 하이퍼파라미터에 대해 MLP 모델이 에러 없이 작동하는지 테스트\n",
    "\n",
    "x = np.random.randn(5, 2)\n",
    "y = np.random.randn(5, 1)\n",
    "print('x =\\n', x)\n",
    "\n",
    "mlp = MLP(input_size=2, hidden_size_list=[10, 5], output_size=1, loss_type='MSE')\n",
    "print('\\nmlp.predict(x) =\\n', mlp.predict(x))\n",
    "print('\\nmlp.forward(x, y) =\\n', mlp.forward(x, y))\n",
    "print('\\nmlp.backward() =\\n', mlp.backward())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크 구조를 정하기 위한 하이퍼파라미터 (784 -> 64 -> 16 -> 10)\n",
    "n_input = 784\n",
    "n_hidden = (64,16,)\n",
    "n_output = 10\n",
    "\n",
    "# 학습에 필요한 하이퍼파라미터\n",
    "batch_size = 128\n",
    "n_epochs = 30\n",
    "print_every = 1\n",
    "learning_rate_mse = 3\n",
    "learning_rate_ce = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE 손실 함수를 사용하는 MLP 모델\n",
    "mlp_mse = MLP(n_input, n_hidden, n_output, loss_type='MSE')\n",
    "\n",
    "# Cross Entropy 손실 함수를 사용하는 MLP 모델\n",
    "mlp_ce = MLP(n_input, n_hidden, n_output, loss_type='CrossEntropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, learning_rate, X_train, y_train, X_test, y_test):\n",
    "    '''모델 학습 함수'''\n",
    "    training_errors, training_accs = [], [] # 학습 손실 및 정확도\n",
    "    test_errors, test_accs = [], []         # 테스트 손실 및 정확도\n",
    "\n",
    "    # 학습 과정 : n_epochs만큼 반복\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        # 학습 데이터를 랜덤하게 섞음\n",
    "        idx = np.random.permutation(X_train.shape[0])\n",
    "        X_train = X_train[idx]\n",
    "        y_train = y_train[idx]\n",
    "\n",
    "        # 미니배치 학습\n",
    "        for i in range(0, X_train.shape[0], batch_size):\n",
    "            X_batch = X_train[i:i+batch_size]\n",
    "            y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "            # 순전파\n",
    "            model.forward(X_batch, y_batch)\n",
    "\n",
    "            # 역전파\n",
    "            model.backward()\n",
    "\n",
    "            # 모델 파라미터 업데이트\n",
    "            for layer in model.layers:\n",
    "                if isinstance(layer, FCLayer):\n",
    "                    layer.W -= learning_rate * layer.dW\n",
    "                    layer.b -= learning_rate * layer.db\n",
    "\n",
    "        # 학습 과정 출력 : print_every의 배수에 해당할 때마다 출력\n",
    "        if (epoch+1) % print_every == 0:\n",
    "            # 모든 학습 데이터에 대한 손실과 정확도 계산\n",
    "            model.forward(X_train, y_train)\n",
    "            training_errors.append(model.loss)\n",
    "            training_accs.append(accuracy(model.predict(X_train), y_train))\n",
    "\n",
    "            # 모든 테스트 데이터에 대한 손실과 정확도 계산\n",
    "            model.forward(X_test, y_test)\n",
    "            test_errors.append(model.loss)\n",
    "            test_accs.append(accuracy(model.predict(X_test), y_test))\n",
    "\n",
    "            # 학습 과정 출력\n",
    "            print('[Epoch {}/{}] Training Loss = {:.4f} / Training Acc = {:.2f}% /'\n",
    "                  'Test Loss = {:.4f} / Test Acc = {:.2f}%'.format(\n",
    "                      epoch+1, n_epochs,\n",
    "                      training_errors[-1], training_accs[-1]*100,\n",
    "                      test_errors[-1], test_accs[-1]*100))\n",
    "\n",
    "    return np.asarray([training_errors, test_errors, training_accs, test_accs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff78fd9ec9f648578289d5c29c38e548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (128,28,28) and (784,64) not aligned: 28 (dim 2) != 784 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# MSE 손실 함수를 사용하는 모델 학습\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m training_result_mse \u001b[38;5;241m=\u001b[39m training(mlp_mse, learning_rate_mse, train_X, train_y, test_X, test_y)\n",
      "Cell \u001b[0;32mIn[23], line 19\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, learning_rate, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     16\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_train[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 순전파\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m model\u001b[38;5;241m.\u001b[39mforward(X_batch, y_batch)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 역전파\u001b[39;00m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[18], line 50\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t):\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''MLP 모델의 순방향 전파'''\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_layer\u001b[38;5;241m.\u001b[39mforward(y, t)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\n",
      "Cell \u001b[0;32mIn[18], line 45\u001b[0m, in \u001b[0;36mMLP.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''입력값을 받았을 때 순방향 전파를 통한 출력물 산출(예측)'''\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 45\u001b[0m     x \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m, in \u001b[0;36mFCLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m---> 12\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (128,28,28) and (784,64) not aligned: 28 (dim 2) != 784 (dim 0)"
     ]
    }
   ],
   "source": [
    "# MSE 손실 함수를 사용하는 모델 학습\n",
    "training_result_mse = training(mlp_mse, learning_rate_mse, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
